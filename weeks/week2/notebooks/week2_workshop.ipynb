{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 2 Interactive Workshop: Advanced Data Processing & LangChain Fundamentals\n",
        "\n",
        "Welcome to Week 2! This interactive workshop combines advanced data preprocessing with LangChain fundamentals to build powerful hybrid ML + LLM pipelines.\n",
        "\n",
        "## üéØ Workshop Objectives\n",
        "\n",
        "By the end of this session, you'll be able to:\n",
        "- Master advanced Metaflow preprocessing patterns\n",
        "- Understand and use LangChain Expression Language (LCEL)\n",
        "- Set up and work with local LLMs using Ollama\n",
        "- Build hybrid workflows combining traditional ML with LLM capabilities\n",
        "- Process text data with sophisticated NLP techniques\n",
        "\n",
        "## ‚è∞ Workshop Timeline (90 minutes)\n",
        "\n",
        "### Part 1: Advanced Data Preprocessing (45 minutes)\n",
        "1. **Missing Data Strategies** (10 min) - Advanced imputation techniques\n",
        "2. **Feature Engineering** (15 min) - Creating predictive features\n",
        "3. **Scaling and Validation** (10 min) - Pipeline robustness\n",
        "4. **Text Data Handling** (10 min) - NLP preprocessing fundamentals\n",
        "\n",
        "### Part 2: LangChain Introduction (30 minutes)\n",
        "1. **Installation and Setup** (5 min) - LangChain and Ollama\n",
        "2. **First LCEL Chain** (10 min) - prompt | model | output_parser\n",
        "3. **Local LLM Integration** (10 min) - Working with Ollama models\n",
        "4. **Chain Composition** (5 min) - Building complex workflows\n",
        "\n",
        "### Part 3: Integration Workshop (15 minutes)\n",
        "1. **Hybrid Pipelines** (10 min) - Combining Metaflow + LangChain\n",
        "2. **Text Analysis** (5 min) - LLM-powered data insights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Prerequisites Check\n",
        "\n",
        "Let's verify your environment is ready for the workshop!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def check_environment():\n",
        "    \"\"\"Comprehensive environment verification for Week 2 workshop\"\"\"\n",
        "    print(\"üîç WEEK 2 ENVIRONMENT CHECK\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Check Python packages\n",
        "    required_packages = {\n",
        "        'metaflow': ['metaflow', '2.7+'],\n",
        "        'pandas': ['pandas', '1.3+'],\n",
        "        'numpy': ['numpy', '1.20+'],\n",
        "        'sklearn': ['scikit-learn', '1.0+'],\n",
        "        'langchain': ['langchain', '0.1+'],\n",
        "        'langchain_community': ['langchain_community', '0.0.10+'],\n",
        "        'matplotlib': ['matplotlib', '3.3+'],\n",
        "        'seaborn': ['seaborn', '0.11+']\n",
        "    }\n",
        "    \n",
        "    print(\"üì¶ Checking Python packages...\")\n",
        "    missing_packages = []\n",
        "    \n",
        "    for lib, package in required_packages.items():\n",
        "        try:\n",
        "            __import__(lib)\n",
        "            print(f\"   ‚úÖ {package[0]} {package[1]} - OK\")\n",
        "        except ImportError:\n",
        "            print(f\"   ‚ùå {package[0]} {package[1]} - MISSING\")\n",
        "            missing_packages.append(f\"{package[0]} {package[1]}\")\n",
        "    \n",
        "    if missing_packages:\n",
        "        print(f\"\\n‚ö†Ô∏è  Install missing packages: pip install {' '.join(missing_packages)}\")\n",
        "        return False\n",
        "    \n",
        "    # Check data files\n",
        "    print(\"\\nüìä Checking data files...\")\n",
        "    data_files = [\n",
        "        '../data/titanic.csv',\n",
        "        '../data/customer_reviews.csv',\n",
        "        '../data/financial_data.json'\n",
        "    ]\n",
        "    \n",
        "    for file_path in data_files:\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"   ‚úÖ {os.path.basename(file_path)}\")\n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è  {os.path.basename(file_path)} - Not found (will use sample data)\")\n",
        "    \n",
        "    # Check Ollama\n",
        "    print(\"\\nüß† Checking Ollama installation...\")\n",
        "    try:\n",
        "        result = subprocess.run(['ollama', '--version'], \n",
        "                              capture_output=True, text=True, timeout=5)\n",
        "        if result.returncode == 0:\n",
        "            print(\"   ‚úÖ Ollama installed\")\n",
        "            print(\"   üí° Download model with: ollama pull llama3.2\")\n",
        "        else:\n",
        "            print(\"   ‚ùå Ollama command failed\")\n",
        "    except (subprocess.TimeoutExpired, FileNotFoundError):\n",
        "        print(\"   ‚ùå Ollama not found - install from ollama.com\")\n",
        "        print(\"      This is required for LLM exercises\")\n",
        "    \n",
        "    print(\"\\nüéØ Environment check complete!\")\n",
        "    print(\"   Ready to start the workshop!\")\n",
        "    return True\n",
        "\n",
        "check_environment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Advanced Data Preprocessing with Metaflow (45 minutes)\n",
        "\n",
        "Let's start by setting up our imports and loading sample data for preprocessing exercises."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complete imports for advanced data preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler, MinMaxScaler, RobustScaler,\n",
        "    LabelEncoder, OneHotEncoder\n",
        ")\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from metaflow import FlowSpec, step, Parameter, IncludeFile, catch\n",
        "import re\n",
        "import string\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"viridis\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "print(\"üìä Data preprocessing environment ready!\")\n",
        "print(\"üéØ Let's build advanced preprocessing pipelines!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Loading and Exploring Our Datasets\n",
        "\n",
        "We'll work with three datasets to practice different preprocessing techniques:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load datasets (with fallback to sample data)\n",
        "def load_workshop_data():\n",
        "    \"\"\"Load datasets for preprocessing workshop\"\"\"\n",
        "    \n",
        "    print(\"üì• Loading workshop datasets...\")\n",
        "    \n",
        "    # Dataset 1: Titanic (structured data with missing values)\n",
        "    try:\n",
        "        titanic = pd.read_csv('../data/titanic.csv')\n",
        "        print(\"   ‚úÖ Loaded Titanic dataset\")\n",
        "    except FileNotFoundError:\n",
        "        # Create sample titanic-like data\n",
        "        np.random.seed(42)\n",
        "        n_samples = 800\n",
        "        titanic = pd.DataFrame({\n",
        "            'PassengerId': range(1, n_samples + 1),\n",
        "            'Survived': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),\n",
        "            'Pclass': np.random.choice([1, 2, 3], n_samples, p=[0.2, 0.3, 0.5]),\n",
        "            'Name': [f'Passenger {i}' for i in range(1, n_samples + 1)],\n",
        "            'Sex': np.random.choice(['male', 'female'], n_samples, p=[0.65, 0.35]),\n",
        "            'Age': np.random.normal(30, 12, n_samples),\n",
        "            'SibSp': np.random.poisson(0.5, n_samples),\n",
        "            'Parch': np.random.poisson(0.3, n_samples),\n",
        "            'Ticket': [f'TICKET{i}' for i in range(1, n_samples + 1)],\n",
        "            'Fare': np.random.lognormal(3, 1, n_samples),\n",
        "            'Cabin': [f'C{i}' if np.random.random() > 0.7 else None for i in range(n_samples)],\n",
        "            'Embarked': np.random.choice(['C', 'Q', 'S'], n_samples, p=[0.2, 0.1, 0.7])\n",
        "        })\n",
        "        # Introduce missing values\n",
        "        titanic.loc[np.random.choice(titanic.index, 150, replace=False), 'Age'] = np.nan\n",
        "        titanic.loc[np.random.choice(titanic.index, 50, replace=False), 'Embarked'] = np.nan\n",
        "        print(\"   ‚úÖ Created sample Titanic-like dataset\")\n",
        "    \n",
        "    # Dataset 2: Customer Reviews (text data)\n",
        "    try:\n",
        "        reviews = pd.read_csv('../data/customer_reviews.csv')\n",
        "        print(\"   ‚úÖ Loaded customer reviews dataset\")\n",
        "    except FileNotFoundError:\n",
        "        # Create sample review data\n",
        "        sample_reviews = [\n",
        "            \"Great product! Highly recommend to everyone.\",\n",
        "            \"Terrible quality. Broke after one day.\",\n",
        "            \"Average product, nothing special but works fine.\",\n",
        "            \"Amazing customer service and fast delivery!\",\n",
        "            \"Not worth the money. Poor build quality.\",\n",
        "            \"Excellent value for money. Very satisfied!\",\n",
        "            \"Disappointed with the purchase. Returns policy unclear.\",\n",
        "            \"Perfect for my needs. Would buy again.\"\n",
        "        ]\n",
        "        \n",
        "        np.random.seed(42)\n",
        "        n_reviews = 500\n",
        "        reviews = pd.DataFrame({\n",
        "            'review_id': range(1, n_reviews + 1),\n",
        "            'review_text': np.random.choice(sample_reviews, n_reviews),\n",
        "            'rating': np.random.choice([1, 2, 3, 4, 5], n_reviews, p=[0.1, 0.1, 0.2, 0.3, 0.3]),\n",
        "            'product_category': np.random.choice(['Electronics', 'Clothing', 'Home', 'Books'], n_reviews)\n",
        "        })\n",
        "        print(\"   ‚úÖ Created sample customer reviews dataset\")\n",
        "    \n",
        "    return titanic, reviews\n",
        "\n",
        "# Load the data\n",
        "titanic_df, reviews_df = load_workshop_data()\n",
        "\n",
        "print(f\"\\nüìä Dataset Overview:\")\n",
        "print(f\"   üö¢ Titanic: {titanic_df.shape[0]} rows, {titanic_df.shape[1]} columns\")\n",
        "print(f\"   üí¨ Reviews: {reviews_df.shape[0]} rows, {reviews_df.shape[1]} columns\")\n",
        "\n",
        "# Quick preview\n",
        "print(\"\\nüîç Titanic Preview:\")\n",
        "display(titanic_df.head())\n",
        "\n",
        "print(\"\\nüîç Reviews Preview:\")\n",
        "display(reviews_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéØ Exercise 1.1: Missing Data Analysis (10 minutes)\n",
        "\n",
        "**Your Task**: Analyze and handle missing data in the Titanic dataset using advanced imputation techniques.\n",
        "\n",
        "**Instructions**:\n",
        "1. Identify columns with missing values and their percentages\n",
        "2. Visualize missing data patterns\n",
        "3. Implement different imputation strategies:\n",
        "   - Simple imputation (mean, median, mode)\n",
        "   - KNN imputation\n",
        "   - Custom domain-specific imputation\n",
        "4. Compare the results and choose the best strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERCISE 1.1: Your solution here!\n",
        "print(\"üíª Exercise 1.1: Missing Data Analysis\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Step 1: Identify missing values\n",
        "missing_info = titanic_df.isnull().sum()\n",
        "missing_percent = (missing_info / len(titanic_df)) * 100\n",
        "\n",
        "print(\"üìä Missing Value Analysis:\")\n",
        "for col in missing_info[missing_info > 0].index:\n",
        "    print(f\"   {col}: {missing_info[col]} ({missing_percent[col]:.1f}%)\")\n",
        "\n",
        "# Step 2: Visualize missing patterns\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "missing_info[missing_info > 0].plot(kind='bar')\n",
        "plt.title('Missing Values Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "# Heatmap of missing values\n",
        "plt.imshow(titanic_df.isnull(), cmap='viridis', aspect='auto')\n",
        "plt.title('Missing Values Pattern')\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Rows')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Your turn: Implement different imputation strategies!\n",
        "print(\"\\nüîß Implement your imputation strategies below:\")\n",
        "print(\"   Hint: Try SimpleImputer and KNNImputer from sklearn\")\n",
        "print(\"   Consider domain knowledge for better imputation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéØ Exercise 1.2: Feature Engineering (15 minutes)\n",
        "\n",
        "**Your Task**: Create meaningful features from the Titanic dataset to improve model performance.\n",
        "\n",
        "**Instructions**:\n",
        "1. Extract titles from passenger names\n",
        "2. Create family size features\n",
        "3. Bin numerical features (Age, Fare)\n",
        "4. Create interaction features\n",
        "5. Evaluate feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERCISE 1.2: Your solution here!\n",
        "print(\"üíª Exercise 1.2: Feature Engineering\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Create a copy for feature engineering\n",
        "titanic_fe = titanic_df.copy()\n",
        "\n",
        "# Example: Extract titles from names\n",
        "def extract_title(name):\n",
        "    \"\"\"Extract title from passenger name\"\"\"\n",
        "    title = re.search(' ([A-Za-z]+)\\.', name)\n",
        "    if title:\n",
        "        return title.group(1)\n",
        "    return 'Unknown'\n",
        "\n",
        "titanic_fe['Title'] = titanic_fe['Name'].apply(extract_title)\n",
        "print(f\"üìù Extracted titles: {titanic_fe['Title'].value_counts().head()}\")\n",
        "\n",
        "# Your turn: Create more features!\n",
        "print(\"\\nüîß Create additional features:\")\n",
        "print(\"   1. Family size (SibSp + Parch + 1)\")\n",
        "print(\"   2. Is alone (family size == 1)\")\n",
        "print(\"   3. Age groups (Child, Adult, Senior)\")\n",
        "print(\"   4. Fare per person (Fare / family size)\")\n",
        "print(\"   5. Deck from Cabin (first letter)\")\n",
        "\n",
        "# Add your feature engineering code here!\n",
        "\n",
        "print(\"\\nüìä Feature engineering complete!\")\n",
        "print(f\"   Original features: {titanic_df.shape[1]}\")\n",
        "print(f\"   New features: {titanic_fe.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéØ Exercise 1.3: Scaling and Pipeline Validation (10 minutes)\n",
        "\n",
        "**Your Task**: Build a robust preprocessing pipeline with proper scaling and validation.\n",
        "\n",
        "**Instructions**:\n",
        "1. Compare different scaling techniques\n",
        "2. Handle categorical variables properly\n",
        "3. Create a complete preprocessing pipeline\n",
        "4. Validate pipeline robustness with cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERCISE 1.3: Your solution here!\n",
        "print(\"üíª Exercise 1.3: Scaling and Pipeline Validation\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Prepare sample data for scaling comparison\n",
        "numerical_features = ['Age', 'Fare', 'SibSp', 'Parch']\n",
        "sample_data = titanic_df[numerical_features].dropna()\n",
        "\n",
        "# Compare scaling techniques\n",
        "scalers = {\n",
        "    'StandardScaler': StandardScaler(),\n",
        "    'MinMaxScaler': MinMaxScaler(),\n",
        "    'RobustScaler': RobustScaler()\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, (name, scaler) in enumerate(scalers.items(), 1):\n",
        "    scaled_data = scaler.fit_transform(sample_data)\n",
        "    \n",
        "    plt.subplot(1, 3, i)\n",
        "    plt.boxplot(scaled_data, labels=numerical_features)\n",
        "    plt.title(f'{name}')\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüîß Build your complete preprocessing pipeline:\")\n",
        "print(\"   1. Handle missing values\")\n",
        "print(\"   2. Encode categorical variables\")\n",
        "print(\"   3. Scale numerical features\")\n",
        "print(\"   4. Add feature engineering\")\n",
        "print(\"   5. Validate with cross-validation\")\n",
        "\n",
        "# Add your pipeline code here!\n",
        "\n",
        "print(\"\\n‚úÖ Pipeline validation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéØ Exercise 1.4: Text Data Preprocessing (10 minutes)\n",
        "\n",
        "**Your Task**: Process the customer reviews dataset using NLP techniques.\n",
        "\n",
        "**Instructions**:\n",
        "1. Clean and normalize text data\n",
        "2. Remove stopwords and special characters\n",
        "3. Apply stemming/lemmatization\n",
        "4. Create TF-IDF features\n",
        "5. Analyze text patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERCISE 1.4: Your solution here!\n",
        "print(\"üíª Exercise 1.4: Text Data Preprocessing\")\n",
        "print(\"=\" * 42)\n",
        "\n",
        "# Basic text preprocessing function\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean and normalize text data\"\"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    \n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Apply basic cleaning\n",
        "reviews_df['clean_text'] = reviews_df['review_text'].apply(clean_text)\n",
        "\n",
        "print(\"üìù Text Cleaning Example:\")\n",
        "for i in range(3):\n",
        "    print(f\"   Original: {reviews_df['review_text'].iloc[i]}\")\n",
        "    print(f\"   Cleaned:  {reviews_df['clean_text'].iloc[i]}\")\n",
        "    print()\n",
        "\n",
        "# Your turn: Add more sophisticated preprocessing!\n",
        "print(\"üîß Add advanced text preprocessing:\")\n",
        "print(\"   1. Remove stopwords\")\n",
        "print(\"   2. Apply stemming or lemmatization\")\n",
        "print(\"   3. Create TF-IDF features\")\n",
        "print(\"   4. Extract sentiment features\")\n",
        "print(\"   5. Analyze word frequencies\")\n",
        "\n",
        "# Create TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
        "tfidf_features = vectorizer.fit_transform(reviews_df['clean_text'])\n",
        "\n",
        "print(f\"\\nüìä TF-IDF Matrix: {tfidf_features.shape}\")\n",
        "print(f\"   Features: {len(vectorizer.get_feature_names_out())}\")\n",
        "print(f\"   Top features: {vectorizer.get_feature_names_out()[:10]}\")\n",
        "\n",
        "# Add your advanced text processing here!\n",
        "\n",
        "print(\"\\n‚úÖ Text preprocessing complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: LangChain Introduction (30 minutes)\n",
        "\n",
        "Now let's dive into LangChain and build our first chains using LCEL (LangChain Expression Language)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LangChain imports and setup\n",
        "try:\n",
        "    from langchain_core.prompts import ChatPromptTemplate\n",
        "    from langchain_core.output_parsers import StrOutputParser\n",
        "    from langchain_community.llms import Ollama\n",
        "    from langchain_community.chat_models import ChatOllama\n",
        "    from langchain_core.runnables import RunnablePassthrough\n",
        "    from langchain_core.messages import HumanMessage, SystemMessage\n",
        "    \n",
        "    print(\"‚úÖ LangChain imports successful!\")\n",
        "    \n",
        "    # Test Ollama connection\n",
        "    try:\n",
        "        llm = ChatOllama(model=\"llama3.2\", temperature=0.1)\n",
        "        test_response = llm.invoke([HumanMessage(content=\"Hello! Just testing connection.\")])\n",
        "        print(\"‚úÖ Ollama connection successful!\")\n",
        "        print(f\"   Model: llama3.2\")\n",
        "        print(f\"   Test response: {test_response.content[:50]}...\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Ollama connection failed: {e}\")\n",
        "        print(\"   Make sure Ollama is running and llama3.2 is downloaded\")\n",
        "        print(\"   Run: ollama pull llama3.2\")\n",
        "        \n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå LangChain import failed: {e}\")\n",
        "    print(\"   Install with: pip install langchain langchain-community\")\n",
        "\n",
        "print(\"\\nüß† LangChain environment ready!\")\n",
        "print(\"üéØ Let's build some chains!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéØ Exercise 2.1: Your First LCEL Chain (10 minutes)\n",
        "\n",
        "**Your Task**: Build a simple prompt | model | output_parser chain using LCEL syntax.\n",
        "\n",
        "**Instructions**:\n",
        "1. Create a chat prompt template\n",
        "2. Set up the Ollama model\n",
        "3. Add an output parser\n",
        "4. Chain them together with LCEL\n",
        "5. Test with different inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERCISE 2.1: Your solution here!\n",
        "print(\"üíª Exercise 2.1: Building Your First LCEL Chain\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Step 1: Create a prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful data science assistant. Provide clear, concise explanations.\"),\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "# Step 2: Set up the model\n",
        "model = ChatOllama(model=\"llama3.2\", temperature=0.1)\n",
        "\n",
        "# Step 3: Add output parser\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# Step 4: Create the chain using LCEL\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "print(\"üîó Chain created: prompt | model | output_parser\")\n",
        "\n",
        "# Step 5: Test the chain\n",
        "test_questions = [\n",
        "    \"What is the difference between bias and variance in machine learning?\",\n",
        "    \"Explain what cross-validation is in simple terms.\",\n",
        "    \"What are the main steps in a data preprocessing pipeline?\"\n",
        "]\n",
        "\n",
        "print(\"\\nüß™ Testing the chain:\")\n",
        "for i, question in enumerate(test_questions[:1], 1):  # Test first question\n",
        "    print(f\"\\n   Question {i}: {question}\")\n",
        "    try:\n",
        "        response = chain.invoke({\"question\": question})\n",
        "        print(f\"   Answer: {response}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error: {e}\")\n",
        "\n",
        "# Your turn: Try the other questions and create your own!\n",
        "print(\"\\nüîß Your turn:\")\n",
        "print(\"   1. Test the remaining questions\")\n",
        "print(\"   2. Create your own data science questions\")\n",
        "print(\"   3. Experiment with different temperature values\")\n",
        "print(\"   4. Modify the system prompt\")\n",
        "\n",
        "print(\"\\n‚úÖ First LCEL chain complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéØ Exercise 2.2: Advanced Chain Composition (10 minutes)\n",
        "\n",
        "**Your Task**: Build more complex chains with multiple steps and data processing.\n",
        "\n",
        "**Instructions**:\n",
        "1. Create a data analysis chain\n",
        "2. Add data preprocessing steps\n",
        "3. Combine statistical analysis with LLM insights\n",
        "4. Build a chain that processes our customer reviews\n",
        "5. Create a summary and recommendations chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERCISE 2.2: Your solution here!\n",
        "print(\"üíª Exercise 2.2: Advanced Chain Composition\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Create a data analysis chain\n",
        "analysis_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a data analyst. Analyze the provided data and give insights.\"),\n",
        "    (\"human\", \"Analyze this dataset summary: {data_summary}\\n\\nProvide key insights and recommendations.\")\n",
        "])\n",
        "\n",
        "# Create a function to summarize our review data\n",
        "def summarize_reviews(reviews_df):\n",
        "    \"\"\"Create a statistical summary of reviews\"\"\"\n",
        "    summary = {\n",
        "        'total_reviews': len(reviews_df),\n",
        "        'avg_rating': reviews_df['rating'].mean(),\n",
        "        'rating_distribution': reviews_df['rating'].value_counts().to_dict(),\n",
        "        'categories': reviews_df['product_category'].value_counts().to_dict(),\n",
        "        'common_words': ' '.join(reviews_df['review_text']).lower().split()\n",
        "    }\n",
        "    \n",
        "    # Get most common words (simple approach)\n",
        "    from collections import Counter\n",
        "    word_counts = Counter(summary['common_words'])\n",
        "    summary['top_words'] = dict(word_counts.most_common(10))\n",
        "    del summary['common_words']  # Remove the large list\n",
        "    \n",
        "    return summary\n",
        "\n",
        "# Create the analysis chain\n",
        "analysis_chain = (\n",
        "    RunnablePassthrough()\n",
        "    | analysis_prompt\n",
        "    | model\n",
        "    | output_parser\n",
        ")\n",
        "\n",
        "# Test the chain with our review data\n",
        "print(\"üìä Analyzing customer reviews...\")\n",
        "review_summary = summarize_reviews(reviews_df)\n",
        "print(f\"   Summary: {review_summary}\")\n",
        "\n",
        "try:\n",
        "    insights = analysis_chain.invoke({\"data_summary\": str(review_summary)})\n",
        "    print(f\"\\nüß† LLM Insights:\\n{insights}\")\n",
        "except Exception as e:\n",
        "    print(f\"   Error: {e}\")\n",
        "\n",
        "# Your turn: Build more complex chains!\n",
        "print(\"\\nüîß Build your own advanced chains:\")\n",
        "print(\"   1. Sentiment analysis chain for individual reviews\")\n",
        "print(\"   2. Product recommendation chain\")\n",
        "print(\"   3. Multi-step analysis pipeline\")\n",
        "print(\"   4. Combine numerical and text analysis\")\n",
        "\n",
        "# Add your advanced chain code here!\n",
        "\n",
        "print(\"\\n‚úÖ Advanced chain composition complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéØ Exercise 2.3: LLM Model Comparison (10 minutes)\n",
        "\n",
        "**Your Task**: Compare different local LLM models and their outputs.\n",
        "\n",
        "**Instructions**:\n",
        "1. Set up multiple Ollama models\n",
        "2. Create a comparison chain\n",
        "3. Test the same prompt across models\n",
        "4. Analyze differences in responses\n",
        "5. Choose the best model for your use case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERCISE 2.3: Your solution here!\n",
        "print(\"üíª Exercise 2.3: LLM Model Comparison\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Available models to test (install with: ollama pull <model>)\n",
        "available_models = [\n",
        "    \"llama3.2:1b\",   # Lightweight\n",
        "    \"llama3.2\",      # Standard\n",
        "    \"phi3\",          # Alternative\n",
        "]\n",
        "\n",
        "# Test prompt\n",
        "test_prompt = \"Explain the bias-variance tradeoff in machine learning in 2-3 sentences.\"\n",
        "\n",
        "print(f\"üß™ Testing prompt: {test_prompt}\")\n",
        "print(\"\\nüìã Model Comparison:\")\n",
        "\n",
        "# Test each available model\n",
        "model_responses = {}\n",
        "\n",
        "for model_name in available_models:\n",
        "    try:\n",
        "        print(f\"\\nü§ñ Testing {model_name}...\")\n",
        "        \n",
        "        # Create model instance\n",
        "        test_model = ChatOllama(model=model_name, temperature=0.1)\n",
        "        \n",
        "        # Simple chain\n",
        "        simple_chain = test_model | StrOutputParser()\n",
        "        \n",
        "        # Get response\n",
        "        response = simple_chain.invoke([HumanMessage(content=test_prompt)])\n",
        "        model_responses[model_name] = response\n",
        "        \n",
        "        print(f\"   ‚úÖ Response: {response}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Error with {model_name}: {e}\")\n",
        "        print(f\"      Try: ollama pull {model_name}\")\n",
        "\n",
        "# Your turn: Analyze the differences!\n",
        "print(\"\\nüîß Analysis tasks:\")\n",
        "print(\"   1. Compare response quality and accuracy\")\n",
        "print(\"   2. Measure response length and detail\")\n",
        "print(\"   3. Test with different types of prompts\")\n",
        "print(\"   4. Consider speed vs. quality tradeoffs\")\n",
        "print(\"   5. Choose the best model for your use case\")\n",
        "\n",
        "# Simple comparison\n",
        "if model_responses:\n",
        "    print(\"\\nüìä Quick Analysis:\")\n",
        "    for model, response in model_responses.items():\n",
        "        print(f\"   {model}: {len(response)} characters\")\n",
        "\n",
        "print(\"\\n‚úÖ Model comparison complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Integration Workshop - Hybrid Pipelines (15 minutes)\n",
        "\n",
        "Now let's combine everything: Metaflow data processing with LangChain analysis!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéØ Exercise 3.1: Building a Hybrid Pipeline (10 minutes)\n",
        "\n",
        "**Your Task**: Create a Metaflow pipeline that incorporates LangChain for intelligent data analysis.\n",
        "\n",
        "**Instructions**:\n",
        "1. Design a Metaflow flow with data preprocessing\n",
        "2. Add LangChain analysis steps\n",
        "3. Combine statistical analysis with LLM insights\n",
        "4. Generate automated reports\n",
        "5. Test the complete pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERCISE 3.1: Your solution here!\n",
        "print(\"üíª Exercise 3.1: Building a Hybrid Pipeline\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Define a hybrid Metaflow + LangChain pipeline\n",
        "class HybridAnalysisPipeline(FlowSpec):\n",
        "    \"\"\"\n",
        "    A hybrid pipeline combining Metaflow data processing \n",
        "    with LangChain LLM analysis\n",
        "    \"\"\"\n",
        "    \n",
        "    dataset_type = Parameter('dataset', default='reviews',\n",
        "                            help='Dataset to analyze: reviews or titanic')\n",
        "    \n",
        "    @step\n",
        "    def start(self):\n",
        "        \"\"\"\n",
        "        Initialize the pipeline and load data\n",
        "        \"\"\"\n",
        "        print(\"üöÄ Starting hybrid analysis pipeline\")\n",
        "        print(f\"   Dataset: {self.dataset_type}\")\n",
        "        \n",
        "        # Load appropriate dataset\n",
        "        if self.dataset_type == 'reviews':\n",
        "            self.data = reviews_df.copy()\n",
        "            print(f\"   Loaded {len(self.data)} reviews\")\n",
        "        else:\n",
        "            self.data = titanic_df.copy()\n",
        "            print(f\"   Loaded {len(self.data)} passenger records\")\n",
        "        \n",
        "        self.next(self.preprocess_data)\n",
        "    \n",
        "    @step\n",
        "    def preprocess_data(self):\n",
        "        \"\"\"\n",
        "        Apply data preprocessing\n",
        "        \"\"\"\n",
        "        print(\"üîß Preprocessing data...\")\n",
        "        \n",
        "        if self.dataset_type == 'reviews':\n",
        "            # Text preprocessing\n",
        "            self.data['clean_text'] = self.data['review_text'].apply(clean_text)\n",
        "            \n",
        "            # Create summary statistics\n",
        "            self.stats = {\n",
        "                'total_reviews': len(self.data),\n",
        "                'avg_rating': self.data['rating'].mean(),\n",
        "                'rating_distribution': self.data['rating'].value_counts().to_dict()\n",
        "            }\n",
        "        else:\n",
        "            # Handle missing values\n",
        "            self.data['Age'].fillna(self.data['Age'].median(), inplace=True)\n",
        "            self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)\n",
        "            \n",
        "            # Create summary statistics\n",
        "            self.stats = {\n",
        "                'survival_rate': self.data['Survived'].mean(),\n",
        "                'avg_age': self.data['Age'].mean(),\n",
        "                'class_distribution': self.data['Pclass'].value_counts().to_dict()\n",
        "            }\n",
        "        \n",
        "        print(f\"   Preprocessing complete: {self.stats}\")\n",
        "        self.next(self.llm_analysis)\n",
        "    \n",
        "    @step \n",
        "    def llm_analysis(self):\n",
        "        \"\"\"\n",
        "        Use LangChain for intelligent analysis\n",
        "        \"\"\"\n",
        "        print(\"üß† Running LLM analysis...\")\n",
        "        \n",
        "        try:\n",
        "            # Create analysis prompt\n",
        "            analysis_prompt = ChatPromptTemplate.from_messages([\n",
        "                (\"system\", \"You are an expert data analyst. Provide insights and recommendations.\"),\n",
        "                (\"human\", \"Analyze this data summary and provide 3 key insights: {data_summary}\")\n",
        "            ])\n",
        "            \n",
        "            # Create analysis chain\n",
        "            analysis_chain = analysis_prompt | model | output_parser\n",
        "            \n",
        "            # Generate insights\n",
        "            self.llm_insights = analysis_chain.invoke({\"data_summary\": str(self.stats)})\n",
        "            print(f\"   LLM Analysis: {self.llm_insights[:100]}...\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   LLM analysis failed: {e}\")\n",
        "            self.llm_insights = \"LLM analysis unavailable\"\n",
        "        \n",
        "        self.next(self.generate_report)\n",
        "    \n",
        "    @step\n",
        "    def generate_report(self):\n",
        "        \"\"\"\n",
        "        Generate final analysis report\n",
        "        \"\"\"\n",
        "        print(\"üìä Generating final report...\")\n",
        "        \n",
        "        self.report = {\n",
        "            'dataset': self.dataset_type,\n",
        "            'data_shape': self.data.shape,\n",
        "            'statistics': self.stats,\n",
        "            'llm_insights': self.llm_insights,\n",
        "            'timestamp': pd.Timestamp.now().isoformat()\n",
        "        }\n",
        "        \n",
        "        print(\"   Report generated successfully!\")\n",
        "        self.next(self.end)\n",
        "    \n",
        "    @step\n",
        "    def end(self):\n",
        "        \"\"\"\n",
        "        Pipeline completion\n",
        "        \"\"\"\n",
        "        print(\"üéâ Hybrid pipeline complete!\")\n",
        "        print(f\"   Final report: {len(str(self.report))} characters\")\n",
        "\n",
        "print(\"‚úÖ Hybrid pipeline class defined!\")\n",
        "print(\"\\nüîß Your turn:\")\n",
        "print(\"   1. Add more sophisticated preprocessing steps\")\n",
        "print(\"   2. Include multiple LLM analysis stages\")\n",
        "print(\"   3. Add data visualization generation\")\n",
        "print(\"   4. Implement error handling and logging\")\n",
        "print(\"   5. Create automated report formatting\")\n",
        "\n",
        "# Test the pipeline (comment out if Ollama not available)\n",
        "print(\"\\nüß™ Testing hybrid pipeline...\")\n",
        "print(\"   (Uncomment the code below to test)\")\n",
        "\n",
        "# Uncomment to test:\n",
        "# if __name__ == '__main__':\n",
        "#     HybridAnalysisPipeline()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéØ Exercise 3.2: Production Considerations (5 minutes)\n",
        "\n",
        "**Your Task**: Discuss and implement production-ready patterns for hybrid pipelines.\n",
        "\n",
        "**Instructions**:\n",
        "1. Error handling and fallback strategies\n",
        "2. Model versioning and updates\n",
        "3. Monitoring and logging\n",
        "4. Scalability considerations\n",
        "5. Cost optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERCISE 3.2: Your solution here!\n",
        "print(\"üíª Exercise 3.2: Production Considerations\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "print(\"üè≠ Production-Ready Patterns:\")\n",
        "\n",
        "production_patterns = {\n",
        "    \"Error Handling\": [\n",
        "        \"Graceful LLM failures with fallback analysis\",\n",
        "        \"Retry logic for API calls\",\n",
        "        \"Data validation checkpoints\",\n",
        "        \"Circuit breaker patterns\"\n",
        "    ],\n",
        "    \"Monitoring\": [\n",
        "        \"Track LLM response times and quality\",\n",
        "        \"Monitor data drift in inputs\",\n",
        "        \"Log pipeline execution metrics\",\n",
        "        \"Alert on analysis anomalies\"\n",
        "    ],\n",
        "    \"Scalability\": [\n",
        "        \"Batch processing for large datasets\",\n",
        "        \"Async LLM calls for parallel processing\",\n",
        "        \"Caching for repeated analyses\",\n",
        "        \"Resource management and limits\"\n",
        "    ],\n",
        "    \"Cost Optimization\": [\n",
        "        \"Local models vs. API costs\",\n",
        "        \"Smart prompt engineering\",\n",
        "        \"Result caching strategies\",\n",
        "        \"Model size vs. accuracy tradeoffs\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "for category, items in production_patterns.items():\n",
        "    print(f\"\\n   üéØ {category}:\")\n",
        "    for item in items:\n",
        "        print(f\"      ‚Ä¢ {item}\")\n",
        "\n",
        "# Example production-ready pattern\n",
        "print(\"\\nüîß Example: Robust LLM Analysis Function\")\n",
        "\n",
        "def robust_llm_analysis(data_summary, max_retries=3, timeout=30):\n",
        "    \"\"\"\n",
        "    Production-ready LLM analysis with error handling\n",
        "    \"\"\"\n",
        "    import time\n",
        "    \n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            # Your LLM call here\n",
        "            # result = llm_chain.invoke({\"data\": data_summary})\n",
        "            \n",
        "            # Simulated response for demo\n",
        "            time.sleep(0.1)  # Simulate processing time\n",
        "            result = f\"Analysis attempt {attempt + 1}: Key insights from data summary\"\n",
        "            \n",
        "            # Validate response quality\n",
        "            if len(result) > 10:  # Basic validation\n",
        "                return {\n",
        "                    'success': True,\n",
        "                    'analysis': result,\n",
        "                    'attempt': attempt + 1\n",
        "                }\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"   Attempt {attempt + 1} failed: {e}\")\n",
        "            if attempt == max_retries - 1:\n",
        "                return {\n",
        "                    'success': False,\n",
        "                    'analysis': 'Automated statistical analysis only',\n",
        "                    'error': str(e)\n",
        "                }\n",
        "            time.sleep(2 ** attempt)  # Exponential backoff\n",
        "\n",
        "# Test the robust function\n",
        "test_result = robust_llm_analysis(\"Sample data summary\")\n",
        "print(f\"   Test result: {test_result}\")\n",
        "\n",
        "print(\"\\nüîß Your turn: Implement production patterns:\")\n",
        "print(\"   1. Add comprehensive logging\")\n",
        "print(\"   2. Implement result caching\")\n",
        "print(\"   3. Add performance monitoring\")\n",
        "print(\"   4. Create configuration management\")\n",
        "print(\"   5. Design automated testing\")\n",
        "\n",
        "print(\"\\n‚úÖ Production considerations complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Workshop Summary & Next Steps\n",
        "\n",
        "Congratulations! You've completed the Week 2 interactive workshop!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üéì WEEK 2 WORKSHOP COMPLETE!\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "print(\"üèÜ What You've Accomplished:\")\n",
        "accomplishments = [\n",
        "    \"‚úÖ Mastered advanced data preprocessing techniques\",\n",
        "    \"‚úÖ Built sophisticated feature engineering pipelines\",\n",
        "    \"‚úÖ Learned LangChain Expression Language (LCEL)\",\n",
        "    \"‚úÖ Set up and used local LLMs with Ollama\",\n",
        "    \"‚úÖ Created hybrid ML + LLM workflows\",\n",
        "    \"‚úÖ Processed text data with NLP techniques\",\n",
        "    \"‚úÖ Built production-ready patterns\"\n",
        "]\n",
        "\n",
        "for achievement in accomplishments:\n",
        "    print(f\"   {achievement}\")\n",
        "\n",
        "print(\"\\nüõ†Ô∏è Key Skills Developed:\")\n",
        "skills = {\n",
        "    \"Data Processing\": [\"Advanced imputation\", \"Feature engineering\", \"Text preprocessing\", \"Pipeline validation\"],\n",
        "    \"LangChain/LLMs\": [\"LCEL syntax\", \"Chain composition\", \"Local model setup\", \"Prompt engineering\"],\n",
        "    \"Integration\": [\"Hybrid pipelines\", \"Error handling\", \"Production patterns\", \"Monitoring strategies\"]\n",
        "}\n",
        "\n",
        "for category, skill_list in skills.items():\n",
        "    print(f\"   üéØ {category}: {', '.join(skill_list)}\")\n",
        "\n",
        "print(\"\\nüöÄ Coming in Week 3:\")\n",
        "week3_topics = [\n",
        "    \"Advanced LangChain patterns and agents\",\n",
        "    \"Vector databases and retrieval systems\",\n",
        "    \"RAG (Retrieval-Augmented Generation)\",\n",
        "    \"Building intelligent applications\",\n",
        "    \"End-to-end AI system deployment\"\n",
        "]\n",
        "\n",
        "for topic in week3_topics:\n",
        "    print(f\"   üîÆ {topic}\")\n",
        "\n",
        "print(\"\\nüí° Practice Recommendations:\")\n",
        "practice_items = [\n",
        "    \"üîÑ Apply preprocessing techniques to your own datasets\",\n",
        "    \"‚öôÔ∏è Experiment with different LLM models and prompts\",\n",
        "    \"üìä Build domain-specific analysis chains\",\n",
        "    \"üèóÔ∏è Create production-ready pipeline templates\",\n",
        "    \"üìö Explore advanced LangChain documentation\"\n",
        "]\n",
        "\n",
        "for item in practice_items:\n",
        "    print(f\"   {item}\")\n",
        "\n",
        "print(\"\\nüìã Self-Study Checklist:\")\n",
        "checklist = [\n",
        "    \"‚ñ° Complete the additional exercises in /exercises/\",\n",
        "    \"‚ñ° Set up additional Ollama models for comparison\",\n",
        "    \"‚ñ° Build a custom preprocessing pipeline for your domain\",\n",
        "    \"‚ñ° Create a LangChain chain for a specific business problem\",\n",
        "    \"‚ñ° Review vector database concepts for Week 3\"\n",
        "]\n",
        "\n",
        "for item in checklist:\n",
        "    print(f\"   {item}\")\n",
        "\n",
        "print(\"\\nüéñÔ∏è Workshop Feedback:\")\n",
        "print(\"   üí≠ What was your favorite part of today's workshop?\")\n",
        "print(\"   ü§î Which concepts need more practice?\")\n",
        "print(\"   üí° What real-world applications are you excited to build?\")\n",
        "\n",
        "print(\"\\nüéâ Excellent work! You're ready for advanced AI applications!\")\n",
        "print(\"üèÜ - INRIVA AI Academy Team\")\n",
        "\n",
        "# Save progress\n",
        "import json\n",
        "progress = {\n",
        "    'workshop': 'week2_interactive',\n",
        "    'completed': True,\n",
        "    'timestamp': pd.Timestamp.now().isoformat(),\n",
        "    'skills_learned': [skill for skill_list in skills.values() for skill in skill_list],\n",
        "    'next_steps': week3_topics\n",
        "}\n",
        "\n",
        "print(f\"\\nüíæ Progress saved: {len(json.dumps(progress))} characters\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
