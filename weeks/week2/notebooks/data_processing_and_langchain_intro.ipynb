{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 2 Workshop: Data Preprocessing and LangChain Introduction\n",
        "\n",
        "Welcome to Week 2! Today we'll master advanced data preprocessing with Metaflow and take our first steps into the world of Large Language Models with LangChain.\n",
        "\n",
        "## üéØ Workshop Objectives\n",
        "\n",
        "By the end of this session, you'll be able to:\n",
        "- Build sophisticated data preprocessing pipelines in Metaflow\n",
        "- Understand and use LangChain Expression Language (LCEL)\n",
        "- Work with local LLMs using Ollama\n",
        "- Create hybrid workflows combining traditional ML with LLM capabilities\n",
        "\n",
        "## üìã Prerequisites Check\n",
        "\n",
        "Let's make sure your environment is ready!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Environment verification for Week 2\n",
        "import sys\n",
        "import subprocess\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def check_environment():\n",
        "    \"\"\"Comprehensive environment check for Week 2\"\"\"\n",
        "    print(\"üîç Week 2 Environment Check\")\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    # Core imports\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        import numpy as np\n",
        "        import matplotlib.pyplot as plt\n",
        "        import seaborn as sns\n",
        "        from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "        from metaflow import FlowSpec, step, Parameter\n",
        "        print(\"‚úÖ Core ML libraries imported successfully\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ùå Core import failed: {e}\")\n",
        "        return False\n",
        "    \n",
        "    # LangChain imports\n",
        "    try:\n",
        "        import langchain\n",
        "        from langchain.schema import BaseOutputParser\n",
        "        from langchain.prompts import PromptTemplate\n",
        "        from langchain_community.llms import Ollama\n",
        "        print(\"‚úÖ LangChain imported successfully\")\n",
        "        print(f\"   LangChain version: {langchain.__version__}\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ùå LangChain import failed: {e}\")\n",
        "        print(\"   Install with: pip install langchain langchain-community\")\n",
        "        return False\n",
        "    \n",
        "    # Check Ollama installation\n",
        "    try:\n",
        "        result = subprocess.run(['ollama', '--version'], \n",
        "                              capture_output=True, text=True, timeout=5)\n",
        "        if result.returncode == 0:\n",
        "            print(\"‚úÖ Ollama is installed\")\n",
        "            print(f\"   Version: {result.stdout.strip()}\")\n",
        "            \n",
        "            # Check for available models\n",
        "            models_result = subprocess.run(['ollama', 'list'], \n",
        "                                         capture_output=True, text=True, timeout=5)\n",
        "            if models_result.returncode == 0:\n",
        "                models = models_result.stdout.strip()\n",
        "                if 'llama' in models.lower() or 'mistral' in models.lower():\n",
        "                    print(\"‚úÖ Local models available\")\n",
        "                else:\n",
        "                    print(\"‚ö†Ô∏è  No models found. Download with: ollama pull llama3.2\")\n",
        "        else:\n",
        "            print(\"‚ùå Ollama command failed\")\n",
        "    except (subprocess.TimeoutExpired, FileNotFoundError):\n",
        "        print(\"‚ùå Ollama not found - install from ollama.com\")\n",
        "        print(\"   This is required for LLM exercises\")\n",
        "    \n",
        "    print(\"\\nüéØ Environment check complete!\")\n",
        "    return True\n",
        "\n",
        "check_environment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Advanced Data Preprocessing with Metaflow\n",
        "\n",
        "Let's start by importing everything we need and loading our datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complete imports for data preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler, MinMaxScaler, RobustScaler,\n",
        "    LabelEncoder, OneHotEncoder\n",
        ")\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from metaflow import FlowSpec, step, Parameter, IncludeFile, catch\n",
        "import re\n",
        "import string\n",
        "from scipy import stats\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"viridis\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "print(\"üìä Data preprocessing environment ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Your Exercise Space\n",
        "\n",
        "Use the cells below to work on the exercises. Feel free to add more cells as needed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise workspace - Add your solutions here!\n",
        "print(\"üíª Ready for your solutions!\")\n",
        "print(\"   Copy one of the exercise prompts above and start coding.\")\n",
        "print(\"   Remember: experimentation is key to learning!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Workshop Complete!\n",
        "\n",
        "You've successfully completed the Week 2 workshop on advanced data preprocessing and LangChain integration!\n",
        "\n",
        "### üèÜ What You've Accomplished:\n",
        "\n",
        "1. **üîß Built sophisticated preprocessing pipelines** with Metaflow\n",
        "2. **ü¶ú Mastered LangChain fundamentals** and LCEL syntax\n",
        "3. **üåä Created hybrid workflows** combining ML + LLM capabilities\n",
        "4. **üìù Processed text data** using modern LLM approaches\n",
        "5. **üéØ Implemented production patterns** for scalable AI systems\n",
        "\n",
        "### üìö Key Takeaways:\n",
        "\n",
        "- **LCEL is powerful**: The `prompt | model | parser` pattern enables flexible chain composition\n",
        "- **Local LLMs matter**: Ollama provides privacy-focused AI capabilities\n",
        "- **Hybrid approaches work**: Combining traditional ML with LLMs creates powerful systems\n",
        "- **Error handling is crucial**: Production systems need robust fallback mechanisms\n",
        "- **Integration patterns**: Metaflow + LangChain = MLOps + LLMOps\n",
        "\n",
        "### üöÄ Next Steps:\n",
        "\n",
        "1. **Complete the exercises** in your own time\n",
        "2. **Experiment with different models** using Ollama\n",
        "3. **Try the advanced patterns** in the resources section\n",
        "4. **Join Friday's showcase** to share your results\n",
        "5. **Prepare for Week 3** - Supervised Learning with Metaflow\n",
        "\n",
        "### üìû Need Help?\n",
        "\n",
        "- **üìÅ Check `/solutions/`** for complete exercise answers\n",
        "- **üí¨ Ask in Google Chat** for quick questions\n",
        "- **üïí Use Friday office hours** for detailed help\n",
        "- **üìñ Review resources** in `/resources/` directory\n",
        "\n",
        "### üéØ Week 3 Preview:\n",
        "\n",
        "Next week we'll dive into supervised learning with Metaflow, building on everything you've learned about data preprocessing and adding sophisticated model training, evaluation, and comparison capabilities.\n",
        "\n",
        "#### üìö **What You'll Learn:**\n",
        "- **ü§ñ Multiple Algorithm Training**: Random Forest, XGBoost, SVM, Logistic Regression\n",
        "- **‚ö° Parallel Processing**: Use `@foreach` to train models simultaneously\n",
        "- **üìä Advanced Evaluation**: ROC curves, precision-recall, feature importance\n",
        "- **üîß Hyperparameter Tuning**: Grid search and Bayesian optimization\n",
        "- **ü¶ú LLM Model Interpretation**: Use LangChain to explain model results\n",
        "- **üìã Cross-Validation**: Robust model validation strategies\n",
        "\n",
        "#### üõ†Ô∏è **Technical Skills:**\n",
        "- Building scalable ML training pipelines\n",
        "- Implementing model comparison frameworks\n",
        "- Creating automated hyperparameter optimization\n",
        "- Integrating LLM explanations for model insights\n",
        "- Deploying model selection workflows\n",
        "\n",
        "#### üéØ **Week 3 Deliverables:**\n",
        "- Multi-algorithm comparison pipeline\n",
        "- Hyperparameter optimization system\n",
        "- LLM-powered model explanation tool\n",
        "- Production-ready model selection workflow\n",
        "\n",
        "**Great work today! You're building real production AI skills! üåü**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}