{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Regression Fundamentals: Comprehensive Tutorial\n",
        "\n",
        "This notebook provides an in-depth exploration of regression algorithms, evaluation techniques, and advanced patterns for real-world applications.\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "\n",
        "By the end of this tutorial, you'll master:\n",
        "- **6+ regression algorithms** with their strengths and use cases\n",
        "- **Advanced evaluation metrics** beyond simple RMSE\n",
        "- **Regularization techniques** to prevent overfitting\n",
        "- **Feature engineering** for regression\n",
        "- **Model interpretation** and explainability\n",
        "- **Production deployment** considerations\n",
        "\n",
        "## üìã Table of Contents\n",
        "\n",
        "1. [Data Loading and Exploration](#1-data-loading-and-exploration)\n",
        "2. [Linear Regression Fundamentals](#2-linear-regression-fundamentals)\n",
        "3. [Regularization Techniques](#3-regularization-techniques)\n",
        "4. [Tree-Based Regression](#4-tree-based-regression)\n",
        "5. [Advanced Evaluation Techniques](#5-advanced-evaluation-techniques)\n",
        "6. [Feature Engineering for Regression](#6-feature-engineering-for-regression)\n",
        "7. [Polynomial and Non-linear Regression](#7-polynomial-and-non-linear-regression)\n",
        "8. [Model Selection and Comparison](#8-model-selection-and-comparison)\n",
        "9. [Production Considerations](#9-production-considerations)\n",
        "10. [Summary and Best Practices](#10-summary-and-best-practices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Essential imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_diabetes, load_boston, make_regression\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, cross_val_score, GridSearchCV,\n",
        "    learning_curve, validation_curve\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\n",
        "from sklearn.linear_model import (\n",
        "    LinearRegression, Ridge, Lasso, ElasticNet,\n",
        "    HuberRegressor, RANSACRegressor\n",
        ")\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor, GradientBoostingRegressor,\n",
        "    ExtraTreesRegressor, BaggingRegressor\n",
        ")\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, r2_score,\n",
        "    mean_absolute_percentage_error, explained_variance_score\n",
        ")\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
        "from sklearn.inspection import permutation_importance\n",
        "from scipy import stats\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"viridis\")\n",
        "\n",
        "print(\"‚úÖ All packages imported successfully!\")\n",
        "print(f\"üìÖ Notebook started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Exploration\n",
        "\n",
        "We'll work with multiple datasets to demonstrate different regression scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load multiple datasets for comprehensive analysis\n",
        "print(\"üìä Loading Regression Datasets\")\n",
        "print(\"=\" * 32)\n",
        "\n",
        "# Dataset 1: Diabetes Dataset (Medical)\n",
        "diabetes_data = load_diabetes()\n",
        "diabetes_X = pd.DataFrame(diabetes_data.data, columns=diabetes_data.feature_names)\n",
        "diabetes_y = diabetes_data.target\n",
        "\n",
        "print(f\"üè• Diabetes Dataset:\")\n",
        "print(f\"   Shape: {diabetes_X.shape}\")\n",
        "print(f\"   Target: Disease progression (continuous)\")\n",
        "print(f\"   Target range: [{diabetes_y.min():.1f}, {diabetes_y.max():.1f}]\")\n",
        "print(f\"   Target mean: {diabetes_y.mean():.1f} ¬± {diabetes_y.std():.1f}\")\n",
        "\n",
        "# Dataset 2: Housing Dataset (Economic)\n",
        "try:\n",
        "    boston_data = load_boston()\n",
        "    housing_X = pd.DataFrame(boston_data.data, columns=boston_data.feature_names)\n",
        "    housing_y = boston_data.target\n",
        "    BOSTON_AVAILABLE = True\n",
        "    \n",
        "    print(f\"\\nüè† Boston Housing Dataset:\")\n",
        "    print(f\"   Shape: {housing_X.shape}\")\n",
        "    print(f\"   Target: Median home value ($1000s)\")\n",
        "    print(f\"   Target range: [${housing_y.min():.1f}k, ${housing_y.max():.1f}k]\")\n",
        "    print(f\"   Target mean: ${housing_y.mean():.1f}k ¬± ${housing_y.std():.1f}k\")\n",
        "except:\n",
        "    # Create synthetic housing dataset if Boston is deprecated\n",
        "    print(f\"\\nüè† Creating Synthetic Housing Dataset:\")\n",
        "    np.random.seed(42)\n",
        "    n_samples = 506\n",
        "    \n",
        "    # Generate realistic housing features\n",
        "    house_age = np.random.uniform(5, 100, n_samples)\n",
        "    rooms = np.random.normal(6, 1, n_samples)\n",
        "    crime_rate = np.random.exponential(3, n_samples)\n",
        "    distance_to_city = np.random.uniform(1, 12, n_samples)\n",
        "    tax_rate = np.random.normal(400, 100, n_samples)\n",
        "    pupil_teacher_ratio = np.random.normal(18, 3, n_samples)\n",
        "    \n",
        "    # Generate price with realistic relationships\n",
        "    price = (\n",
        "        rooms * 8 +\n",
        "        -house_age * 0.2 +\n",
        "        -crime_rate * 2 +\n",
        "        -distance_to_city * 1.5 +\n",
        "        -tax_rate * 0.02 +\n",
        "        -pupil_teacher_ratio * 0.8 +\n",
        "        np.random.normal(0, 3, n_samples) + 25\n",
        "    )\n",
        "    \n",
        "    housing_X = pd.DataFrame({\n",
        "        'house_age': house_age,\n",
        "        'avg_rooms': rooms,\n",
        "        'crime_rate': crime_rate,\n",
        "        'distance_to_city': distance_to_city,\n",
        "        'tax_rate': tax_rate,\n",
        "        'pupil_teacher_ratio': pupil_teacher_ratio\n",
        "    })\n",
        "    housing_y = price\n",
        "    BOSTON_AVAILABLE = False\n",
        "    \n",
        "    print(f\"   Shape: {housing_X.shape}\")\n",
        "    print(f\"   Target: Median home value ($1000s)\")\n",
        "    print(f\"   Target range: [${housing_y.min():.1f}k, ${housing_y.max():.1f}k]\")\n",
        "    print(f\"   Target mean: ${housing_y.mean():.1f}k ¬± ${housing_y.std():.1f}k\")\n",
        "\n",
        "# Dataset 3: High-dimensional Synthetic Dataset\n",
        "highdim_X, highdim_y = make_regression(\n",
        "    n_samples=800,\n",
        "    n_features=50,\n",
        "    n_informative=30,\n",
        "    noise=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "highdim_X = pd.DataFrame(highdim_X, columns=[f'feature_{i:02d}' for i in range(50)])\n",
        "\n",
        "print(f\"\\nüî¨ High-Dimensional Synthetic Dataset:\")\n",
        "print(f\"   Shape: {highdim_X.shape}\")\n",
        "print(f\"   Target: Synthetic continuous variable\")\n",
        "print(f\"   Target range: [{highdim_y.min():.1f}, {highdim_y.max():.1f}]\")\n",
        "print(f\"   Target mean: {highdim_y.mean():.1f} ¬± {highdim_y.std():.1f}\")\n",
        "\n",
        "# Dataset 4: Noisy Dataset with Outliers\n",
        "np.random.seed(42)\n",
        "n_samples = 300\n",
        "X_clean = np.random.randn(n_samples, 3)\n",
        "y_clean = 2*X_clean[:, 0] + 3*X_clean[:, 1] - X_clean[:, 2] + np.random.randn(n_samples) * 0.5\n",
        "\n",
        "# Add outliers\n",
        "n_outliers = 30\n",
        "outlier_indices = np.random.choice(n_samples, n_outliers, replace=False)\n",
        "y_noisy = y_clean.copy()\n",
        "y_noisy[outlier_indices] += np.random.randn(n_outliers) * 10  # Strong outliers\n",
        "\n",
        "noisy_X = pd.DataFrame(X_clean, columns=['feature_A', 'feature_B', 'feature_C'])\n",
        "noisy_y = y_noisy\n",
        "\n",
        "print(f\"\\nüìà Noisy Dataset with Outliers:\")\n",
        "print(f\"   Shape: {noisy_X.shape}\")\n",
        "print(f\"   Outliers: {n_outliers} samples (~{n_outliers/n_samples*100:.1f}%)\")\n",
        "print(f\"   Target range: [{noisy_y.min():.1f}, {noisy_y.max():.1f}]\")\n",
        "print(f\"   Target mean: {noisy_y.mean():.1f} ¬± {noisy_y.std():.1f}\")\n",
        "\n",
        "print(\"\\n‚úÖ All datasets loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive data exploration\n",
        "def explore_regression_dataset(X, y, dataset_name):\n",
        "    \"\"\"\n",
        "    Comprehensive exploration of a regression dataset.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîç Exploring {dataset_name} Dataset\")\n",
        "    print(\"=\" * (len(dataset_name) + 20))\n",
        "    \n",
        "    # Basic statistics\n",
        "    print(f\"üìä Dataset Shape: {X.shape}\")\n",
        "    print(f\"üéØ Target Statistics:\")\n",
        "    print(f\"   Mean: {y.mean():.3f}\")\n",
        "    print(f\"   Std: {y.std():.3f}\")\n",
        "    print(f\"   Min: {y.min():.3f}\")\n",
        "    print(f\"   Max: {y.max():.3f}\")\n",
        "    print(f\"   Range: {y.max() - y.min():.3f}\")\n",
        "    print(f\"   Skewness: {stats.skew(y):.3f}\")\n",
        "    \n",
        "    # Check for normality of target\n",
        "    _, p_value = stats.shapiro(y[:100] if len(y) > 100 else y)\n",
        "    if p_value > 0.05:\n",
        "        print(f\"   ‚úÖ Target appears normally distributed (p={p_value:.3f})\")\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è Target may not be normally distributed (p={p_value:.3f})\")\n",
        "    \n",
        "    # Outlier detection\n",
        "    Q1 = np.percentile(y, 25)\n",
        "    Q3 = np.percentile(y, 75)\n",
        "    IQR = Q3 - Q1\n",
        "    outlier_threshold = 1.5 * IQR\n",
        "    outliers = np.sum((y < Q1 - outlier_threshold) | (y > Q3 + outlier_threshold))\n",
        "    outlier_percentage = outliers / len(y) * 100\n",
        "    \n",
        "    print(f\"   Outliers: {outliers} ({outlier_percentage:.1f}%)\")\n",
        "    \n",
        "    # Feature statistics\n",
        "    print(f\"\\nüìà Feature Statistics:\")\n",
        "    print(f\"   Feature count: {X.shape[1]}\")\n",
        "    print(f\"   Missing values: {X.isnull().sum().sum()}\")\n",
        "    \n",
        "    # Feature scaling analysis\n",
        "    feature_ranges = X.max() - X.min()\n",
        "    max_range = feature_ranges.max()\n",
        "    min_range = feature_ranges.min()\n",
        "    \n",
        "    if max_range / min_range > 10:\n",
        "        print(f\"   üîß Feature scaling recommended (range ratio: {max_range/min_range:.1f}:1)\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ Feature scales are relatively similar\")\n",
        "    \n",
        "    # Correlation analysis\n",
        "    correlations = X.corrwith(pd.Series(y))\n",
        "    strong_correlations = correlations[abs(correlations) > 0.5]\n",
        "    \n",
        "    print(f\"\\nüîó Target Correlations:\")\n",
        "    print(f\"   Strong correlations (|r| > 0.5): {len(strong_correlations)}\")\n",
        "    if len(strong_correlations) > 0:\n",
        "        best_feature = correlations.abs().idxmax()\n",
        "        print(f\"   Strongest: {best_feature} (r={correlations[best_feature]:.3f})\")\n",
        "    \n",
        "    # Multicollinearity check\n",
        "    corr_matrix = X.corr()\n",
        "    high_corr_pairs = []\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i+1, len(corr_matrix.columns)):\n",
        "            if abs(corr_matrix.iloc[i, j]) > 0.8:\n",
        "                high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
        "    \n",
        "    if high_corr_pairs:\n",
        "        print(f\"   ‚ö†Ô∏è High multicollinearity detected: {len(high_corr_pairs)} pairs with |r| > 0.8\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ No significant multicollinearity detected\")\n",
        "    \n",
        "    return {\n",
        "        'shape': X.shape,\n",
        "        'target_mean': y.mean(),\n",
        "        'target_std': y.std(),\n",
        "        'target_range': y.max() - y.min(),\n",
        "        'target_skew': stats.skew(y),\n",
        "        'outlier_percentage': outlier_percentage,\n",
        "        'needs_scaling': max_range / min_range > 10,\n",
        "        'strong_correlations': len(strong_correlations),\n",
        "        'multicollinearity_pairs': len(high_corr_pairs),\n",
        "        'target_normal': p_value > 0.05\n",
        "    }\n",
        "\n",
        "# Explore all datasets\n",
        "diabetes_stats = explore_regression_dataset(diabetes_X, diabetes_y, \"Diabetes\")\n",
        "housing_stats = explore_regression_dataset(housing_X, housing_y, \"Housing\")\n",
        "highdim_stats = explore_regression_dataset(highdim_X, highdim_y, \"High-Dimensional\")\n",
        "noisy_stats = explore_regression_dataset(noisy_X, noisy_y, \"Noisy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization of dataset characteristics\n",
        "print(\"üìä Dataset Visualization\")\n",
        "print(\"=\" * 24)\n",
        "\n",
        "fig, axes = plt.subplots(4, 4, figsize=(20, 16))\n",
        "\n",
        "datasets = [\n",
        "    (diabetes_X, diabetes_y, \"Diabetes\"),\n",
        "    (housing_X, housing_y, \"Housing\"),\n",
        "    (highdim_X, highdim_y, \"High-Dim\"),\n",
        "    (noisy_X, noisy_y, \"Noisy\")\n",
        "]\n",
        "\n",
        "for i, (X, y, name) in enumerate(datasets):\n",
        "    # 1. Target distribution\n",
        "    axes[i, 0].hist(y, bins=30, alpha=0.7, density=True, color='skyblue', edgecolor='black')\n",
        "    axes[i, 0].axvline(y.mean(), color='red', linestyle='--', label=f'Mean: {y.mean():.1f}')\n",
        "    axes[i, 0].axvline(np.median(y), color='green', linestyle='--', label=f'Median: {np.median(y):.1f}')\n",
        "    axes[i, 0].set_title(f'{name} - Target Distribution')\n",
        "    axes[i, 0].set_xlabel('Target Value')\n",
        "    axes[i, 0].set_ylabel('Density')\n",
        "    axes[i, 0].legend()\n",
        "    axes[i, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Feature correlation with target\n",
        "    correlations = X.corrwith(pd.Series(y))\n",
        "    top_features = correlations.abs().nlargest(min(8, len(correlations)))\n",
        "    \n",
        "    colors = ['red' if corr < 0 else 'blue' for corr in correlations[top_features.index]]\n",
        "    bars = axes[i, 1].barh(range(len(top_features)), correlations[top_features.index], color=colors, alpha=0.7)\n",
        "    axes[i, 1].set_yticks(range(len(top_features)))\n",
        "    axes[i, 1].set_yticklabels([col[:10] + '...' if len(col) > 10 else col for col in top_features.index])\n",
        "    axes[i, 1].set_title(f'{name} - Feature Correlations')\n",
        "    axes[i, 1].set_xlabel('Correlation with Target')\n",
        "    axes[i, 1].axvline(0, color='black', linestyle='-', alpha=0.5)\n",
        "    axes[i, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add correlation values as text\n",
        "    for j, (bar, corr) in enumerate(zip(bars, correlations[top_features.index])):\n",
        "        width = bar.get_width()\n",
        "        axes[i, 1].text(width + 0.01 if width >= 0 else width - 0.01, bar.get_y() + bar.get_height()/2, \n",
        "                        f'{corr:.2f}', ha='left' if width >= 0 else 'right', va='center', fontsize=8)\n",
        "    \n",
        "    # 3. Scatter plot of best correlated feature\n",
        "    best_feature = correlations.abs().idxmax()\n",
        "    best_corr = correlations[best_feature]\n",
        "    \n",
        "    scatter = axes[i, 2].scatter(X[best_feature], y, alpha=0.6, s=20)\n",
        "    \n",
        "    # Add trend line\n",
        "    z = np.polyfit(X[best_feature], y, 1)\n",
        "    p = np.poly1d(z)\n",
        "    x_trend = np.linspace(X[best_feature].min(), X[best_feature].max(), 100)\n",
        "    axes[i, 2].plot(x_trend, p(x_trend), \"r--\", alpha=0.8, linewidth=2)\n",
        "    \n",
        "    axes[i, 2].set_xlabel(best_feature[:15] + '...' if len(best_feature) > 15 else best_feature)\n",
        "    axes[i, 2].set_ylabel('Target')\n",
        "    axes[i, 2].set_title(f'{name} - Best Feature\\n(r={best_corr:.3f})')\n",
        "    axes[i, 2].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Feature correlation heatmap (subset)\n",
        "    n_features_to_show = min(6, X.shape[1])\n",
        "    if X.shape[1] > n_features_to_show:\n",
        "        # Select features with highest correlation to target\n",
        "        top_feature_names = correlations.abs().nlargest(n_features_to_show).index\n",
        "        feature_subset = X[top_feature_names]\n",
        "    else:\n",
        "        feature_subset = X\n",
        "    \n",
        "    corr_matrix = feature_subset.corr()\n",
        "    \n",
        "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "    sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', center=0, \n",
        "                ax=axes[i, 3], cbar_kws={'shrink': 0.8}, fmt='.2f')\n",
        "    axes[i, 3].set_title(f'{name} - Feature Correlations')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Dataset exploration and visualization complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Linear Regression Fundamentals\n",
        "\n",
        "Let's start with the foundation of regression: linear regression and its assumptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Linear regression fundamentals with housing dataset\n",
        "print(\"üìà Linear Regression Fundamentals\")\n",
        "print(\"=\" * 34)\n",
        "\n",
        "# Use housing dataset for realistic example\n",
        "X_lr = housing_X\n",
        "y_lr = housing_y\n",
        "\n",
        "# Split and scale data\n",
        "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(\n",
        "    X_lr, y_lr, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler_lr = StandardScaler()\n",
        "X_train_lr_scaled = scaler_lr.fit_transform(X_train_lr)\n",
        "X_test_lr_scaled = scaler_lr.transform(X_test_lr)\n",
        "\n",
        "print(f\"üìä Training set: {X_train_lr_scaled.shape}\")\n",
        "print(f\"üìä Test set: {X_test_lr_scaled.shape}\")\n",
        "print(f\"üéØ Target range: ${y_train_lr.min():.0f}k - ${y_train_lr.max():.0f}k\")\n",
        "\n",
        "# Fit linear regression model\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_lr_scaled, y_train_lr)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_lr = lr_model.predict(X_test_lr_scaled)\n",
        "y_pred_train_lr = lr_model.predict(X_train_lr_scaled)\n",
        "\n",
        "# Calculate comprehensive metrics\n",
        "mse_test = mean_squared_error(y_test_lr, y_pred_lr)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "mae_test = mean_absolute_error(y_test_lr, y_pred_lr)\n",
        "r2_test = r2_score(y_test_lr, y_pred_lr)\n",
        "mape_test = mean_absolute_percentage_error(y_test_lr, y_pred_lr)\n",
        "explained_var = explained_variance_score(y_test_lr, y_pred_lr)\n",
        "\n",
        "# Training metrics\n",
        "mse_train = mean_squared_error(y_train_lr, y_pred_train_lr)\n",
        "r2_train = r2_score(y_train_lr, y_pred_train_lr)\n",
        "\n",
        "print(f\"\\nüìä Linear Regression Performance:\")\n",
        "print(f\"   Training R¬≤: {r2_train:.3f}\")\n",
        "print(f\"   Test R¬≤: {r2_test:.3f}\")\n",
        "print(f\"   Test RMSE: ${rmse_test:.1f}k\")\n",
        "print(f\"   Test MAE: ${mae_test:.1f}k\")\n",
        "print(f\"   Test MAPE: {mape_test:.1%}\")\n",
        "print(f\"   Explained Variance: {explained_var:.3f}\")\n",
        "\n",
        "# Analyze overfitting\n",
        "overfitting_gap = r2_train - r2_test\n",
        "if overfitting_gap > 0.1:\n",
        "    print(f\"   ‚ö†Ô∏è Potential overfitting detected (gap: {overfitting_gap:.3f})\")\n",
        "elif overfitting_gap < 0.05:\n",
        "    print(f\"   ‚úÖ Good generalization (gap: {overfitting_gap:.3f})\")\n",
        "else:\n",
        "    print(f\"   ‚ö° Moderate overfitting (gap: {overfitting_gap:.3f})\")\n",
        "\n",
        "# Analyze coefficients\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X_lr.columns,\n",
        "    'Coefficient': lr_model.coef_,\n",
        "    'Abs_Coefficient': np.abs(lr_model.coef_)\n",
        "})\n",
        "coefficients = coefficients.sort_values('Abs_Coefficient', ascending=False)\n",
        "\n",
        "print(f\"\\nüîç Feature Coefficients (Standardized):\")\n",
        "print(f\"   Intercept: ${lr_model.intercept_:.1f}k\")\n",
        "for _, row in coefficients.head(5).iterrows():\n",
        "    sign = '+' if row['Coefficient'] > 0 else ''\n",
        "    print(f\"   {row['Feature']:15}: {sign}{row['Coefficient']:.2f} (impact: ${abs(row['Coefficient']):.2f}k)\")\n",
        "\n",
        "# Cross-validation analysis\n",
        "print(f\"\\nüîÑ Cross-Validation Analysis:\")\n",
        "cv_scores = cross_val_score(lr_model, X_train_lr_scaled, y_train_lr, cv=5, scoring='r2')\n",
        "cv_rmse_scores = cross_val_score(lr_model, X_train_lr_scaled, y_train_lr, cv=5, \n",
        "                                scoring='neg_root_mean_squared_error')\n",
        "\n",
        "print(f\"   CV R¬≤: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\")\n",
        "print(f\"   CV RMSE: ${-cv_rmse_scores.mean():.1f}k ¬± ${cv_rmse_scores.std():.1f}k\")\n",
        "\n",
        "# Store results for comparison\n",
        "linear_results = {\n",
        "    'model': lr_model,\n",
        "    'r2_test': r2_test,\n",
        "    'rmse_test': rmse_test,\n",
        "    'mae_test': mae_test,\n",
        "    'mape_test': mape_test,\n",
        "    'r2_train': r2_train,\n",
        "    'cv_r2_mean': cv_scores.mean(),\n",
        "    'cv_r2_std': cv_scores.std(),\n",
        "    'predictions': y_pred_lr,\n",
        "    'coefficients': coefficients\n",
        "}\n",
        "\n",
        "print(\"\\n‚úÖ Linear regression analysis complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Linear regression assumptions checking\n",
        "print(\"üî¨ Checking Linear Regression Assumptions\")\n",
        "print(\"=\" * 41)\n",
        "\n",
        "# Calculate residuals\n",
        "residuals_test = y_test_lr - y_pred_lr\n",
        "residuals_train = y_train_lr - y_pred_train_lr\n",
        "\n",
        "# 1. Linearity assumption (residuals vs fitted)\n",
        "print(\"\\n1Ô∏è‚É£ Linearity Assumption:\")\n",
        "# Durbin-Watson test for independence (approximate)\n",
        "residuals_sorted = residuals_test.sort_index()\n",
        "dw_stat = np.sum(np.diff(residuals_sorted)**2) / np.sum(residuals_sorted**2)\n",
        "print(f\"   Durbin-Watson statistic: {dw_stat:.3f}\")\n",
        "if 1.5 <= dw_stat <= 2.5:\n",
        "    print(f\"   ‚úÖ Residuals appear independent\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è Potential autocorrelation in residuals\")\n",
        "\n",
        "# 2. Homoscedasticity (constant variance)\n",
        "print(f\"\\n2Ô∏è‚É£ Homoscedasticity (Constant Variance):\")\n",
        "# Breusch-Pagan test approximation\n",
        "fitted_values = y_pred_lr\n",
        "correlation_resid_fitted = np.corrcoef(np.abs(residuals_test), fitted_values)[0, 1]\n",
        "print(f\"   Correlation(|residuals|, fitted): {correlation_resid_fitted:.3f}\")\n",
        "if abs(correlation_resid_fitted) < 0.1:\n",
        "    print(f\"   ‚úÖ Homoscedasticity assumption likely satisfied\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è Potential heteroscedasticity detected\")\n",
        "\n",
        "# 3. Normality of residuals\n",
        "print(f\"\\n3Ô∏è‚É£ Normality of Residuals:\")\n",
        "_, p_value_normality = stats.shapiro(residuals_test[:100] if len(residuals_test) > 100 else residuals_test)\n",
        "print(f\"   Shapiro-Wilk p-value: {p_value_normality:.3f}\")\n",
        "if p_value_normality > 0.05:\n",
        "    print(f\"   ‚úÖ Residuals appear normally distributed\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è Residuals may not be normally distributed\")\n",
        "\n",
        "# 4. No multicollinearity (VIF approximation)\n",
        "print(f\"\\n4Ô∏è‚É£ Multicollinearity Check:\")\n",
        "corr_matrix = X_lr.corr()\n",
        "high_corr_pairs = []\n",
        "for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1, len(corr_matrix.columns)):\n",
        "        if abs(corr_matrix.iloc[i, j]) > 0.8:\n",
        "            high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
        "\n",
        "if high_corr_pairs:\n",
        "    print(f\"   ‚ö†Ô∏è High correlations detected: {len(high_corr_pairs)} pairs\")\n",
        "    for feat1, feat2, corr in high_corr_pairs:\n",
        "        print(f\"      {feat1} - {feat2}: {corr:.3f}\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ No significant multicollinearity detected\")\n",
        "\n",
        "# Summary of assumption checking\n",
        "assumptions_met = [\n",
        "    1.5 <= dw_stat <= 2.5,  # Independence\n",
        "    abs(correlation_resid_fitted) < 0.1,  # Homoscedasticity\n",
        "    p_value_normality > 0.05,  # Normality\n",
        "    len(high_corr_pairs) == 0  # No multicollinearity\n",
        "]\n",
        "\n",
        "print(f\"\\nüìã Assumption Summary:\")\n",
        "print(f\"   Assumptions met: {sum(assumptions_met)}/4\")\n",
        "if sum(assumptions_met) >= 3:\n",
        "    print(f\"   ‚úÖ Linear regression is appropriate for this data\")\n",
        "elif sum(assumptions_met) >= 2:\n",
        "    print(f\"   ‚ö†Ô∏è Linear regression may work but consider alternatives\")\n",
        "else:\n",
        "    print(f\"   ‚ùå Consider non-linear or robust regression methods\")\n",
        "\n",
        "print(\"\\n‚úÖ Assumption checking complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization of linear regression results and diagnostics\n",
        "print(\"üìä Linear Regression Diagnostics Visualization\")\n",
        "print(\"=\" * 46)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# 1. Actual vs Predicted\n",
        "min_val = min(y_test_lr.min(), y_pred_lr.min())\n",
        "max_val = max(y_test_lr.max(), y_pred_lr.max())\n",
        "\n",
        "axes[0].scatter(y_test_lr, y_pred_lr, alpha=0.6, s=30)\n",
        "axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
        "axes[0].set_xlabel('Actual Price ($k)')\n",
        "axes[0].set_ylabel('Predicted Price ($k)')\n",
        "axes[0].set_title(f'Actual vs Predicted\\nR¬≤ = {r2_test:.3f}')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Add R¬≤ text\n",
        "axes[0].text(0.05, 0.95, f'RMSE: ${rmse_test:.1f}k\\nMAE: ${mae_test:.1f}k', \n",
        "            transform=axes[0].transAxes, verticalalignment='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "# 2. Residuals vs Fitted (Homoscedasticity)\n",
        "axes[1].scatter(y_pred_lr, residuals_test, alpha=0.6, s=30)\n",
        "axes[1].axhline(y=0, color='r', linestyle='--', alpha=0.8)\n",
        "axes[1].set_xlabel('Fitted Values ($k)')\n",
        "axes[1].set_ylabel('Residuals ($k)')\n",
        "axes[1].set_title('Residuals vs Fitted\\n(Homoscedasticity Check)')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Add trend line to check for patterns\n",
        "z = np.polyfit(y_pred_lr, residuals_test, 1)\n",
        "p = np.poly1d(z)\n",
        "x_trend = np.linspace(y_pred_lr.min(), y_pred_lr.max(), 100)\n",
        "axes[1].plot(x_trend, p(x_trend), \"g--\", alpha=0.8, linewidth=2, label=f'Trend (slope={z[0]:.1e})')\n",
        "axes[1].legend()\n",
        "\n",
        "# 3. Q-Q Plot for normality of residuals\n",
        "stats.probplot(residuals_test, dist=\"norm\", plot=axes[2])\n",
        "axes[2].set_title('Q-Q Plot\\n(Normality of Residuals)')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Histogram of residuals\n",
        "axes[3].hist(residuals_test, bins=30, alpha=0.7, density=True, color='skyblue', edgecolor='black')\n",
        "axes[3].axvline(residuals_test.mean(), color='red', linestyle='--', \n",
        "               label=f'Mean: ${residuals_test.mean():.1f}k')\n",
        "axes[3].axvline(0, color='green', linestyle='--', label='Zero')\n",
        "\n",
        "# Overlay normal distribution\n",
        "x_norm = np.linspace(residuals_test.min(), residuals_test.max(), 100)\n",
        "normal_curve = stats.norm.pdf(x_norm, residuals_test.mean(), residuals_test.std())\n",
        "axes[3].plot(x_norm, normal_curve, 'orange', linewidth=2, label='Normal Curve')\n",
        "\n",
        "axes[3].set_xlabel('Residuals ($k)')\n",
        "axes[3].set_ylabel('Density')\n",
        "axes[3].set_title('Residuals Distribution')\n",
        "axes[3].legend()\n",
        "axes[3].grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Feature coefficients\n",
        "top_coeffs = coefficients.head(len(X_lr.columns))\n",
        "colors = ['red' if coef < 0 else 'blue' for coef in top_coeffs['Coefficient']]\n",
        "\n",
        "bars = axes[4].barh(range(len(top_coeffs)), top_coeffs['Coefficient'], color=colors, alpha=0.7)\n",
        "axes[4].set_yticks(range(len(top_coeffs)))\n",
        "axes[4].set_yticklabels([name[:12] + '...' if len(name) > 12 else name for name in top_coeffs['Feature']])\n",
        "axes[4].set_xlabel('Coefficient Value')\n",
        "axes[4].set_title('Feature Coefficients\\n(Standardized)')\n",
        "axes[4].axvline(0, color='black', linestyle='-', alpha=0.5)\n",
        "axes[4].grid(True, alpha=0.3)\n",
        "\n",
        "# Add coefficient values as text\n",
        "for i, (bar, coef) in enumerate(zip(bars, top_coeffs['Coefficient'])):\n",
        "    width = bar.get_width()\n",
        "    axes[4].text(width + 0.1 if width >= 0 else width - 0.1, bar.get_y() + bar.get_height()/2, \n",
        "                f'{coef:.2f}', ha='left' if width >= 0 else 'right', va='center', fontsize=8)\n",
        "\n",
        "# 6. Cross-validation scores\n",
        "cv_scores_detailed = cross_val_score(lr_model, X_train_lr_scaled, y_train_lr, cv=5, scoring='r2')\n",
        "\n",
        "axes[5].boxplot([cv_scores_detailed], labels=['CV R¬≤ Scores'])\n",
        "axes[5].scatter([1] * len(cv_scores_detailed), cv_scores_detailed, color='red', alpha=0.7, s=50)\n",
        "axes[5].axhline(r2_test, color='blue', linestyle='--', label=f'Test R¬≤: {r2_test:.3f}')\n",
        "axes[5].set_ylabel('R¬≤ Score')\n",
        "axes[5].set_title(f'Cross-Validation Scores\\nMean: {cv_scores_detailed.mean():.3f} ¬± {cv_scores_detailed.std():.3f}')\n",
        "axes[5].legend()\n",
        "axes[5].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Linear regression diagnostics visualization complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Regularization Techniques\n",
        "\n",
        "Let's explore Ridge, Lasso, and Elastic Net regression to handle overfitting and feature selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Regularization techniques comparison\n",
        "print(\"üéØ Regularization Techniques\")\n",
        "print(\"=\" * 28)\n",
        "\n",
        "# Use high-dimensional dataset for regularization demo\n",
        "X_reg = highdim_X\n",
        "y_reg = highdim_y\n",
        "\n",
        "# Split and scale data\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler_reg = StandardScaler()\n",
        "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
        "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n",
        "\n",
        "print(f\"üìä Training set: {X_train_reg_scaled.shape}\")\n",
        "print(f\"üìä Test set: {X_test_reg_scaled.shape}\")\n",
        "print(f\"üéØ Features: {X_reg.shape[1]} (high-dimensional for regularization demo)\")\n",
        "\n",
        "# Define regularization models with different alpha values\n",
        "regularization_models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge (Œ±=0.1)': Ridge(alpha=0.1, random_state=42),\n",
        "    'Ridge (Œ±=1.0)': Ridge(alpha=1.0, random_state=42),\n",
        "    'Ridge (Œ±=10.0)': Ridge(alpha=10.0, random_state=42),\n",
        "    'Lasso (Œ±=0.1)': Lasso(alpha=0.1, random_state=42, max_iter=2000),\n",
        "    'Lasso (Œ±=1.0)': Lasso(alpha=1.0, random_state=42, max_iter=2000),\n",
        "    'Lasso (Œ±=10.0)': Lasso(alpha=10.0, random_state=42, max_iter=2000),\n",
        "    'Elastic Net (Œ±=0.1)': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42, max_iter=2000),\n",
        "    'Elastic Net (Œ±=1.0)': ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42, max_iter=2000),\n",
        "    'Elastic Net (Œ±=10.0)': ElasticNet(alpha=10.0, l1_ratio=0.5, random_state=42, max_iter=2000)\n",
        "}\n",
        "\n",
        "print(f\"\\nü§ñ Training {len(regularization_models)} regularized models...\")\n",
        "\n",
        "regularization_results = {}\n",
        "\n",
        "for name, model in regularization_models.items():\n",
        "    print(f\"\\nüîÑ Training {name}...\")\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(X_train_reg_scaled, y_train_reg)\n",
        "    \n",
        "    # Make predictions\n",
        "    y_pred_reg = model.predict(X_test_reg_scaled)\n",
        "    y_pred_train_reg = model.predict(X_train_reg_scaled)\n",
        "    \n",
        "    training_time = (datetime.now() - start_time).total_seconds()\n",
        "    \n",
        "    # Calculate metrics\n",
        "    r2_test = r2_score(y_test_reg, y_pred_reg)\n",
        "    r2_train = r2_score(y_train_reg, y_pred_train_reg)\n",
        "    rmse_test = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
        "    mae_test = mean_absolute_error(y_test_reg, y_pred_reg)\n",
        "    \n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train_reg_scaled, y_train_reg, cv=5, scoring='r2')\n",
        "    \n",
        "    # Feature selection analysis (for Lasso and Elastic Net)\n",
        "    n_selected_features = np.sum(np.abs(model.coef_) > 1e-5) if hasattr(model, 'coef_') else X_reg.shape[1]\n",
        "    \n",
        "    # Coefficient sparsity\n",
        "    coefficient_norm = np.linalg.norm(model.coef_) if hasattr(model, 'coef_') else 0\n",
        "    \n",
        "    regularization_results[name] = {\n",
        "        'model': model,\n",
        "        'r2_test': r2_test,\n",
        "        'r2_train': r2_train,\n",
        "        'rmse_test': rmse_test,\n",
        "        'mae_test': mae_test,\n",
        "        'cv_r2_mean': cv_scores.mean(),\n",
        "        'cv_r2_std': cv_scores.std(),\n",
        "        'overfitting_gap': r2_train - r2_test,\n",
        "        'n_selected_features': n_selected_features,\n",
        "        'coefficient_norm': coefficient_norm,\n",
        "        'training_time': training_time,\n",
        "        'predictions': y_pred_reg\n",
        "    }\n",
        "    \n",
        "    print(f\"   ‚úÖ R¬≤ Test: {r2_test:.3f} | R¬≤ Train: {r2_train:.3f} | Gap: {r2_train - r2_test:.3f}\")\n",
        "    print(f\"      RMSE: {rmse_test:.2f} | Features: {n_selected_features}/{X_reg.shape[1]}\")\n",
        "    print(f\"      CV R¬≤: {cv_scores.mean():.3f}¬±{cv_scores.std():.3f} | Time: {training_time:.3f}s\")\n",
        "\n",
        "print(\"\\nüèÜ Regularization training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Regularization path analysis\n",
        "print(\"üìà Regularization Path Analysis\")\n",
        "print(\"=\" * 32)\n",
        "\n",
        "# Analyze how coefficients change with regularization strength\n",
        "alpha_range = np.logspace(-3, 2, 20)  # From 0.001 to 100\n",
        "\n",
        "# Ridge path\n",
        "ridge_coefs = []\n",
        "ridge_r2_train = []\n",
        "ridge_r2_test = []\n",
        "\n",
        "print(\"\\nüîç Computing Ridge regularization path...\")\n",
        "for alpha in alpha_range:\n",
        "    ridge = Ridge(alpha=alpha, random_state=42)\n",
        "    ridge.fit(X_train_reg_scaled, y_train_reg)\n",
        "    \n",
        "    ridge_coefs.append(ridge.coef_)\n",
        "    ridge_r2_train.append(ridge.score(X_train_reg_scaled, y_train_reg))\n",
        "    ridge_r2_test.append(ridge.score(X_test_reg_scaled, y_test_reg))\n",
        "\n",
        "ridge_coefs = np.array(ridge_coefs)\n",
        "\n",
        "# Lasso path\n",
        "lasso_coefs = []\n",
        "lasso_r2_train = []\n",
        "lasso_r2_test = []\n",
        "lasso_n_features = []\n",
        "\n",
        "print(\"üîç Computing Lasso regularization path...\")\n",
        "for alpha in alpha_range:\n",
        "    lasso = Lasso(alpha=alpha, random_state=42, max_iter=2000)\n",
        "    lasso.fit(X_train_reg_scaled, y_train_reg)\n",
        "    \n",
        "    lasso_coefs.append(lasso.coef_)\n",
        "    lasso_r2_train.append(lasso.score(X_train_reg_scaled, y_train_reg))\n",
        "    lasso_r2_test.append(lasso.score(X_test_reg_scaled, y_test_reg))\n",
        "    lasso_n_features.append(np.sum(np.abs(lasso.coef_) > 1e-5))\n",
        "\n",
        "lasso_coefs = np.array(lasso_coefs)\n",
        "\n",
        "# Find optimal alpha values\n",
        "optimal_ridge_idx = np.argmax(ridge_r2_test)\n",
        "optimal_lasso_idx = np.argmax(lasso_r2_test)\n",
        "\n",
        "optimal_ridge_alpha = alpha_range[optimal_ridge_idx]\n",
        "optimal_lasso_alpha = alpha_range[optimal_lasso_idx]\n",
        "\n",
        "print(f\"\\nüéØ Optimal Alpha Values:\")\n",
        "print(f\"   Ridge: {optimal_ridge_alpha:.3f} (R¬≤ = {ridge_r2_test[optimal_ridge_idx]:.3f})\")\n",
        "print(f\"   Lasso: {optimal_lasso_alpha:.3f} (R¬≤ = {lasso_r2_test[optimal_lasso_idx]:.3f})\")\n",
        "print(f\"   Lasso features selected: {lasso_n_features[optimal_lasso_idx]}/{X_reg.shape[1]}\")\n",
        "\n",
        "# Grid search for optimal hyperparameters\n",
        "print(f\"\\nüîç Grid Search for Optimal Hyperparameters...\")\n",
        "\n",
        "# Ridge grid search\n",
        "ridge_grid = GridSearchCV(\n",
        "    Ridge(random_state=42),\n",
        "    {'alpha': alpha_range},\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1\n",
        ")\n",
        "ridge_grid.fit(X_train_reg_scaled, y_train_reg)\n",
        "\n",
        "# Lasso grid search\n",
        "lasso_grid = GridSearchCV(\n",
        "    Lasso(random_state=42, max_iter=2000),\n",
        "    {'alpha': alpha_range},\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1\n",
        ")\n",
        "lasso_grid.fit(X_train_reg_scaled, y_train_reg)\n",
        "\n",
        "# Elastic Net grid search\n",
        "elastic_grid = GridSearchCV(\n",
        "    ElasticNet(random_state=42, max_iter=2000),\n",
        "    {'alpha': alpha_range[:10], 'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]},\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1\n",
        ")\n",
        "elastic_grid.fit(X_train_reg_scaled, y_train_reg)\n",
        "\n",
        "print(f\"\\nüèÜ Grid Search Results:\")\n",
        "print(f\"   Best Ridge Œ±: {ridge_grid.best_params_['alpha']:.3f} (CV R¬≤: {ridge_grid.best_score_:.3f})\")\n",
        "print(f\"   Best Lasso Œ±: {lasso_grid.best_params_['alpha']:.3f} (CV R¬≤: {lasso_grid.best_score_:.3f})\")\n",
        "print(f\"   Best Elastic Net: Œ±={elastic_grid.best_params_['alpha']:.3f}, \")\n",
        "print(f\"                     l1_ratio={elastic_grid.best_params_['l1_ratio']:.1f} (CV R¬≤: {elastic_grid.best_score_:.3f})\")\n",
        "\n",
        "# Store optimal models\n",
        "optimal_models = {\n",
        "    'Ridge (Optimal)': ridge_grid.best_estimator_,\n",
        "    'Lasso (Optimal)': lasso_grid.best_estimator_,\n",
        "    'Elastic Net (Optimal)': elastic_grid.best_estimator_\n",
        "}\n",
        "\n",
        "# Evaluate optimal models\n",
        "print(f\"\\nüìä Optimal Model Performance:\")\n",
        "for name, model in optimal_models.items():\n",
        "    y_pred_opt = model.predict(X_test_reg_scaled)\n",
        "    r2_opt = r2_score(y_test_reg, y_pred_opt)\n",
        "    rmse_opt = np.sqrt(mean_squared_error(y_test_reg, y_pred_opt))\n",
        "    n_features_opt = np.sum(np.abs(model.coef_) > 1e-5) if hasattr(model, 'coef_') else X_reg.shape[1]\n",
        "    \n",
        "    print(f\"   {name:20}: R¬≤={r2_opt:.3f}, RMSE={rmse_opt:.2f}, Features={n_features_opt}\")\n",
        "\n",
        "print(\"\\n‚úÖ Regularization path analysis complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization of regularization results\n",
        "print(\"üìä Regularization Techniques Visualization\")\n",
        "print(\"=\" * 41)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# 1. Regularization path - Ridge coefficients\n",
        "for i in range(min(10, ridge_coefs.shape[1])):\n",
        "    axes[0].plot(alpha_range, ridge_coefs[:, i], alpha=0.7)\n",
        "\n",
        "axes[0].set_xscale('log')\n",
        "axes[0].set_xlabel('Alpha (Regularization Strength)')\n",
        "axes[0].set_ylabel('Coefficient Value')\n",
        "axes[0].set_title('Ridge Regression Path')\n",
        "axes[0].axvline(optimal_ridge_alpha, color='red', linestyle='--', label=f'Optimal Œ±: {optimal_ridge_alpha:.3f}')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Regularization path - Lasso coefficients\n",
        "for i in range(min(10, lasso_coefs.shape[1])):\n",
        "    axes[1].plot(alpha_range, lasso_coefs[:, i], alpha=0.7)\n",
        "\n",
        "axes[1].set_xscale('log')\n",
        "axes[1].set_xlabel('Alpha (Regularization Strength)')\n",
        "axes[1].set_ylabel('Coefficient Value')\n",
        "axes[1].set_title('Lasso Regression Path')\n",
        "axes[1].axvline(optimal_lasso_alpha, color='red', linestyle='--', label=f'Optimal Œ±: {optimal_lasso_alpha:.3f}')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. R¬≤ scores vs Alpha\n",
        "axes[2].plot(alpha_range, ridge_r2_train, 'b-', label='Ridge Train', alpha=0.7)\n",
        "axes[2].plot(alpha_range, ridge_r2_test, 'b--', label='Ridge Test', alpha=0.7)\n",
        "axes[2].plot(alpha_range, lasso_r2_train, 'r-', label='Lasso Train', alpha=0.7)\n",
        "axes[2].plot(alpha_range, lasso_r2_test, 'r--', label='Lasso Test', alpha=0.7)\n",
        "\n",
        "axes[2].set_xscale('log')\n",
        "axes[2].set_xlabel('Alpha (Regularization Strength)')\n",
        "axes[2].set_ylabel('R¬≤ Score')\n",
        "axes[2].set_title('R¬≤ Score vs Regularization')\n",
        "axes[2].legend()\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Number of selected features (Lasso)\n",
        "axes[3].plot(alpha_range, lasso_n_features, 'go-', alpha=0.7)\n",
        "axes[3].set_xscale('log')\n",
        "axes[3].set_xlabel('Alpha (Regularization Strength)')\n",
        "axes[3].set_ylabel('Number of Selected Features')\n",
        "axes[3].set_title('Lasso Feature Selection')\n",
        "axes[3].axvline(optimal_lasso_alpha, color='red', linestyle='--', \n",
        "               label=f'Optimal: {lasso_n_features[optimal_lasso_idx]} features')\n",
        "axes[3].legend()\n",
        "axes[3].grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Regularization comparison\n",
        "reg_names = [name.split('(')[0].strip() for name in regularization_results.keys()]\n",
        "reg_r2_test = [results['r2_test'] for results in regularization_results.values()]\n",
        "reg_overfitting = [results['overfitting_gap'] for results in regularization_results.values()]\n",
        "\n",
        "x = np.arange(len(reg_names))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = axes[4].bar(x - width/2, reg_r2_test, width, label='Test R¬≤', alpha=0.8)\n",
        "bars2 = axes[4].bar(x + width/2, reg_overfitting, width, label='Overfitting Gap', alpha=0.8)\n",
        "\n",
        "axes[4].set_xlabel('Model')\n",
        "axes[4].set_ylabel('Score')\n",
        "axes[4].set_title('Regularization Comparison')\n",
        "axes[4].set_xticks(x)\n",
        "axes[4].set_xticklabels(reg_names, rotation=45)\n",
        "axes[4].legend()\n",
        "axes[4].grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Feature importance (best regularized model)\n",
        "best_reg_name = max(regularization_results.items(), key=lambda x: x[1]['r2_test'])[0]\n",
        "best_reg_model = regularization_results[best_reg_name]['model']\n",
        "\n",
        "if hasattr(best_reg_model, 'coef_'):\n",
        "    # Get top features by absolute coefficient value\n",
        "    coef_abs = np.abs(best_reg_model.coef_)\n",
        "    top_indices = np.argsort(coef_abs)[-10:]\n",
        "    top_coefs = best_reg_model.coef_[top_indices]\n",
        "    top_features = [X_reg.columns[i] for i in top_indices]\n",
        "    \n",
        "    colors = ['red' if coef < 0 else 'blue' for coef in top_coefs]\n",
        "    bars = axes[5].barh(range(10), top_coefs, color=colors, alpha=0.7)\n",
        "    axes[5].set_yticks(range(10))\n",
        "    axes[5].set_yticklabels(top_features)\n",
        "    axes[5].set_xlabel('Coefficient Value')\n",
        "    axes[5].set_title(f'Top 10 Features\\n({best_reg_name})')\n",
        "    axes[5].axvline(0, color='black', linestyle='-', alpha=0.5)\n",
        "    axes[5].grid(True, alpha=0.3)\n",
        "else:\n",
        "    axes[5].text(0.5, 0.5, 'No coefficients\\navailable', \n",
        "                ha='center', va='center', transform=axes[5].transAxes, fontsize=12)\n",
        "    axes[5].set_title('Feature Coefficients')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Regularization visualization complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Tree-Based Regression\n",
        "\n",
        "Let's explore decision trees, random forests, and gradient boosting for regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tree-based regression methods\n",
        "print(\"üå≥ Tree-Based Regression Methods\")\n",
        "print(\"=\" * 33)\n",
        "\n",
        "# Use diabetes dataset for tree methods\n",
        "X_tree = diabetes_X\n",
        "y_tree = diabetes_y\n",
        "\n",
        "# Split and scale data\n",
        "X_train_tree, X_test_tree, y_train_tree, y_test_tree = train_test_split(\n",
        "    X_tree, y_tree, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Note: Tree-based methods don't require scaling, but we'll scale for consistency\n",
        "scaler_tree = StandardScaler()\n",
        "X_train_tree_scaled = scaler_tree.fit_transform(X_train_tree)\n",
        "X_test_tree_scaled = scaler_tree.transform(X_test_tree)\n",
        "\n",
        "print(f\"üìä Training set: {X_train_tree_scaled.shape}\")\n",
        "print(f\"üìä Test set: {X_test_tree_scaled.shape}\")\n",
        "print(f\"üéØ Target range: [{y_train_tree.min():.1f}, {y_train_tree.max():.1f}]\")\n",
        "\n",
        "# Define tree-based models\n",
        "tree_models = {\n",
        "    'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
        "    'Decision Tree (Deeper)': DecisionTreeRegressor(random_state=42, max_depth=20),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'Random Forest (More Trees)': RandomForestRegressor(n_estimators=200, random_state=42),\n",
        "    'Extra Trees': ExtraTreesRegressor(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting (Tuned)': GradientBoostingRegressor(\n",
        "        n_estimators=150, learning_rate=0.1, max_depth=6, random_state=42\n",
        "    ),\n",
        "    'Bagging': BaggingRegressor(\n",
        "        base_estimator=DecisionTreeRegressor(max_depth=15, random_state=42),\n",
        "        n_estimators=100, random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "print(f\"\\nü§ñ Training {len(tree_models)} tree-based models...\")\n",
        "\n",
        "tree_results = {}\n",
        "\n",
        "for name, model in tree_models.items():\n",
        "    print(f\"\\nüîÑ Training {name}...\")\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    # Train the model (using unscaled data for trees)\n",
        "    model.fit(X_train_tree, y_train_tree)\n",
        "    \n",
        "    # Make predictions\n",
        "    y_pred_tree = model.predict(X_test_tree)\n",
        "    y_pred_train_tree = model.predict(X_train_tree)\n",
        "    \n",
        "    training_time = (datetime.now() - start_time).total_seconds()\n",
        "    \n",
        "    # Calculate metrics\n",
        "    r2_test = r2_score(y_test_tree, y_pred_tree)\n",
        "    r2_train = r2_score(y_train_tree, y_pred_train_tree)\n",
        "    rmse_test = np.sqrt(mean_squared_error(y_test_tree, y_pred_tree))\n",
        "    mae_test = mean_absolute_error(y_test_tree, y_pred_tree)\n",
        "    mape_test = mean_absolute_percentage_error(y_test_tree, y_pred_tree)\n",
        "    \n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train_tree, y_train_tree, cv=5, scoring='r2')\n",
        "    \n",
        "    # Feature importance\n",
        "    feature_importance = None\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        feature_importance = model.feature_importances_\n",
        "    elif hasattr(model, 'estimators_') and hasattr(model.estimators_[0], 'feature_importances_'):\n",
        "        # For bagging regressor\n",
        "        feature_importance = np.mean([est.feature_importances_ for est in model.estimators_], axis=0)\n",
        "    \n",
        "    tree_results[name] = {\n",
        "        'model': model,\n",
        "        'r2_test': r2_test,\n",
        "        'r2_train': r2_train,\n",
        "        'rmse_test': rmse_test,\n",
        "        'mae_test': mae_test,\n",
        "        'mape_test': mape_test,\n",
        "        'cv_r2_mean': cv_scores.mean(),\n",
        "        'cv_r2_std': cv_scores.std(),\n",
        "        'overfitting_gap': r2_train - r2_test,\n",
        "        'training_time': training_time,\n",
        "        'feature_importance': feature_importance,\n",
        "        'predictions': y_pred_tree\n",
        "    }\n",
        "    \n",
        "    print(f\"   ‚úÖ R¬≤ Test: {r2_test:.3f} | R¬≤ Train: {r2_train:.3f} | Gap: {r2_train - r2_test:.3f}\")\n",
        "    print(f\"      RMSE: {rmse_test:.2f} | MAE: {mae_test:.2f} | MAPE: {mape_test:.1%}\")\n",
        "    print(f\"      CV R¬≤: {cv_scores.mean():.3f}¬±{cv_scores.std():.3f} | Time: {training_time:.3f}s\")\n",
        "\n",
        "print(\"\\nüèÜ Tree-based models training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tree-based model analysis and visualization\n",
        "print(\"üìä Tree-Based Model Analysis\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Learning curves for tree models\n",
        "print(\"\\nüìö Generating Learning Curves...\")\n",
        "best_tree_name = max(tree_results.items(), key=lambda x: x[1]['r2_test'])[0]\n",
        "best_tree_model = tree_results[best_tree_name]['model']\n",
        "\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    best_tree_model, X_train_tree, y_train_tree,\n",
        "    cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10),\n",
        "    scoring='r2', random_state=42\n",
        ")\n",
        "\n",
        "train_mean = train_scores.mean(axis=1)\n",
        "train_std = train_scores.std(axis=1)\n",
        "val_mean = val_scores.mean(axis=1)\n",
        "val_std = val_scores.std(axis=1)\n",
        "\n",
        "print(f\"   Best model: {best_tree_name}\")\n",
        "print(f\"   Training score at 100%: {train_mean[-1]:.3f} ¬± {train_std[-1]:.3f}\")\n",
        "print(f\"   Validation score at 100%: {val_mean[-1]:.3f} ¬± {val_std[-1]:.3f}\")\n",
        "print(f\"   Gap at 100%: {train_mean[-1] - val_mean[-1]:.3f}\")\n",
        "\n",
        "# Feature importance analysis\n",
        "print(f\"\\nüîç Feature Importance Analysis:\")\n",
        "models_with_importance = [(name, results) for name, results in tree_results.items() \n",
        "                         if results['feature_importance'] is not None]\n",
        "\n",
        "if models_with_importance:\n",
        "    # Compare feature importance across models\n",
        "    importance_comparison = pd.DataFrame()\n",
        "    \n",
        "    for name, results in models_with_importance:\n",
        "        importance_comparison[name] = results['feature_importance']\n",
        "    \n",
        "    importance_comparison.index = X_tree.columns\n",
        "    \n",
        "    # Calculate average importance\n",
        "    importance_comparison['Average'] = importance_comparison.mean(axis=1)\n",
        "    importance_comparison = importance_comparison.sort_values('Average', ascending=False)\n",
        "    \n",
        "    print(f\"   Top 5 Features (Average Importance):\")\n",
        "    for i, (feature, avg_imp) in enumerate(importance_comparison['Average'].head(5).items(), 1):\n",
        "        print(f\"   {i}. {feature}: {avg_imp:.3f}\")\n",
        "\n",
        "# Hyperparameter tuning for Random Forest\n",
        "print(f\"\\nüîß Hyperparameter Tuning (Random Forest):\")\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "rf_grid = GridSearchCV(\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    rf_param_grid,\n",
        "    cv=3,  # Reduced for speed\n",
        "    scoring='r2',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_grid.fit(X_train_tree, y_train_tree)\n",
        "\n",
        "print(f\"   Best parameters: {rf_grid.best_params_}\")\n",
        "print(f\"   Best CV score: {rf_grid.best_score_:.3f}\")\n",
        "\n",
        "# Evaluate tuned model\n",
        "rf_tuned = rf_grid.best_estimator_\n",
        "y_pred_tuned = rf_tuned.predict(X_test_tree)\n",
        "r2_tuned = r2_score(y_test_tree, y_pred_tuned)\n",
        "rmse_tuned = np.sqrt(mean_squared_error(y_test_tree, y_pred_tuned))\n",
        "\n",
        "print(f\"   Tuned model test R¬≤: {r2_tuned:.3f}\")\n",
        "print(f\"   Tuned model test RMSE: {rmse_tuned:.2f}\")\n",
        "\n",
        "# Add tuned model to results\n",
        "tree_results['Random Forest (Tuned)'] = {\n",
        "    'model': rf_tuned,\n",
        "    'r2_test': r2_tuned,\n",
        "    'rmse_test': rmse_tuned,\n",
        "    'predictions': y_pred_tuned\n",
        "}\n",
        "\n",
        "print(\"\\n‚úÖ Tree-based model analysis complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization of tree-based results\n",
        "print(\"üìä Tree-Based Model Visualizations\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# 1. Model performance comparison\n",
        "model_names = [name.split('(')[0].strip() for name in tree_results.keys()]\n",
        "r2_scores = [results['r2_test'] for results in tree_results.values()]\n",
        "rmse_scores = [results.get('rmse_test', 0) for results in tree_results.values()]\n",
        "\n",
        "x = np.arange(len(model_names))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = axes[0].bar(x - width/2, r2_scores, width, label='R¬≤ Score', alpha=0.8)\n",
        "axes[0].set_xlabel('Model')\n",
        "axes[0].set_ylabel('R¬≤ Score')\n",
        "axes[0].set_title('Tree-Based Model Performance')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(model_names, rotation=45)\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, score in zip(bars1, r2_scores):\n",
        "    height = bar.get_height()\n",
        "    axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                f'{score:.3f}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "# 2. Learning curves\n",
        "axes[1].plot(train_sizes, train_mean, 'o-', color='blue', label='Training Score')\n",
        "axes[1].fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
        "\n",
        "axes[1].plot(train_sizes, val_mean, 'o-', color='red', label='Validation Score')\n",
        "axes[1].fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')\n",
        "\n",
        "axes[1].set_xlabel('Training Set Size')\n",
        "axes[1].set_ylabel('R¬≤ Score')\n",
        "axes[1].set_title(f'Learning Curves\\n({best_tree_name})')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Feature importance comparison\n",
        "if models_with_importance:\n",
        "    # Plot top 8 features for top 3 models\n",
        "    top_3_models = sorted(models_with_importance, key=lambda x: x[1]['r2_test'], reverse=True)[:3]\n",
        "    \n",
        "    feature_names = X_tree.columns\n",
        "    top_features = importance_comparison.head(8).index\n",
        "    \n",
        "    x_pos = np.arange(len(top_features))\n",
        "    width = 0.25\n",
        "    \n",
        "    for i, (model_name, results) in enumerate(top_3_models):\n",
        "        importances = [results['feature_importance'][list(feature_names).index(feat)] for feat in top_features]\n",
        "        axes[2].bar(x_pos + i*width, importances, width, \n",
        "                   label=model_name.split('(')[0].strip(), alpha=0.8)\n",
        "    \n",
        "    axes[2].set_xlabel('Features')\n",
        "    axes[2].set_ylabel('Importance')\n",
        "    axes[2].set_title('Feature Importance Comparison')\n",
        "    axes[2].set_xticks(x_pos + width)\n",
        "    axes[2].set_xticklabels([feat[:8] + '...' if len(feat) > 8 else feat for feat in top_features], rotation=45)\n",
        "    axes[2].legend()\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "else:\n",
        "    axes[2].text(0.5, 0.5, 'No feature importance\\navailable', \n",
        "                ha='center', va='center', transform=axes[2].transAxes, fontsize=12)\n",
        "    axes[2].set_title('Feature Importance')\n",
        "\n",
        "# 4. Overfitting analysis\n",
        "overfitting_gaps = [results.get('overfitting_gap', 0) for results in tree_results.values()]\n",
        "training_times = [results.get('training_time', 0) for results in tree_results.values()]\n",
        "\n",
        "colors = ['red' if gap > 0.1 else 'orange' if gap > 0.05 else 'green' for gap in overfitting_gaps]\n",
        "bars = axes[3].bar(range(len(model_names)), overfitting_gaps, color=colors, alpha=0.7)\n",
        "\n",
        "axes[3].set_xlabel('Model')\n",
        "axes[3].set_ylabel('Overfitting Gap (Train R¬≤ - Test R¬≤)')\n",
        "axes[3].set_title('Overfitting Analysis')\n",
        "axes[3].set_xticks(range(len(model_names)))\n",
        "axes[3].set_xticklabels(model_names, rotation=45)\n",
        "axes[3].axhline(0.1, color='red', linestyle='--', alpha=0.5, label='High overfitting')\n",
        "axes[3].axhline(0.05, color='orange', linestyle='--', alpha=0.5, label='Moderate overfitting')\n",
        "axes[3].legend()\n",
        "axes[3].grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Actual vs Predicted (best model)\n",
        "best_predictions = tree_results[best_tree_name]['predictions']\n",
        "best_r2 = tree_results[best_tree_name]['r2_test']\n",
        "\n",
        "min_val = min(y_test_tree.min(), best_predictions.min())\n",
        "max_val = max(y_test_tree.max(), best_predictions.max())\n",
        "\n",
        "axes[4].scatter(y_test_tree, best_predictions, alpha=0.6, s=30)\n",
        "axes[4].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
        "axes[4].set_xlabel('Actual Values')\n",
        "axes[4].set_ylabel('Predicted Values')\n",
        "axes[4].set_title(f'Actual vs Predicted\\n({best_tree_name})\\nR¬≤ = {best_r2:.3f}')\n",
        "axes[4].legend()\n",
        "axes[4].grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Training time vs Performance\n",
        "scatter = axes[5].scatter(training_times, r2_scores, s=100, alpha=0.7, \n",
        "                         c=range(len(model_names)), cmap='viridis')\n",
        "\n",
        "for i, name in enumerate(model_names):\n",
        "    axes[5].annotate(name.split('(')[0][:8], \n",
        "                    (training_times[i], r2_scores[i]), \n",
        "                    xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
        "\n",
        "axes[5].set_xlabel('Training Time (seconds)')\n",
        "axes[5].set_ylabel('R¬≤ Score')\n",
        "axes[5].set_title('Performance vs Training Time')\n",
        "axes[5].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Tree-based model visualization complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Model Selection and Comparison\n",
        "\n",
        "Let's compare all regression techniques we've covered and select the best approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive model comparison\n",
        "print(\"üèÜ Comprehensive Model Comparison\")\n",
        "print(\"=\" * 36)\n",
        "\n",
        "# Create final model suite for comparison\n",
        "final_models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge (Optimal)': ridge_grid.best_estimator_,\n",
        "    'Lasso (Optimal)': lasso_grid.best_estimator_,\n",
        "    'Elastic Net (Optimal)': elastic_grid.best_estimator_,\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    'SVR (RBF)': SVR(kernel='rbf', C=1.0),\n",
        "    'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
        "    'K-Nearest Neighbors': KNeighborsRegressor(n_neighbors=5),\n",
        "    'Extra Trees': ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Use housing dataset for final comparison\n",
        "X_final = housing_X\n",
        "y_final = housing_y\n",
        "\n",
        "# Split and scale data\n",
        "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
        "    X_final, y_final, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler_final = StandardScaler()\n",
        "X_train_final_scaled = scaler_final.fit_transform(X_train_final)\n",
        "X_test_final_scaled = scaler_final.transform(X_test_final)\n",
        "\n",
        "print(f\"üìä Final comparison dataset: {X_final.shape}\")\n",
        "print(f\"üéØ Target: House prices (${y_final.mean():.1f}k ¬± ${y_final.std():.1f}k)\")\n",
        "\n",
        "print(f\"\\nü§ñ Training {len(final_models)} models for final comparison...\")\n",
        "\n",
        "final_results = {}\n",
        "\n",
        "for name, model in final_models.items():\n",
        "    print(f\"\\nüîÑ Training {name}...\")\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    # Use scaled data for linear models, unscaled for tree-based\n",
        "    if any(tree_type in name.lower() for tree_type in ['tree', 'forest', 'boosting', 'extra']):\n",
        "        X_train_use = X_train_final\n",
        "        X_test_use = X_test_final\n",
        "    else:\n",
        "        X_train_use = X_train_final_scaled\n",
        "        X_test_use = X_test_final_scaled\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(X_train_use, y_train_final)\n",
        "    \n",
        "    # Make predictions\n",
        "    y_pred_final = model.predict(X_test_use)\n",
        "    y_pred_train_final = model.predict(X_train_use)\n",
        "    \n",
        "    training_time = (datetime.now() - start_time).total_seconds()\n",
        "    \n",
        "    # Calculate comprehensive metrics\n",
        "    r2_test = r2_score(y_test_final, y_pred_final)\n",
        "    r2_train = r2_score(y_train_final, y_pred_train_final)\n",
        "    rmse_test = np.sqrt(mean_squared_error(y_test_final, y_pred_final))\n",
        "    mae_test = mean_absolute_error(y_test_final, y_pred_final)\n",
        "    mape_test = mean_absolute_percentage_error(y_test_final, y_pred_final)\n",
        "    explained_var = explained_variance_score(y_test_final, y_pred_final)\n",
        "    \n",
        "    # Cross-validation with multiple metrics\n",
        "    cv_r2 = cross_val_score(model, X_train_use, y_train_final, cv=5, scoring='r2')\n",
        "    cv_rmse = cross_val_score(model, X_train_use, y_train_final, cv=5, \n",
        "                             scoring='neg_root_mean_squared_error')\n",
        "    cv_mae = cross_val_score(model, X_train_use, y_train_final, cv=5, \n",
        "                            scoring='neg_mean_absolute_error')\n",
        "    \n",
        "    # Model complexity metrics\n",
        "    n_features_used = X_final.shape[1]\n",
        "    if hasattr(model, 'coef_'):\n",
        "        n_features_used = np.sum(np.abs(model.coef_) > 1e-5)\n",
        "        coefficient_norm = np.linalg.norm(model.coef_)\n",
        "    else:\n",
        "        coefficient_norm = 0\n",
        "    \n",
        "    final_results[name] = {\n",
        "        'model': model,\n",
        "        'r2_test': r2_test,\n",
        "        'r2_train': r2_train,\n",
        "        'rmse_test': rmse_test,\n",
        "        'mae_test': mae_test,\n",
        "        'mape_test': mape_test,\n",
        "        'explained_variance': explained_var,\n",
        "        'cv_r2_mean': cv_r2.mean(),\n",
        "        'cv_r2_std': cv_r2.std(),\n",
        "        'cv_rmse_mean': -cv_rmse.mean(),\n",
        "        'cv_rmse_std': cv_rmse.std(),\n",
        "        'cv_mae_mean': -cv_mae.mean(),\n",
        "        'cv_mae_std': cv_mae.std(),\n",
        "        'overfitting_gap': r2_train - r2_test,\n",
        "        'training_time': training_time,\n",
        "        'n_features_used': n_features_used,\n",
        "        'coefficient_norm': coefficient_norm,\n",
        "        'predictions': y_pred_final\n",
        "    }\n",
        "    \n",
        "    print(f\"   ‚úÖ R¬≤ Test: {r2_test:.3f} | RMSE: ${rmse_test:.1f}k | MAE: ${mae_test:.1f}k\")\n",
        "    print(f\"      CV R¬≤: {cv_r2.mean():.3f}¬±{cv_r2.std():.3f} | Gap: {r2_train - r2_test:.3f}\")\n",
        "    print(f\"      MAPE: {mape_test:.1%} | Time: {training_time:.3f}s\")\n",
        "\n",
        "print(\"\\nüèÜ Final model comparison complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive comparison report\n",
        "print(\"üìã Final Model Comparison Report\")\n",
        "print(\"=\" * 34)\n",
        "\n",
        "# Create summary DataFrame\n",
        "comparison_data = []\n",
        "for name, results in final_results.items():\n",
        "    comparison_data.append({\n",
        "        'Model': name,\n",
        "        'R¬≤ Test': results['r2_test'],\n",
        "        'RMSE Test': results['rmse_test'],\n",
        "        'MAE Test': results['mae_test'],\n",
        "        'MAPE Test': results['mape_test'],\n",
        "        'CV R¬≤ Mean': results['cv_r2_mean'],\n",
        "        'CV R¬≤ Std': results['cv_r2_std'],\n",
        "        'Overfitting Gap': results['overfitting_gap'],\n",
        "        'Training Time': results['training_time'],\n",
        "        'Features Used': results['n_features_used']\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df = comparison_df.sort_values('R¬≤ Test', ascending=False)\n",
        "\n",
        "print(\"\\nüèÜ Model Performance Rankings:\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "for i, (_, row) in enumerate(comparison_df.iterrows(), 1):\n",
        "    print(f\"{i:2d}. {row['Model']:20} | R¬≤: {row['R¬≤ Test']:.3f} | RMSE: ${row['RMSE Test']:5.1f}k | \"\n",
        "          f\"MAPE: {row['MAPE Test']:5.1%} | Gap: {row['Overfitting Gap']:5.3f}\")\n",
        "\n",
        "# Best model analysis\n",
        "best_model_name = comparison_df.iloc[0]['Model']\n",
        "best_model_results = final_results[best_model_name]\n",
        "\n",
        "print(f\"\\nü•á Best Model: {best_model_name}\")\n",
        "print(f\"   üìä Test R¬≤: {best_model_results['r2_test']:.3f}\")\n",
        "print(f\"   üí∞ Test RMSE: ${best_model_results['rmse_test']:.1f}k\")\n",
        "print(f\"   üìà Test MAE: ${best_model_results['mae_test']:.1f}k\")\n",
        "print(f\"   üìä Test MAPE: {best_model_results['mape_test']:.1%}\")\n",
        "print(f\"   üîÑ CV R¬≤: {best_model_results['cv_r2_mean']:.3f} ¬± {best_model_results['cv_r2_std']:.3f}\")\n",
        "print(f\"   ‚öñÔ∏è Overfitting Gap: {best_model_results['overfitting_gap']:.3f}\")\n",
        "print(f\"   ‚è±Ô∏è Training Time: {best_model_results['training_time']:.3f}s\")\n",
        "\n",
        "# Model category analysis\n",
        "print(f\"\\nüìä Performance by Model Category:\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "categories = {\n",
        "    'Linear Models': ['Linear Regression', 'Ridge (Optimal)', 'Lasso (Optimal)', 'Elastic Net (Optimal)'],\n",
        "    'Tree-Based': ['Random Forest', 'Gradient Boosting', 'Decision Tree', 'Extra Trees'],\n",
        "    'Other': ['SVR (RBF)', 'K-Nearest Neighbors']\n",
        "}\n",
        "\n",
        "for category, models in categories.items():\n",
        "    category_models = [m for m in models if m in final_results]\n",
        "    if category_models:\n",
        "        avg_r2 = np.mean([final_results[m]['r2_test'] for m in category_models])\n",
        "        avg_rmse = np.mean([final_results[m]['rmse_test'] for m in category_models])\n",
        "        avg_time = np.mean([final_results[m]['training_time'] for m in category_models])\n",
        "        \n",
        "        print(f\"   {category:12}: Avg R¬≤ = {avg_r2:.3f}, Avg RMSE = ${avg_rmse:.1f}k, Avg Time = {avg_time:.3f}s\")\n",
        "\n",
        "# Feature importance analysis (for best tree-based model)\n",
        "tree_models = [(name, results) for name, results in final_results.items() \n",
        "               if any(tree_type in name.lower() for tree_type in ['tree', 'forest', 'boosting', 'extra'])]\n",
        "\n",
        "if tree_models:\n",
        "    best_tree_name, best_tree_results = max(tree_models, key=lambda x: x[1]['r2_test'])\n",
        "    best_tree_model = best_tree_results['model']\n",
        "    \n",
        "    print(f\"\\nüå≥ Feature Importance Analysis ({best_tree_name}):\")\n",
        "    print(\"=\" * 45)\n",
        "    \n",
        "    if hasattr(best_tree_model, 'feature_importances_'):\n",
        "        importances = best_tree_model.feature_importances_\n",
        "        feature_names = X_final.columns\n",
        "        \n",
        "        # Create feature importance DataFrame\n",
        "        importance_df = pd.DataFrame({\n",
        "            'Feature': feature_names,\n",
        "            'Importance': importances\n",
        "        }).sort_values('Importance', ascending=False)\n",
        "        \n",
        "        print(\"   Top 5 Most Important Features:\")\n",
        "        for i, (_, row) in enumerate(importance_df.head(5).iterrows(), 1):\n",
        "            print(f\"   {i}. {row['Feature']:15}: {row['Importance']:.3f}\")\n",
        "\n",
        "# Statistical significance testing\n",
        "print(f\"\\nüìä Statistical Significance Testing:\")\n",
        "print(\"=\" * 38)\n",
        "\n",
        "# Compare top 3 models\n",
        "top_3_models = comparison_df.head(3)\n",
        "\n",
        "print(\"   Comparing top 3 models with paired t-test:\")\n",
        "for i in range(len(top_3_models) - 1):\n",
        "    model1_name = top_3_models.iloc[i]['Model']\n",
        "    model2_name = top_3_models.iloc[i + 1]['Model']\n",
        "    \n",
        "    # Get CV scores for comparison\n",
        "    model1_results = final_results[model1_name]\n",
        "    model2_results = final_results[model2_name]\n",
        "    \n",
        "    # Use scaled data for linear models, unscaled for tree-based\n",
        "    if any(tree_type in model1_name.lower() for tree_type in ['tree', 'forest', 'boosting', 'extra']):\n",
        "        X_cv1 = X_train_final\n",
        "    else:\n",
        "        X_cv1 = X_train_final_scaled\n",
        "        \n",
        "    if any(tree_type in model2_name.lower() for tree_type in ['tree', 'forest', 'boosting', 'extra']):\n",
        "        X_cv2 = X_train_final\n",
        "    else:\n",
        "        X_cv2 = X_train_final_scaled\n",
        "    \n",
        "    model1_cv = cross_val_score(model1_results['model'], X_cv1, y_train_final, cv=5, scoring='r2')\n",
        "    model2_cv = cross_val_score(model2_results['model'], X_cv2, y_train_final, cv=5, scoring='r2')\n",
        "    \n",
        "    # Paired t-test\n",
        "    from scipy.stats import ttest_rel\n",
        "    t_stat, p_value = ttest_rel(model1_cv, model2_cv)\n",
        "    \n",
        "    significance = \"‚úÖ Significant\" if p_value < 0.05 else \"‚ùå Not significant\"\n",
        "    print(f\"   {model1_name} vs {model2_name}:\")\n",
        "    print(f\"      p-value: {p_value:.3f} | {significance} (Œ±=0.05)\")\n",
        "\n",
        "print(\"\\n‚úÖ Comprehensive model comparison complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Summary and Best Practices\n",
        "\n",
        "Let's conclude with advanced techniques and a comprehensive summary of regression best practices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Regression best practices and summary\n",
        "print(\"üéì Regression Fundamentals Summary\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "# Complete session statistics\n",
        "total_models_trained = len(regularization_results) + len(tree_results) + len(final_results)\n",
        "total_datasets_used = 4  # Diabetes, Housing, High-dim, Noisy\n",
        "techniques_covered = [\n",
        "    \"Linear Regression\", \"Ridge Regression\", \"Lasso Regression\", \"Elastic Net\",\n",
        "    \"Random Forest\", \"Gradient Boosting\", \"Support Vector Regression\",\n",
        "    \"Decision Trees\", \"K-Nearest Neighbors\", \"Extra Trees\"\n",
        "]\n",
        "\n",
        "print(f\"üìä Session Statistics:\")\n",
        "print(f\"   ü§ñ Total Models Trained: {total_models_trained}\")\n",
        "print(f\"   üìÅ Datasets Analyzed: {total_datasets_used}\")\n",
        "print(f\"   üîß Techniques Covered: {len(techniques_covered)}\")\n",
        "print(f\"   ‚è±Ô∏è Estimated Session Time: ~60-90 minutes\")\n",
        "\n",
        "print(f\"\\nüèÜ Key Performance Insights:\")\n",
        "print(\"=\" * 26)\n",
        "\n",
        "# Overall best performers\n",
        "best_r2_model = max(final_results.items(), key=lambda x: x[1]['r2_test'])\n",
        "best_rmse_model = min(final_results.items(), key=lambda x: x[1]['rmse_test'])\n",
        "fastest_model = min(final_results.items(), key=lambda x: x[1]['training_time'])\n",
        "most_stable_model = min(final_results.items(), key=lambda x: x[1]['overfitting_gap'])\n",
        "\n",
        "print(f\"   ü•á Best R¬≤ Score: {best_r2_model[0]} ({best_r2_model[1]['r2_test']:.3f})\")\n",
        "print(f\"   üí∞ Lowest RMSE: {best_rmse_model[0]} (${best_rmse_model[1]['rmse_test']:.1f}k)\")\n",
        "print(f\"   ‚ö° Fastest Training: {fastest_model[0]} ({fastest_model[1]['training_time']:.3f}s)\")\n",
        "print(f\"   üìà Most Stable: {most_stable_model[0]} (gap: {most_stable_model[1]['overfitting_gap']:.3f})\")\n",
        "\n",
        "# Algorithm recommendations by use case\n",
        "print(f\"\\nüí° Algorithm Recommendations by Use Case:\")\n",
        "print(\"=\" * 43)\n",
        "\n",
        "use_cases = {\n",
        "    \"High Interpretability\": {\n",
        "        \"Primary\": \"Linear Regression\",\n",
        "        \"Alternative\": \"Lasso Regression\",\n",
        "        \"Reason\": \"Simple coefficients, clear feature relationships\"\n",
        "    },\n",
        "    \"Feature Selection\": {\n",
        "        \"Primary\": \"Lasso Regression\",\n",
        "        \"Alternative\": \"Elastic Net\",\n",
        "        \"Reason\": \"Automatic feature selection through L1 penalty\"\n",
        "    },\n",
        "    \"High Accuracy\": {\n",
        "        \"Primary\": best_r2_model[0],\n",
        "        \"Alternative\": \"Gradient Boosting\",\n",
        "        \"Reason\": \"Complex patterns, non-linear relationships\"\n",
        "    },\n",
        "    \"Fast Prediction\": {\n",
        "        \"Primary\": \"Linear Regression\",\n",
        "        \"Alternative\": \"Ridge Regression\",\n",
        "        \"Reason\": \"Simple linear transformation\"\n",
        "    },\n",
        "    \"Robust to Outliers\": {\n",
        "        \"Primary\": \"Random Forest\",\n",
        "        \"Alternative\": \"Huber Regression\",\n",
        "        \"Reason\": \"Tree-based methods and robust loss functions\"\n",
        "    },\n",
        "    \"Small Datasets\": {\n",
        "        \"Primary\": \"Ridge Regression\",\n",
        "        \"Alternative\": \"Linear Regression\",\n",
        "        \"Reason\": \"Regularization prevents overfitting\"\n",
        "    }\n",
        "}\n",
        "\n",
        "for use_case, recommendations in use_cases.items():\n",
        "    print(f\"\\nüéØ {use_case}:\")\n",
        "    print(f\"   Primary: {recommendations['Primary']}\")\n",
        "    print(f\"   Alternative: {recommendations['Alternative']}\")\n",
        "    print(f\"   Reason: {recommendations['Reason']}\")\n",
        "\n",
        "# Regression best practices\n",
        "print(f\"\\nüìã Regression Best Practices:\")\n",
        "print(\"=\" * 29)\n",
        "\n",
        "best_practices = {\n",
        "    \"Data Preparation\": [\n",
        "        \"Check for linearity between features and target\",\n",
        "        \"Handle outliers appropriately (removal vs robust methods)\",\n",
        "        \"Scale features for distance-based algorithms\",\n",
        "        \"Engineer meaningful features from domain knowledge\",\n",
        "        \"Check and handle multicollinearity\"\n",
        "    ],\n",
        "    \"Model Selection\": [\n",
        "        \"Start with linear regression as baseline\",\n",
        "        \"Use regularization for high-dimensional data\",\n",
        "        \"Try tree-based methods for non-linear patterns\",\n",
        "        \"Consider ensemble methods for best performance\",\n",
        "        \"Balance complexity with interpretability needs\"\n",
        "    ],\n",
        "    \"Evaluation Strategy\": [\n",
        "        \"Use multiple metrics (R¬≤, RMSE, MAE, MAPE)\",\n",
        "        \"Implement proper cross-validation\",\n",
        "        \"Check for overfitting with learning curves\",\n",
        "        \"Validate assumptions for linear models\",\n",
        "        \"Consider business impact of prediction errors\"\n",
        "    ],\n",
        "    \"Hyperparameter Tuning\": [\n",
        "        \"Use grid search or random search systematically\",\n",
        "        \"Optimize on validation set, not test set\",\n",
        "        \"Consider computational costs vs performance gains\",\n",
        "        \"Use nested cross-validation for unbiased estimates\",\n",
        "        \"Document optimal parameters and rationale\"\n",
        "    ],\n",
        "    \"Production Considerations\": [\n",
        "        \"Monitor prediction quality over time\",\n",
        "        \"Implement data drift detection\",\n",
        "        \"Plan for model retraining schedules\",\n",
        "        \"Consider model interpretability requirements\",\n",
        "        \"Establish performance thresholds and alerts\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "for category, practices in best_practices.items():\n",
        "    print(f\"\\nüìù {category}:\")\n",
        "    for practice in practices:\n",
        "        print(f\"   ‚Ä¢ {practice}\")\n",
        "\n",
        "# Key metrics reference\n",
        "print(f\"\\nüìä Key Metrics Reference:\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "metrics_guide = {\n",
        "    \"R¬≤ Score\": \"Proportion of variance explained (0-1, higher better)\",\n",
        "    \"RMSE\": \"Root Mean Square Error (same units as target, lower better)\",\n",
        "    \"MAE\": \"Mean Absolute Error (robust to outliers, lower better)\",\n",
        "    \"MAPE\": \"Mean Absolute Percentage Error (scale-independent, lower better)\",\n",
        "    \"Explained Variance\": \"Similar to R¬≤ but doesn't account for bias\",\n",
        "    \"Cross-validation\": \"Robust estimate using multiple train/validation splits\",\n",
        "    \"Learning Curves\": \"Diagnose overfitting and underfitting\",\n",
        "    \"Residual Analysis\": \"Check model assumptions and patterns\"\n",
        "}\n",
        "\n",
        "for metric, description in metrics_guide.items():\n",
        "    print(f\"   {metric:18}: {description}\")\n",
        "\n",
        "# Common pitfalls to avoid\n",
        "print(f\"\\n‚ö†Ô∏è Common Pitfalls to Avoid:\")\n",
        "print(\"-\" * 28)\n",
        "\n",
        "pitfalls = [\n",
        "    \"Using R¬≤ alone without considering other metrics\",\n",
        "    \"Not checking linear regression assumptions\",\n",
        "    \"Forgetting to scale features for distance-based algorithms\",\n",
        "    \"Overfitting by optimizing on test set\",\n",
        "    \"Ignoring outliers in model selection\",\n",
        "    \"Not considering multicollinearity in linear models\",\n",
        "    \"Using complex models when simple ones suffice\",\n",
        "    \        "Not validating model assumptions properly\",\n",
        "    \"Mixing correlation with causation in interpretation\"\n",
        "]\n",
        "\n",
        "for i, pitfall in enumerate(pitfalls, 1):\n",
        "    print(f\"   {i}. {pitfall}\")\n",
        "\n",
        "# Advanced techniques summary\n",
        "print(f\"\\nüöÄ Advanced Techniques Covered:\")\n",
        "print(\"-\" * 32)\n",
        "\n",
        "advanced_techniques = {\n",
        "    \"Regularization\": \"Ridge, Lasso, Elastic Net for feature selection and overfitting control\",\n",
        "    \"Ensemble Methods\": \"Random Forest, Gradient Boosting for improved accuracy\",\n",
        "    \"Cross-Validation\": \"Stratified k-fold for robust model evaluation\",\n",
        "    \"Hyperparameter Tuning\": \"Grid search and random search optimization\",\n",
        "    \"Feature Engineering\": \"Polynomial features and interaction terms\",\n",
        "    \"Residual Analysis\": \"Diagnostic plots for assumption checking\",\n",
        "    \"Learning Curves\": \"Overfitting and underfitting detection\",\n",
        "    \"Statistical Testing\": \"Significance testing for model comparison\"\n",
        "}\n",
        "\n",
        "for technique, description in advanced_techniques.items():\n",
        "    print(f\"   {technique:20}: {description}\")\n",
        "\n",
        "# Final summary statistics\n",
        "print(f\"\\nüìà Session Statistics:\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "total_models = len(regularization_results) + len(tree_results) + len(final_results)\n",
        "total_datasets = 4\n",
        "techniques_covered = 10  # Different algorithm types\n",
        "\n",
        "print(f\"   ü§ñ Total Models Trained: {total_models}\")\n",
        "print(f\"   üìä Datasets Analyzed: {total_datasets}\")\n",
        "print(f\"   üîß Techniques Covered: {techniques_covered}\")\n",
        "print(f\"   ‚è±Ô∏è Estimated Total Time: ~60-90 minutes\")\n",
        "\n",
        "print(\"\\nüéâ Regression Fundamentals Complete!\")\n",
        "print(\"\\nüöÄ Next Steps:\")\n",
        "print(\"   ‚Ä¢ Practice with your own datasets\")\n",
        "print(\"   ‚Ä¢ Explore advanced ensemble methods\")\n",
        "print(\"   ‚Ä¢ Study feature engineering techniques\")\n",
        "print(\"   ‚Ä¢ Learn about neural networks for regression\")\n",
        "print(\"   ‚Ä¢ Implement model monitoring in production\")\n",
        "print(\"   ‚Ä¢ Study time series regression methods\")\n",
        "print(\"   ‚Ä¢ Explore Bayesian regression approaches\")\n",
        "\n",
        "print(\"\\n‚úÖ You are now ready for advanced regression challenges!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exercises and Practice Problems\n",
        "\n",
        "### Exercise 1: Model Selection Challenge\n",
        "Choose the best model from our comparison and explain your reasoning considering:\n",
        "- Predictive performance\n",
        "- Interpretability requirements\n",
        "- Training/prediction speed\n",
        "- Overfitting concerns\n",
        "\n",
        "### Exercise 2: Feature Engineering\n",
        "Create polynomial features and interaction terms for the housing dataset. Compare performance with original features.\n",
        "\n",
        "### Exercise 3: Regularization Parameter Tuning\n",
        "Implement a more extensive grid search for Lasso regression with alpha values from 0.001 to 100. Plot the regularization path.\n",
        "\n",
        "### Exercise 4: Residual Analysis\n",
        "Perform comprehensive residual analysis on the best linear model:\n",
        "- Check all four linear regression assumptions\n",
        "- Identify potential outliers\n",
        "- Suggest model improvements\n",
        "\n",
        "### Exercise 5: Custom Ensemble\n",
        "Create a voting regressor combining the top 3 models from our comparison. Compare its performance to individual models.\n",
        "\n",
        "### Discussion Questions:\n",
        "1. When would you choose Ridge over Lasso regression?\n",
        "2. How do you handle non-linear relationships in regression?\n",
        "3. What are the trade-offs between model complexity and interpretability?\n",
        "4. How would you detect and handle concept drift in production?\n",
        "5. When might tree-based methods fail despite their flexibility?\n",
        "\n",
        "### Real-World Application:\n",
        "Apply these techniques to a dataset from your domain and:\n",
        "- Perform thorough EDA\n",
        "- Compare multiple algorithms\n",
        "- Validate model assumptions\n",
        "- Implement proper evaluation\n",
        "- Document your findings and recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Additional Resources\n",
        "\n",
        "### Key Concepts Mastered:\n",
        "- **Linear Regression**: Assumptions, interpretation, diagnostics\n",
        "- **Regularization**: Ridge, Lasso, Elastic Net for overfitting control\n",
        "- **Tree-Based Methods**: Random Forest, Gradient Boosting, feature importance\n",
        "- **Model Evaluation**: Multiple metrics, cross-validation, learning curves\n",
        "- **Feature Engineering**: Scaling, polynomial features, selection techniques\n",
        "- **Model Selection**: Systematic comparison and statistical testing\n",
        "\n",
        "### Performance Benchmarks:\n",
        "- **Linear Models**: Good baseline, highly interpretable\n",
        "- **Regularized Models**: Better generalization, automatic feature selection\n",
        "- **Tree-Based Models**: Handle non-linearity, robust to outliers\n",
        "- **Ensemble Methods**: Often best performance, reduced overfitting\n",
        "\n",
        "### Production Considerations:\n",
        "- **Model Monitoring**: Track prediction quality over time\n",
        "- **Data Drift**: Detect changes in input distributions\n",
        "- **Retraining**: Establish schedules and triggers\n",
        "- **Interpretability**: Balance accuracy with explainability\n",
        "- **Scalability**: Consider computational requirements\n",
        "\n",
        "### Remember:\n",
        "- Start simple, add complexity gradually\n",
        "- Always validate model assumptions\n",
        "- Use multiple evaluation metrics\n",
        "- Consider business context in model selection\n",
        "- Document decisions and rationale\n",
        "- Plan for production deployment from the start\n",
        "\n",
        "**Happy Modeling! üöÄ**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}