{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 Workshop - Complete Solutions\n",
    "\n",
    "This notebook contains complete solutions and examples from the Week 1 workshop.\n",
    "Use this as a reference for understanding the complete workflow.\n",
    "\n",
    "## Workshop Progression\n",
    "1. Environment verification\n",
    "2. Metaflow fundamentals\n",
    "3. Data exploration with pandas\n",
    "4. Visualization techniques\n",
    "5. Complete ML pipeline\n",
    "\n",
    "**Note**: This is a reference solution. Your implementation may vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Complete Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete import setup for the workshop\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine, load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    precision_recall_curve, roc_curve, roc_auc_score\n",
    ")\n",
    "from metaflow import FlowSpec, step, Parameter, catch\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"âœ… All packages imported successfully!\")\n",
    "print(\"ðŸŽ¯ Environment ready for complete workshop solutions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Complete Data Exploration Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_data_exploration(dataset_name='wine'):\n",
    "    \"\"\"\n",
    "    Complete data exploration function demonstrating all techniques\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ” Complete Data Exploration: {dataset_name.title()} Dataset\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load dataset\n",
    "    if dataset_name == 'wine':\n",
    "        data = load_wine()\n",
    "    elif dataset_name == 'iris':\n",
    "        data = load_iris()\n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        data = load_breast_cancer()\n",
    "    else:\n",
    "        raise ValueError(\"Dataset must be 'wine', 'iris', or 'breast_cancer'\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "    df['target'] = data.target\n",
    "    \n",
    "    # 1. Basic Information\n",
    "    print(\"ðŸ“Š Basic Dataset Information:\")\n",
    "    print(f\"   Shape: {df.shape}\")\n",
    "    print(f\"   Features: {len(data.feature_names)}\")\n",
    "    print(f\"   Classes: {len(data.target_names)} - {data.target_names}\")\n",
    "    print(f\"   Memory Usage: {df.memory_usage().sum() / 1024:.1f} KB\")\n",
    "    \n",
    "    # 2. Data Quality Assessment\n",
    "    print(\"\\nðŸ” Data Quality:\")\n",
    "    missing_vals = df.isnull().sum().sum()\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"   Missing values: {missing_vals}\")\n",
    "    print(f\"   Duplicate rows: {duplicates}\")\n",
    "    \n",
    "    # 3. Class Distribution\n",
    "    print(\"\\nðŸŽ¯ Target Analysis:\")\n",
    "    class_counts = df['target'].value_counts().sort_index()\n",
    "    class_balance = class_counts.min() / class_counts.max()\n",
    "    print(f\"   Class distribution: {class_counts.values}\")\n",
    "    print(f\"   Class balance ratio: {class_balance:.3f}\")\n",
    "    \n",
    "    # 4. Feature Statistics\n",
    "    numeric_features = df.select_dtypes(include=[np.number]).drop('target', axis=1)\n",
    "    print(\"\\nðŸ“ˆ Feature Statistics:\")\n",
    "    print(f\"   Mean range: {numeric_features.mean().min():.2f} - {numeric_features.mean().max():.2f}\")\n",
    "    print(f\"   Std range: {numeric_features.std().min():.2f} - {numeric_features.std().max():.2f}\")\n",
    "    \n",
    "    # 5. Correlation Analysis\n",
    "    correlations = numeric_features.corrwith(df['target']).abs().sort_values(ascending=False)\n",
    "    print(\"\\nðŸ”— Top 5 Features by Target Correlation:\")\n",
    "    for i, (feature, corr) in enumerate(correlations.head(5).items(), 1):\n",
    "        print(f\"   {i}. {feature}: {corr:.3f}\")\n",
    "    \n",
    "    # 6. Feature Correlations\n",
    "    corr_matrix = numeric_features.corr()\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "                high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "    \n",
    "    print(f\"\\nðŸ”— High Correlation Pairs (|r| > 0.7): {len(high_corr_pairs)}\")\n",
    "    for feat1, feat2, corr in high_corr_pairs[:3]:  # Show top 3\n",
    "        print(f\"   {feat1} â†” {feat2}: {corr:.3f}\")\n",
    "    \n",
    "    return df, {\n",
    "        'class_balance': class_balance,\n",
    "        'top_features': correlations.head(5).index.tolist(),\n",
    "        'high_correlations': len(high_corr_pairs),\n",
    "        'data_quality_score': (missing_vals == 0) + (duplicates == 0) + (class_balance > 0.7) + (len(high_corr_pairs) < 5)\n",
    "    }\n",
    "\n",
    "# Demonstrate with wine dataset\n",
    "df, analysis = complete_data_exploration('wine')\n",
    "print(f\"\\nâœ… Analysis complete! Data quality score: {analysis['data_quality_score']}/4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Complete Visualization Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_visualization(df, target_col='target'):\n",
    "    \"\"\"\n",
    "    Create a comprehensive visualization dashboard\n",
    "    \"\"\"\n",
    "    print(\"ðŸŽ¨ Creating Comprehensive Visualization Dashboard\")\n",
    "    \n",
    "    # Setup figure\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
    "    fig.suptitle('Complete Data Analysis Dashboard', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).drop(target_col, axis=1)\n",
    "    target_correlations = numeric_cols.corrwith(df[target_col]).abs().sort_values(ascending=False)\n",
    "    top_features = target_correlations.head(5).index\n",
    "    \n",
    "    # 1. Target distribution\n",
    "    df[target_col].value_counts().plot(kind='bar', ax=axes[0, 0], color='skyblue')\n",
    "    axes[0, 0].set_title('Target Distribution')\n",
    "    axes[0, 0].set_xlabel('Class')\n",
    "    axes[0, 0].set_ylabel('Count')\n",
    "    \n",
    "    # 2. Top feature distribution\n",
    "    top_feature = top_features[0]\n",
    "    df[top_feature].hist(bins=20, ax=axes[0, 1], alpha=0.7, color='lightcoral')\n",
    "    axes[0, 1].axvline(df[top_feature].mean(), color='red', linestyle='--', label='Mean')\n",
    "    axes[0, 1].set_title(f'{top_feature} Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # 3. Feature correlation with target\n",
    "    target_correlations.head(8).plot(kind='barh', ax=axes[0, 2], color='green')\n",
    "    axes[0, 2].set_title('Feature-Target Correlations')\n",
    "    axes[0, 2].set_xlabel('Absolute Correlation')\n",
    "    \n",
    "    # 4. Scatter plot of top 2 features\n",
    "    scatter = axes[1, 0].scatter(df[top_features[0]], df[top_features[1]], \n",
    "                               c=df[target_col], cmap='viridis', alpha=0.7)\n",
    "    axes[1, 0].set_xlabel(top_features[0])\n",
    "    axes[1, 0].set_ylabel(top_features[1])\n",
    "    axes[1, 0].set_title('Top Features Scatter Plot')\n",
    "    plt.colorbar(scatter, ax=axes[1, 0])\n",
    "    \n",
    "    # 5. Box plot by class\n",
    "    df.boxplot(column=top_feature, by=target_col, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title(f'{top_feature} by Class')\n",
    "    \n",
    "    # 6. Correlation heatmap\n",
    "    corr_subset = df[top_features].corr()\n",
    "    sns.heatmap(corr_subset, annot=True, ax=axes[1, 2], cmap='RdBu_r', center=0)\n",
    "    axes[1, 2].set_title('Feature Correlation Matrix')\n",
    "    \n",
    "    # 7. Feature importance (mock)\n",
    "    rf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "    X = df[numeric_cols.columns]\n",
    "    y = df[target_col]\n",
    "    rf.fit(X, y)\n",
    "    importance = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    importance.head(8).plot(kind='barh', ax=axes[2, 0], color='orange')\n",
    "    axes[2, 0].set_title('Feature Importance (Random Forest)')\n",
    "    \n",
    "    # 8. Distribution comparison\n",
    "    for i, class_val in enumerate(df[target_col].unique()):\n",
    "        class_data = df[df[target_col] == class_val][top_feature]\n",
    "        axes[2, 1].hist(class_data, bins=15, alpha=0.6, label=f'Class {class_val}', density=True)\n",
    "    axes[2, 1].set_title(f'{top_feature} by Class')\n",
    "    axes[2, 1].legend()\n",
    "    \n",
    "    # 9. Statistical summary table\n",
    "    axes[2, 2].axis('off')\n",
    "    summary_stats = df[top_features[:4]].describe().round(2)\n",
    "    table = axes[2, 2].table(cellText=summary_stats.values,\n",
    "                           rowLabels=summary_stats.index,\n",
    "                           colLabels=summary_stats.columns,\n",
    "                           cellLoc='center',\n",
    "                           loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(8)\n",
    "    axes[2, 2].set_title('Statistical Summary')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… Comprehensive visualization complete!\")\n",
    "    return fig\n",
    "\n",
    "# Create visualization for wine dataset\n",
    "fig = create_comprehensive_visualization(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Complete Metaflow Pipeline Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComprehensiveMLPipeline(FlowSpec):\n",
    "    \"\"\"\n",
    "    Complete ML pipeline solution demonstrating all workshop concepts\n",
    "    \"\"\"\n",
    "    \n",
    "    test_size = Parameter('test_size', default=0.2, type=float)\n",
    "    random_state = Parameter('random_state', default=42, type=int)\n",
    "    dataset = Parameter('dataset', default='wine', help='Dataset to use: wine, iris, breast_cancer')\n",
    "    \n",
    "    @step\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Load dataset and perform initial validation\n",
    "        \"\"\"\n",
    "        print(f\"ðŸš€ Starting Comprehensive ML Pipeline\")\n",
    "        print(f\"ðŸ“Š Dataset: {self.dataset}\")\n",
    "        print(f\"âš™ï¸ Parameters: test_size={self.test_size}, random_state={self.random_state}\")\n",
    "        \n",
    "        # Load dataset\n",
    "        if self.dataset == 'wine':\n",
    "            data = load_wine()\n",
    "        elif self.dataset == 'iris':\n",
    "            data = load_iris()\n",
    "        elif self.dataset == 'breast_cancer':\n",
    "            data = load_breast_cancer()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown dataset: {self.dataset}\")\n",
    "        \n",
    "        self.X = data.data\n",
    "        self.y = data.target\n",
    "        self.feature_names = data.feature_names\n",
    "        self.target_names = data.target_names\n",
    "        \n",
    "        # Dataset info\n",
    "        self.dataset_info = {\n",
    "            'n_samples': self.X.shape[0],\n",
    "            'n_features': self.X.shape[1],\n",
    "            'n_classes': len(np.unique(self.y)),\n",
    "            'class_distribution': np.bincount(self.y).tolist()\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… Loaded {self.dataset_info['n_samples']} samples with {self.dataset_info['n_features']} features\")\n",
    "        \n",
    "        self.next(self.explore_data)\n",
    "    \n",
    "    @step\n",
    "    def explore_data(self):\n",
    "        \"\"\"\n",
    "        Comprehensive data exploration\n",
    "        \"\"\"\n",
    "        print(\"ðŸ” Exploring data...\")\n",
    "        \n",
    "        df = pd.DataFrame(self.X, columns=self.feature_names)\n",
    "        df['target'] = self.y\n",
    "        \n",
    "        # Correlation analysis\n",
    "        numeric_features = df.select_dtypes(include=[np.number]).drop('target', axis=1)\n",
    "        correlations = numeric_features.corrwith(df['target']).abs().sort_values(ascending=False)\n",
    "        \n",
    "        self.exploration_results = {\n",
    "            'top_features': correlations.head(5).index.tolist(),\n",
    "            'top_correlations': correlations.head(5).values.tolist(),\n",
    "            'feature_stats': {\n",
    "                'means': numeric_features.mean().to_dict(),\n",
    "                'stds': numeric_features.std().to_dict()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"ðŸ“Š Top predictive feature: {self.exploration_results['top_features'][0]}\")\n",
    "        print(f\"ðŸŽ¯ Correlation: {self.exploration_results['top_correlations'][0]:.3f}\")\n",
    "        \n",
    "        self.next(self.preprocess)\n",
    "    \n",
    "    @step\n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "        Data preprocessing and splitting\n",
    "        \"\"\"\n",
    "        print(\"ðŸ”§ Preprocessing data...\")\n",
    "        \n",
    "        # Split data\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=self.test_size, \n",
    "            random_state=self.random_state, stratify=self.y\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "        \n",
    "        print(f\"ðŸ“Š Train: {len(self.X_train)}, Test: {len(self.X_test)}\")\n",
    "        \n",
    "        self.next(self.train_models)\n",
    "    \n",
    "    @catch(var='training_errors')\n",
    "    @step\n",
    "    def train_models(self):\n",
    "        \"\"\"\n",
    "        Train multiple models with comprehensive evaluation\n",
    "        \"\"\"\n",
    "        print(\"ðŸ¤– Training multiple models...\")\n",
    "        \n",
    "        models = {\n",
    "            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=self.random_state),\n",
    "            'LogisticRegression': LogisticRegression(random_state=self.random_state, max_iter=1000),\n",
    "            'SVM': SVC(random_state=self.random_state, probability=True),\n",
    "            'DecisionTree': DecisionTreeClassifier(random_state=self.random_state),\n",
    "            'GradientBoosting': GradientBoostingClassifier(random_state=self.random_state)\n",
    "        }\n",
    "        \n",
    "        self.model_results = {}\n",
    "        self.training_errors = {}\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            try:\n",
    "                print(f\"   Training {name}...\")\n",
    "                \n",
    "                # Cross-validation\n",
    "                cv_scores = cross_val_score(model, self.X_train_scaled, self.y_train, cv=cv)\n",
    "                \n",
    "                # Fit and evaluate\n",
    "                model.fit(self.X_train_scaled, self.y_train)\n",
    "                train_score = model.score(self.X_train_scaled, self.y_train)\n",
    "                test_score = model.score(self.X_test_scaled, self.y_test)\n",
    "                \n",
    "                self.model_results[name] = {\n",
    "                    'model': model,\n",
    "                    'cv_mean': cv_scores.mean(),\n",
    "                    'cv_std': cv_scores.std(),\n",
    "                    'train_score': train_score,\n",
    "                    'test_score': test_score,\n",
    "                    'overfitting': train_score - test_score\n",
    "                }\n",
    "                \n",
    "                print(f\"     CV: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}\")\n",
    "                print(f\"     Test: {test_score:.3f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"     âŒ Failed: {str(e)}\")\n",
    "                self.training_errors[name] = str(e)\n",
    "        \n",
    "        print(f\"âœ… Trained {len(self.model_results)} models successfully\")\n",
    "        \n",
    "        self.next(self.evaluate)\n",
    "    \n",
    "    @step\n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Comprehensive model evaluation\n",
    "        \"\"\"\n",
    "        print(\"ðŸ“Š Evaluating models...\")\n",
    "        \n",
    "        if not self.model_results:\n",
    "            print(\"âŒ No models to evaluate\")\n",
    "            self.evaluation_results = {}\n",
    "            self.next(self.end)\n",
    "            return\n",
    "        \n",
    "        # Find best model\n",
    "        best_model_name = max(self.model_results.keys(), \n",
    "                            key=lambda x: self.model_results[x]['cv_mean'])\n",
    "        \n",
    "        self.best_model_name = best_model_name\n",
    "        best_model = self.model_results[best_model_name]['model']\n",
    "        \n",
    "        # Detailed evaluation\n",
    "        y_pred = best_model.predict(self.X_test_scaled)\n",
    "        \n",
    "        self.evaluation_results = {\n",
    "            'best_model': best_model_name,\n",
    "            'best_cv_score': self.model_results[best_model_name]['cv_mean'],\n",
    "            'best_test_score': self.model_results[best_model_name]['test_score'],\n",
    "            'classification_report': classification_report(\n",
    "                self.y_test, y_pred, target_names=self.target_names, output_dict=True\n",
    "            ),\n",
    "            'confusion_matrix': confusion_matrix(self.y_test, y_pred).tolist(),\n",
    "            'model_comparison': {\n",
    "                name: {\n",
    "                    'cv_score': results['cv_mean'],\n",
    "                    'test_score': results['test_score'],\n",
    "                    'overfitting': results['overfitting']\n",
    "                }\n",
    "                for name, results in self.model_results.items()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"ðŸ† Best model: {best_model_name}\")\n",
    "        print(f\"ðŸ“ˆ CV score: {self.evaluation_results['best_cv_score']:.3f}\")\n",
    "        print(f\"ðŸŽ¯ Test score: {self.evaluation_results['best_test_score']:.3f}\")\n",
    "        \n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        Generate final report\n",
    "        \"\"\"\n",
    "        print(\"ðŸŽ‰ Pipeline complete!\")\n",
    "        \n",
    "        # Create comprehensive summary\n",
    "        self.final_summary = {\n",
    "            'dataset': self.dataset,\n",
    "            'dataset_info': self.dataset_info,\n",
    "            'exploration_results': self.exploration_results,\n",
    "            'evaluation_results': self.evaluation_results,\n",
    "            'parameters': {\n",
    "                'test_size': self.test_size,\n",
    "                'random_state': self.random_state\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if self.evaluation_results:\n",
    "            best_accuracy = self.evaluation_results['best_test_score']\n",
    "            performance_grade = (\n",
    "                'Excellent' if best_accuracy > 0.95 else\n",
    "                'Very Good' if best_accuracy > 0.9 else\n",
    "                'Good' if best_accuracy > 0.8 else\n",
    "                'Fair'\n",
    "            )\n",
    "            \n",
    "            print(f\"ðŸ“Š Final Results:\")\n",
    "            print(f\"   Best Model: {self.evaluation_results['best_model']}\")\n",
    "            print(f\"   Accuracy: {best_accuracy:.3f}\")\n",
    "            print(f\"   Performance: {performance_grade}\")\n",
    "            print(f\"   Models Compared: {len(self.model_results)}\")\n",
    "        \n",
    "        print(\"âœ¨ All results saved automatically by Metaflow!\")\n",
    "\n",
    "# For demonstration in notebook\n",
    "print(\"âœ… ComprehensiveMLPipeline class defined!\")\n",
    "print(\"ðŸ’¡ To run: save as .py file and execute 'python pipeline.py run'\")\n",
    "print(\"ðŸŽ¯ This demonstrates the complete workshop workflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exercise Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 Solution: Add Decision Tree to comparison\n",
    "def exercise_1_solution():\n",
    "    \"\"\"\n",
    "    Exercise 1: Add Decision Tree and compare with different parameters\n",
    "    \"\"\"\n",
    "    print(\"ðŸŽ¯ Exercise 1 Solution: Enhanced Model Comparison\")\n",
    "    \n",
    "    # Load wine data\n",
    "    wine = load_wine()\n",
    "    X, y = wine.data, wine.target\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Test different parameters\n",
    "    for test_size in [0.2, 0.3]:\n",
    "        for random_state in [42, 123, 999]:\n",
    "            print(f\"\\nðŸ“Š Testing: test_size={test_size}, random_state={random_state}\")\n",
    "            \n",
    "            # Split data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "            )\n",
    "            \n",
    "            # Scale features\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            \n",
    "            # Models including Decision Tree\n",
    "            models = {\n",
    "                'RandomForest': RandomForestClassifier(n_estimators=100, random_state=random_state),\n",
    "                'LogisticRegression': LogisticRegression(random_state=random_state, max_iter=1000),\n",
    "                'SVM': SVC(random_state=random_state),\n",
    "                'DecisionTree': DecisionTreeClassifier(random_state=random_state)  # NEW\n",
    "            }\n",
    "            \n",
    "            run_results = {}\n",
    "            for name, model in models.items():\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                accuracy = model.score(X_test_scaled, y_test)\n",
    "                run_results[name] = accuracy\n",
    "                print(f\"   {name}: {accuracy:.3f}\")\n",
    "            \n",
    "            results[f\"test_{test_size}_seed_{random_state}\"] = run_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Exercise 2 Solution: Different dataset pipeline\n",
    "def exercise_2_solution(dataset_name='breast_cancer'):\n",
    "    \"\"\"\n",
    "    Exercise 2: Complete pipeline for different dataset\n",
    "    \"\"\"\n",
    "    print(f\"ðŸŽ¯ Exercise 2 Solution: {dataset_name.title()} Pipeline\")\n",
    "    \n",
    "    # Load dataset\n",
    "    if dataset_name == 'breast_cancer':\n",
    "        data = load_breast_cancer()\n",
    "    elif dataset_name == 'iris':\n",
    "        data = load_iris()\n",
    "    else:\n",
    "        raise ValueError(\"Use 'breast_cancer' or 'iris'\")\n",
    "    \n",
    "    X, y = data.data, data.target\n",
    "    \n",
    "    # 1. Data Exploration\n",
    "    print(f\"\\nðŸ“Š Dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    print(f\"ðŸŽ¯ Classes: {len(np.unique(y))} - {data.target_names}\")\n",
    "    \n",
    "    # 2. Preprocessing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # 3. Model Comparison\n",
    "    models = {\n",
    "        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'SVM': SVC(random_state=42),\n",
    "        'GradientBoosting': GradientBoostingClassifier(random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "        \n",
    "        # Fit and test
        model.fit(X_train_scaled, y_train)
        test_score = model.score(X_test_scaled, y_test)
        
        results[name] = {
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'test_score': test_score
        }
        
        print(f"{name}: CV={cv_scores.mean():.3f}Â±{cv_scores.std():.3f}, Test={test_score:.3f}")
    
    # 4. Best Model Analysis
    best_model_name = max(results.keys(), key=lambda x: results[x]['cv_mean'])
    print(f"\nðŸ† Best Model: {best_model_name}")
    
    return results

# Exercise 3 Solution: Advanced Metaflow features
def exercise_3_demo():
    """
    Exercise 3: Demonstrate advanced Metaflow patterns
    """
    print("ðŸŽ¯ Exercise 3 Solution: Advanced Metaflow Patterns")
    
    # Example of @catch decorator usage
    example_code = '''
from metaflow import FlowSpec, step, catch, foreach

class AdvancedFlow(FlowSpec):
    
    @step
    def start(self):
        # Parallel model training setup
        self.models_to_train = ['rf', 'lr', 'svm', 'dt']
        self.next(self.train_model, foreach='models_to_train')
    
    @catch(var='training_error')
    @step
    def train_model(self):
        """Train models in parallel with error handling"""
        model_name = self.input
        
        try:
            # Simulate model training
            if model_name == 'rf':
                model = RandomForestClassifier(random_state=42)
            elif model_name == 'lr':
                model = LogisticRegression(random_state=42, max_iter=1000)
            elif model_name == 'svm':
                model = SVC(random_state=42)
            elif model_name == 'dt':
                model = DecisionTreeClassifier(random_state=42)
            
            # Train model (load data here in real implementation)
            # model.fit(X_train, y_train)
            
            self.model_name = model_name
            self.model = model
            self.training_error = None
            
        except Exception as e:
            self.training_error = str(e)
            self.model = None
    
    @step
    def join_models(self, inputs):
        """Combine results from parallel training"""
        self.successful_models = []
        self.failed_models = []
        
        for inp in inputs:
            if inp.training_error is None:
                self.successful_models.append(inp.model_name)
            else:
                self.failed_models.append({
                    'model': inp.model_name,
                    'error': inp.training_error
                })
        
        print(f"Successful: {self.successful_models}")
        print(f"Failed: {self.failed_models}")
        
        self.next(self.end)
    
    @step
    def end(self):
        print("Advanced flow complete!")
    '''
    
    print("ðŸ“ Advanced Metaflow Pattern:")
    print(example_code)
    
    return example_code

# Run demonstration solutions
print("ðŸŽ“ Running Exercise Solutions...")

# Exercise 1
results_1 = exercise_1_solution()
print(f"\nâœ… Exercise 1 complete! Tested {len(results_1)} parameter combinations")

# Exercise 2  
results_2 = exercise_2_solution('breast_cancer')
print(f"\nâœ… Exercise 2 complete! Best model performance: {max([r['test_score'] for r in results_2.values()]):.3f}")

# Exercise 3
exercise_3_demo()
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Workshop Summary and Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workshop_summary():\n",
    "    \"\"\"\n",
    "    Summary of all workshop concepts and best practices\n",
    "    \"\"\"\n",
    "    print(\"ðŸŽ“ WEEK 1 WORKSHOP SUMMARY\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    concepts_covered = {\n",
    "        \"Metaflow Fundamentals\": [\n",
    "            \"FlowSpec class structure\",\n",
    "            \"Step definitions and flow control\",\n",
    "            \"Parameter management\",\n",
    "            \"Artifact storage and retrieval\",\n",
    "            \"Error handling with @catch\",\n",
    "            \"Parallel execution with @foreach\"\n",
    "        ],\n",
    "        \"Data Exploration\": [\n",
    "            \"Comprehensive data quality assessment\",\n",
    "            \"Statistical analysis and correlation\",\n",
    "            \"Outlier detection and handling\",\n",
    "            \"Feature relationship analysis\",\n",
    "            \"Class distribution evaluation\",\n",
    "            \"Missing value and duplicate detection\"\n",
    "        ],\n",
    "        \"Visualization Techniques\": [\n",
    "            \"Essential chart types for ML\",\n",
    "            \"Statistical visualization methods\",\n",
    "            \"Publication-ready plot formatting\",\n",
    "            \"Multi-panel dashboard creation\",\n",
    "            \"Interactive visualization concepts\",\n",
    "            \"Color theory and accessibility\"\n",
    "        ],\n",
    "        \"Machine Learning Pipeline\": [\n",
    "            \"Data preprocessing and scaling\",\n",
    "            \"Multiple algorithm comparison\",\n",
    "            \"Cross-validation and model selection\",\n",
    "            \"Performance evaluation metrics\",\n",
    "            \"Feature importance analysis\",\n",
    "            \"Production readiness assessment\"\n",
    "        ],\n",
    "        \"MLOps Best Practices\": [\n",
    "            \"Reproducible pipeline design\",\n",
    "            \"Comprehensive error handling\",\n",
    "            \"Automated report generation\",\n",
    "            \"Version control and artifact management\",\n",
    "            \"Performance monitoring and validation\",\n",
    "            \"Documentation and code quality\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, items in concepts_covered.items():\n",
    "        print(f\"\\nðŸ“š {category}:\")\n",
    "        for item in items:\n",
    "            print(f\"   âœ… {item}\")\n",
    "    \n",
    "    print(\"\\nðŸ† Key Achievements:\")\n",
    "    achievements = [\n",
    "        \"Built production-ready ML pipeline from scratch\",\n",
    "        \"Mastered essential data science tools and libraries\",\n",
    "        \"Created professional data visualizations\",\n",
    "        \"Implemented MLOps best practices with Metaflow\",\n",
    "        \"Developed systematic approach to ML problem solving\"\n",
    "    ]\n",
    "    \n",
    "    for i, achievement in enumerate(achievements, 1):\n",
    "        print(f\"   {i}. {achievement}\")\n",
    "    \n",
    "    print(\"\\nðŸ’¡ Best Practices Learned:\")\n",
    "    best_practices = {\n",
    "        \"Code Quality\": [\n",
    "            \"Use descriptive variable and function names\",\n",
    "            \"Add comprehensive docstrings and comments\",\n",
    "            \"Implement proper error handling\",\n",
    "            \"Follow PEP 8 style guidelines\"\n",
    "        ],\n",
    "        \"Data Science\": [\n",
    "            \"Always explore data before modeling\",\n",
    "            \"Validate data quality and assumptions\",\n",
    "            \"Use cross-validation for model selection\",\n",
    "            \"Document data preprocessing steps\"\n",
    "        ],\n",
    "        \"MLOps\": [\n",
    "            \"Make pipelines reproducible with fixed seeds\",\n",
    "            \"Version control all code and configurations\",\n",
    "            \"Automate testing and validation\",\n",
    "            \"Monitor model performance in production\"\n",
    "        ],\n",
    "        \"Collaboration\": [\n",
    "            \"Create clear, documented workflows\",\n",
    "            \"Use version control effectively\",\n",
    "            \"Share results through automated reports\",\n",
    "            \"Make code accessible to team members\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, practices in best_practices.items():\n",
    "        print(f\"\\n   ðŸŽ¯ {category}:\")\n",
    "        for practice in practices:\n",
    "            print(f\"      â€¢ {practice}\")\n",
    "    \n",
    "    print(\"\\nðŸš€ Ready for Week 2!\")\n",
    "    print(\"Next up: LangChain, LCEL, and LLM integration\")\n",
    "    \n",
    "    return concepts_covered, best_practices\n",
    "\n",
    "# Generate workshop summary\n",
    "concepts, practices = workshop_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quick Reference Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quick_reference():\n",
    "    \"\"\"\n",
    "    Create a quick reference guide for workshop concepts\n",
    "    \"\"\"\n",
    "    print(\"ðŸ“– QUICK REFERENCE GUIDE\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    reference_guide = {\n",
    "        \"Metaflow Commands\": {\n",
    "            \"Run flow\": \"python flow.py run\",\n",
    "            \"Run with params\": \"python flow.py run --param value\",\n",
    "            \"Show flow info\": \"python flow.py show\",\n",
    "            \"List runs\": \"metaflow list runs FlowName\",\n",
    "            \"Access results\": \"Flow('FlowName').latest_run\"\n",
    "        },\n",
    "        \"Essential Pandas\": {\n",
    "            \"Load data\": \"pd.read_csv('file.csv')\",\n",
    "            \"Basic info\": \"df.info(), df.describe()\",\n",
    "            \"Missing values\": \"df.isnull().sum()\",\n",
    "            \"Filter data\": \"df[df['col'] > value]\",\n",
    "            \"Group by\": \"df.groupby('col').mean()\"\n",
    "        },\n",
    "        \"Key Visualizations\": {\n",
    "            \"Histogram\": \"plt.hist(data, bins=20)\",\n",
    "            \"Scatter plot\": \"plt.scatter(x, y, c=colors)\",\n",
    "            \"Box plot\": \"df.boxplot(column='col', by='group')\",\n",
    "            \"Correlation\": \"sns.heatmap(df.corr(), annot=True)\",\n",
    "            \"Distribution\": \"sns.histplot(data, hue='category')\"\n",
    "        },\n",
    "        \"ML Pipeline Steps\": {\n",
    "            \"Load data\": \"X, y = load_dataset()\",\n",
    "            \"Split data\": \"train_test_split(X, y, test_size=0.2)\",\n",
    "            \"Scale features\": \"StandardScaler().fit_transform(X)\",\n",
    "            \"Train model\": \"model.fit(X_train, y_train)\",\n",
    "            \"Evaluate\": \"model.score(X_test, y_test)\"\n",
    "        },\n",
    "        \"Common Patterns\": {\n",
    "            \"Error handling\": \"@catch(var='error_info')\",\n",
    "            \"Parallel execution\": \"@foreach\",\n",
    "            \"Cross-validation\": \"cross_val_score(model, X, y, cv=5)\",\n",
    "            \"Feature importance\": \"model.feature_importances_\",\n",
    "            \"Model comparison\": \"Compare multiple algorithms\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for section, items in reference_guide.items():\n",
    "        print(f\"\\nðŸ“Œ {section}:\")\n",
    "        for concept, code in items.items():\n",
    "            print(f\"   {concept:20}: {code}\")\n",
    "    \n",
    "    print(\"\\nðŸ”— Useful Resources:\")\n",
    "    resources = [\n",
    "        \"Metaflow docs: https://docs.metaflow.org/\",\n",
    "        \"Pandas docs: https://pandas.pydata.org/docs/\",\n",
    "        \"Scikit-learn: https://scikit-learn.org/stable/\",\n",
    "        \"Matplotlib: https://matplotlib.org/stable/\",\n",
    "        \"Seaborn: https://seaborn.pydata.org/\"\n",
    "    ]\n",
    "    \n",
    "    for resource in resources:\n",
    "        print(f\"   â€¢ {resource}\")\n",
    "    \n",
    "    return reference_guide\n",
    "\n",
    "# Create reference guide\n",
    "reference = create_quick_reference()\n",
    "\n",
    "print(\"\\nðŸŽ‰ Workshop Solutions Complete!\")\n",
    "print(\"Use this notebook as your reference for Week 1 concepts.\")\n",
    "print(\"All code examples are production-ready and follow best practices.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}