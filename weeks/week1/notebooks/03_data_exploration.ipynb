{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration with Pandas - Week 1 Workshop\n",
    "\n",
    "Data exploration is the foundation of any successful ML project. In this notebook, we'll master pandas techniques for understanding, cleaning, and preparing data for machine learning.\n",
    "\n",
    "## Learning Objectives\n",
    "- Master essential pandas operations\n",
    "- Perform comprehensive data quality assessment\n",
    "- Discover patterns and relationships in data\n",
    "- Prepare data for machine learning\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and First Look at Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üç∑ Loading the Wine Dataset...\")\n",
    "\n",
    "# Load wine dataset\n",
    "wine_data = load_wine()\n",
    "wine_df = pd.DataFrame(wine_data.data, columns=wine_data.feature_names)\n",
    "wine_df['target'] = wine_data.target\n",
    "wine_df['target_name'] = wine_df['target'].map({0: 'class_0', 1: 'class_1', 2: 'class_2'})\n",
    "\n",
    "print(\"‚úÖ Wine Dataset Loaded Successfully!\")\n",
    "print(f\"üìä Shape: {wine_df.shape}\")\n",
    "print(f\"üéØ Features: {len(wine_data.feature_names)}\")\n",
    "print(f\"üè∑Ô∏è Classes: {wine_data.target_names}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüëÄ First 5 rows:\")\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview and Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä COMPREHENSIVE DATA OVERVIEW\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Basic dataset information\n",
    "print(\"1. Dataset Dimensions:\")\n",
    "print(f\"   Rows: {len(wine_df):,}\")\n",
    "print(f\"   Columns: {len(wine_df.columns)}\")\n",
    "print(f\"   Memory usage: {wine_df.memory_usage().sum() / 1024:.1f} KB\")\n",
    "\n",
    "# Data types analysis\n",
    "print(\"\\n2. Data Types Distribution:\")\n",
    "for dtype, count in wine_df.dtypes.value_counts().items():\n",
    "    print(f\"   {dtype}: {count} columns\")\n",
    "\n",
    "# Missing values analysis\n",
    "print(\"\\n3. Missing Values Check:\")\n",
    "missing_values = wine_df.isnull().sum()\n",
    "total_missing = missing_values.sum()\n",
    "print(f\"   Total missing values: {total_missing}\")\n",
    "\n",
    "if total_missing > 0:\n",
    "    print(\"   Columns with missing values:\")\n",
    "    for col, missing_count in missing_values[missing_values > 0].items():\n",
    "        percentage = (missing_count / len(wine_df)) * 100\n",
    "        print(f\"      {col}: {missing_count} ({percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No missing values found!\")\n",
    "\n",
    "# Basic statistics for numeric columns\n",
    "print(\"\\n4. Numeric Columns Summary:\")\n",
    "numeric_cols = wine_df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"   Number of numeric columns: {len(numeric_cols)}\")\n",
    "print(f\"   Numeric columns: {list(numeric_cols[:5])}{'...' if len(numeric_cols) > 5 else ''}\")\n",
    "\n",
    "# Display detailed statistics\n",
    "wine_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ TARGET VARIABLE ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Class distribution\n",
    "print(\"1. Class Distribution:\")\n",
    "class_counts = wine_df['target_name'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "# Calculate class balance\n",
    "class_balance = class_counts.min() / class_counts.max()\n",
    "print(f\"\\n   Class balance ratio: {class_balance:.3f}\")\n",
    "if class_balance > 0.7:\n",
    "    print(\"   ‚úÖ Well-balanced classes\")\n",
    "elif class_balance > 0.5:\n",
    "    print(\"   ‚ö†Ô∏è Moderately imbalanced classes\")\n",
    "else:\n",
    "    print(\"   ‚ùå Highly imbalanced classes - consider resampling\")\n",
    "\n",
    "# Class percentages\n",
    "print(\"\\n2. Class Percentages:\")\n",
    "class_percentages = wine_df['target_name'].value_counts(normalize=True) * 100\n",
    "for class_name, percentage in class_percentages.items():\n",
    "    print(f\"   {class_name}: {percentage:.1f}%\")\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "class_counts.plot(kind='bar', color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "plt.title('Wine Class Distribution (Counts)')\n",
    "plt.xlabel('Wine Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "class_percentages.plot(kind='pie', autopct='%1.1f%%', colors=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "plt.title('Wine Class Distribution (Percentages)')\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Target variable analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Analysis and Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç FEATURE ANALYSIS\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "# Feature ranges and scales\n",
    "print(\"1. Feature Scales Analysis:\")\n",
    "numeric_features = wine_df.select_dtypes(include=[np.number]).drop(['target'], axis=1)\n",
    "feature_ranges = numeric_features.max() - numeric_features.min()\n",
    "feature_scales = numeric_features.max() / numeric_features.min()\n",
    "\n",
    "print(f\"   Features with largest ranges:\")\n",
    "top_ranges = feature_ranges.nlargest(5)\n",
    "for feature, range_val in top_ranges.items():\n",
    "    print(f\"      {feature}: {range_val:.1f}\")\n",
    "\n",
    "print(f\"\\n   Features with highest scale ratios:\")\n",
    "top_scales = feature_scales.nlargest(5)\n",
    "for feature, scale_ratio in top_scales.items():\n",
    "    print(f\"      {feature}: {scale_ratio:.1f}x\")\n",
    "\n",
    "# Check for features that need scaling\n",
    "features_need_scaling = feature_scales[feature_scales > 100]\n",
    "if len(features_need_scaling) > 0:\n",
    "    print(f\"\\n   ‚ö†Ô∏è Features that likely need scaling:\")\n",
    "    for feature in features_need_scaling.index:\n",
    "        print(f\"      {feature}\")\n",
    "else:\n",
    "    print(\"\\n   ‚úÖ Feature scales are relatively similar\")\n",
    "\n",
    "# Feature correlations with target\n",
    "print(\"\\n2. Feature-Target Correlations:\")\n",
    "target_correlations = numeric_features.corrwith(wine_df['target']).abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"   Strongest correlations with target:\")\n",
    "top_correlations = target_correlations.head(8)\n",
    "for feature, correlation in top_correlations.items():\n",
    "    strength = \"Strong\" if correlation > 0.5 else \"Moderate\" if correlation > 0.3 else \"Weak\"\n",
    "    print(f\"      {feature}: {correlation:.3f} ({strength})\")\n",
    "\n",
    "# Visualize top correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_correlations.plot(kind='barh', color='steelblue')\n",
    "plt.title('Top Feature Correlations with Target')\n",
    "plt.xlabel('Absolute Correlation')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature-Feature Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîó FEATURE-FEATURE CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = numeric_features.corr()\n",
    "\n",
    "# Find highly correlated feature pairs\n",
    "print(\"1. Highly Correlated Feature Pairs (|r| > 0.7):\")\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        correlation = corr_matrix.iloc[i, j]\n",
    "        if abs(correlation) > 0.7:\n",
    "            feature1 = corr_matrix.columns[i]\n",
    "            feature2 = corr_matrix.columns[j]\n",
    "            high_corr_pairs.append((feature1, feature2, correlation))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    for feature1, feature2, corr in sorted(high_corr_pairs, key=lambda x: abs(x[2]), reverse=True):\n",
    "        corr_type = \"Positive\" if corr > 0 else \"Negative\"\n",
    "        print(f\"   {feature1} ‚Üî {feature2}: {corr:.3f} ({corr_type})\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No highly correlated feature pairs found\")\n",
    "\n",
    "# Create correlation heatmap for selected features\n",
    "print(\"\\n2. Correlation Heatmap (Top 10 Features):\")\n",
    "top_features = target_correlations.head(10).index\n",
    "top_corr_matrix = wine_df[top_features].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(top_corr_matrix, dtype=bool))\n",
    "sns.heatmap(top_corr_matrix, \n",
    "            mask=mask,\n",
    "            annot=True, \n",
    "            cmap='RdBu_r', \n",
    "            center=0,\n",
    "            square=True,\n",
    "            fmt='.2f',\n",
    "            cbar_kws={\"shrink\": .8})\n",
    "plt.title('Feature Correlation Matrix (Top 10 Features)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature multicollinearity check\n",
    "print(\"\\n3. Multicollinearity Assessment:\")\n",
    "highly_correlated_features = []\n",
    "for feature1, feature2, corr in high_corr_pairs:\n",
    "    if abs(corr) > 0.8:\n",
    "        highly_correlated_features.extend([feature1, feature2])\n",
    "\n",
    "if highly_correlated_features:\n",
    "    unique_features = list(set(highly_correlated_features))\n",
    "    print(f\"   ‚ö†Ô∏è Features with potential multicollinearity: {len(unique_features)}\")\n",
    "    for feature in unique_features[:5]:  # Show first 5\n",
    "        print(f\"      {feature}\")\n",
    "    print(\"   üí° Consider feature selection or dimensionality reduction\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No significant multicollinearity detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Outlier Detection and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ OUTLIER DETECTION ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"Detect outliers using IQR method\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Analyze outliers for top features\n",
    "print(\"1. Outlier Analysis for Key Features:\")\n",
    "outlier_summary = {}\n",
    "\n",
    "for feature in top_correlations.head(5).index:\n",
    "    outliers, lower, upper = detect_outliers_iqr(wine_df, feature)\n",
    "    outlier_count = len(outliers)\n",
    "    outlier_percentage = (outlier_count / len(wine_df)) * 100\n",
    "    \n",
    "    outlier_summary[feature] = {\n",
    "        'count': outlier_count,\n",
    "        'percentage': outlier_percentage,\n",
    "        'bounds': (lower, upper)\n",
    "    }\n",
    "    \n",
    "    print(f\"   {feature}:\")\n",
    "    print(f\"      Outliers: {outlier_count} ({outlier_percentage:.1f}%)\")\n",
    "    print(f\"      Normal range: [{lower:.2f}, {upper:.2f}]\")\n",
    "\n",
    "# Visualize outliers with box plots\n",
    "print(\"\\n2. Outlier Visualization:\")\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "top_5_features = top_correlations.head(5).index\n",
    "for idx, feature in enumerate(top_5_features):\n",
    "    wine_df.boxplot(column=feature, by='target_name', ax=axes[idx])\n",
    "    axes[idx].set_title(f'{feature} by Wine Class')\n",
    "    axes[idx].set_xlabel('Wine Class')\n",
    "\n",
    "# Overall outlier distribution\n",
    "axes[5].bar(outlier_summary.keys(), [v['count'] for v in outlier_summary.values()], \n",
    "           color='lightcoral')\n",
    "axes[5].set_title('Outlier Counts by Feature')\n",
    "axes[5].set_xlabel('Features')\n",
    "axes[5].set_ylabel('Number of Outliers')\n",
    "axes[5].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overall outlier assessment\n",
    "total_outliers = sum([v['count'] for v in outlier_summary.values()])\n",
    "print(f\"\\n3. Overall Outlier Summary:\")\n",
    "print(f\"   Total outlier instances: {total_outliers}\")\n",
    "print(f\"   Average outliers per feature: {total_outliers / len(outlier_summary):.1f}\")\n",
    "\n",
    "if total_outliers > len(wine_df) * 0.1:\n",
    "    print(\"   ‚ö†Ô∏è High number of outliers detected - investigate data quality\")\n",
    "else:\n",
    "    print(\"   ‚úÖ Outlier levels appear normal for this dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä FEATURE DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "def analyze_distribution(data, column):\n",
    "    \"\"\"Analyze the distribution of a feature\"\"\"\n",
    "    # Basic statistics\n",
    "    mean_val = data[column].mean()\n",
    "    median_val = data[column].median()\n",
    "    std_val = data[column].std()\n",
    "    \n",
    "    # Skewness and kurtosis\n",
    "    skewness = data[column].skew()\n",
    "    kurtosis = data[column].kurtosis()\n",
    "    \n",
    "    # Distribution assessment\n",
    "    if abs(skewness) < 0.5:\n",
    "        skew_assessment = \"Nearly symmetric\"\n",
    "    elif abs(skewness) < 1.0:\n",
    "        skew_assessment = \"Moderately skewed\"\n",
    "    else:\n",
    "        skew_assessment = \"Highly skewed\"\n",
    "    \n",
    "    return {\n",
    "        'mean': mean_val,\n",
    "        'median': median_val,\n",
    "        'std': std_val,\n",
    "        'skewness': skewness,\n",
    "        'kurtosis': kurtosis,\n",
    "        'skew_assessment': skew_assessment\n",
    "    }\n",
    "\n",
    "print(\"1. Distribution Analysis for Key Features:\")\n",
    "distribution_analysis = {}\n",
    "\n",
    "for feature in top_correlations.head(6).index:\n",
    "    analysis = analyze_distribution(wine_df, feature)\n",
    "    distribution_analysis[feature] = analysis\n",
    "    \n",
    "    print(f\"\\n   {feature}:\")\n",
    "    print(f\"      Mean: {analysis['mean']:.3f}, Median: {analysis['median']:.3f}\")\n",
    "    print(f\"      Skewness: {analysis['skewness']:.3f} ({analysis['skew_assessment']})\")\n",
    "    print(f\"      Kurtosis: {analysis['kurtosis']:.3f}\")\n",
    "\n",
    "# Visualize distributions\n",
    "print(\"\\n2. Distribution Visualizations:\")\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(top_correlations.head(6).index):\n",
    "    # Histogram with KDE\n",
    "    wine_df[feature].hist(bins=20, alpha=0.7, ax=axes[idx], density=True)\n",
    "    wine_df[feature].plot(kind='kde', ax=axes[idx], color='red')\n",
    "    \n",
    "    axes[idx].set_title(f'{feature} Distribution')\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Density')\n",
    "    \n",
    "    # Add mean and median lines\n",
    "    mean_val = wine_df[feature].mean()\n",
    "    median_val = wine_df[feature].median()\n",
    "    axes[idx].axvline(mean_val, color='green', linestyle='--', alpha=0.7, label=f'Mean: {mean_val:.2f}')\n",
    "    axes[idx].axvline(median_val, color='orange', linestyle='--', alpha=0.7, label=f'Median: {median_val:.2f}')\n",
    "    axes[idx].legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Normality assessment\n",
    "print(\"\\n3. Normality Assessment:\")\n",
    "skewed_features = []\n",
    "normal_features = []\n",
    "\n",
    "for feature, analysis in distribution_analysis.items():\n",
    "    if abs(analysis['skewness']) > 0.5:\n",
    "        skewed_features.append(feature)\n",
    "    else:\n",
    "        normal_features.append(feature)\n",
    "\n",
    "if skewed_features:\n",
    "    print(f\"   Features with significant skewness: {len(skewed_features)}\")\n",
    "    for feature in skewed_features[:3]:  # Show first 3\n",
    "        print(f\"      {feature} (skewness: {distribution_analysis[feature]['skewness']:.3f})\")\n",
    "    print(\"   üí° Consider log transformation or other normalization techniques\")\n",
    "\n",
    "if normal_features:\n",
    "    print(f\"   ‚úÖ Features with normal-like distributions: {len(normal_features)}\")\n",
    "    for feature in normal_features[:3]:  # Show first 3\n",
    "        print(f\"      {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Class-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üè∑Ô∏è CLASS-SPECIFIC FEATURE ANALYSIS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Analyze feature means by class\n",
    "print(\"1. Feature Means by Wine Class:\")\n",
    "class_means = wine_df.groupby('target_name')[top_correlations.head(5).index].mean()\n",
    "print(class_means.round(3))\n",
    "\n",
    "# Find features with largest class differences\n",
    "print(\"\\n2. Features with Largest Class Differences:\")\n",
    "class_ranges = class_means.max() - class_means.min()\n",
    "top_discriminative = class_ranges.sort_values(ascending=False)\n",
    "\n",
    "for feature, range_val in top_discriminative.head(5).items():\n",
    "    print(f\"   {feature}: {range_val:.3f}\")\n",
    "    # Show which class has highest/lowest values\n",
    "    feature_by_class = class_means[feature]\n",
    "    highest_class = feature_by_class.idxmax()\n",
    "    lowest_class = feature_by_class.idxmin()\n",
    "    print(f\"      Highest: {highest_class} ({feature_by_class[highest_class]:.3f})\")\n",
    "    print(f\"      Lowest: {lowest_class} ({feature_by_class[lowest_class]:.3f})\")\n",
    "\n",
    "# Visualize class differences\n",
    "print(\"\\n3. Class Comparison Visualizations:\")\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Box plots for top discriminative features\n",
    "for idx, feature in enumerate(top_discriminative.head(5).index):\n",
    "    sns.boxplot(data=wine_df, x='target_name', y=feature, ax=axes[idx])\n",
    "    axes[idx].set_title(f'{feature} by Wine Class')\n",
    "    axes[idx].set_xlabel('Wine Class')\n",
    "\n",
    "# Feature means heatmap\n",
    "sns.heatmap(class_means.T, annot=True, cmap='RdYlBu_r', ax=axes[5], fmt='.2f')\n",
    "axes[5].set_title('Feature Means by Class (Heatmap)')\n",
    "axes[5].set_xlabel('Wine Class')\n",
    "axes[5].set_ylabel('Features')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical significance testing\n",
    "print(\"\\n4. Statistical Significance (ANOVA F-statistic):\")\n",
    "from scipy import stats\n",
    "\n",
    "significant_features = []\n",
    "for feature in top_discriminative.head(5).index:\n",
    "    # Perform ANOVA\n",
    "    groups = [wine_df[wine_df['target_name'] == class_name][feature] \n",
    "              for class_name in wine_df['target_name'].unique()]\n",
    "    f_stat, p_value = stats.f_oneway(*groups)\n",
    "    \n",
    "    significance = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"ns\"\n",
    "    print(f\"   {feature}: F={f_stat:.3f}, p={p_value:.3e} {significance}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        significant_features.append(feature)\n",
    "\n",
    "print(f\"\\n   ‚úÖ Significant features for class discrimination: {len(significant_features)}\")\n",
    "print(\"   üí° These features show significant differences between wine classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Quality Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìã DATA EXPLORATION SUMMARY\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Compile overall assessment\n",
    "print(\"1. Dataset Quality Assessment:\")\n",
    "quality_score = 0\n",
    "max_score = 5\n",
    "\n",
    "# Check missing values\n",
    "if total_missing == 0:\n",
    "    print(\"   ‚úÖ No missing values\")\n",
    "    quality_score += 1\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è {total_missing} missing values ({(total_missing/len(wine_df)*100):.1f}%)\")\n",
    "\n",
    "# Check class balance\n",
    "if class_balance > 0.7:\n",
    "    print(\"   ‚úÖ Well-balanced target classes\")\n",
    "    quality_score += 1\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Imbalanced classes (ratio: {class_balance:.3f})\")\n",
    "\n",
    "# Check feature discrimination\n",
    "if len(significant_features) >= 3:\n",
    "    print(f\"   ‚úÖ {len(significant_features)} features significantly discriminate classes\")\n",
    "    quality_score += 1\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Only {len(significant_features)} significantly discriminative features\")\n",
    "\n",
    "# Check multicollinearity\n",
    "if len(high_corr_pairs) <= 3:\n",
    "    print(\"   ‚úÖ Low multicollinearity between features\")\n",
    "    quality_score += 1\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è {len(high_corr_pairs)} highly correlated feature pairs\")\n",
    "\n",
    "# Check outliers\n",
    "outlier_rate = total_outliers / (len(wine_df) * len(outlier_summary))\n",
    "if outlier_rate < 0.05:\n",
    "    print(\"   ‚úÖ Low outlier rate\")\n",
    "    quality_score += 1\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è High outlier rate ({outlier_rate:.1%})\")\n",
    "\n",
    "print(f\"\\n   Overall Quality Score: {quality_score}/{max_score} ({'Excellent' if quality_score >= 4 else 'Good' if quality_score >= 3 else 'Fair'})\")\n",
    "\n",
    "print(\"\\n2. Key Insights:\")\n",
    "print(f\"   üìä Dataset has {len(wine_df)} samples with {len(numeric_features.columns)} features\")\n",
    "print(f\"   üéØ {len(significant_features)} features strongly discriminate between classes\")\n",
    "print(f\"   üîó {len(high_corr_pairs)} highly correlated feature pairs detected\")\n",
    "print(f\"   üìà Top predictive feature: {top_correlations.index[0]} (r={top_correlations.iloc[0]:.3f})\")\n",
    "\n",
    "print(\"\\n3. Recommendations for ML Pipeline:\")\n",
    "\n",
    "# Feature scaling recommendation\n",
    "if len(features_need_scaling) > 0:\n",
    "    print(\"   üîß Apply feature scaling (StandardScaler recommended)\")\n",
    "    print(f\"      Features needing scaling: {len(features_need_scaling)}\")\n",
    "\n",
    "# Feature selection recommendation\n",
    "if len(high_corr_pairs) > 3:\n",
    "    print(\"   ‚úÇÔ∏è Consider feature selection to reduce multicollinearity\")\n",
    "    print(f\"      Correlated pairs to review: {len(high_corr_pairs)}\")\n",
    "\n",
    "# Outlier handling recommendation\n",
    "if outlier_rate > 0.05:\n",
    "    print(\"   üéØ Consider outlier detection and handling\")\n",
    "    print(\"      Methods: IQR filtering, Isolation Forest, or robust scaling\")\n",
    "\n",
    "# Data transformation recommendation\n",
    "if len(skewed_features) > 0:\n",
    "    print(\"   üìê Consider transforming skewed features\")\n",
    "    print(\"      Methods: Log transformation, Box-Cox, or Yeo-Johnson\")\n",
    "\n",
    "# Model selection recommendation\n",
    "print(\"   ü§ñ Recommended algorithms:\")\n",
    "if quality_score >= 4:\n",
    "    print(\"      - Random Forest (handles feature interactions well)\")\n",
    "    print(\"      - SVM (good for this dataset size)\")\n",
    "    print(\"      - Logistic Regression (if interpretability needed)\")\n",
    "else:\n",
    "    print(\"      - Random Forest (robust to data quality issues)\")\n",
    "    print(\"      - Gradient Boosting (handles complex patterns)\")\n",
    "\n",
    "print(\"\\n‚úÖ Data exploration complete! Ready for machine learning pipeline.\")\n",
    "print(\"üí° Next: Feature preprocessing and model training with Metaflow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}