{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete ML Pipeline - Week 1 Workshop\n",
    "\n",
    "This is the culmination of Week 1! We'll combine everything we've learned - Metaflow, data exploration, and visualization - into a production-ready machine learning pipeline.\n",
    "\n",
    "## Learning Objectives\n",
    "- Build end-to-end ML pipelines with Metaflow\n",
    "- Implement proper data preprocessing\n",
    "- Compare multiple ML algorithms systematically\n",
    "- Create comprehensive model evaluation\n",
    "- Generate production-ready reports\n",
    "\n",
    "Let's build something amazing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pipeline Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "print(\"ğŸš€ Setting up Complete ML Pipeline Environment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Core ML and data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Metaflow for MLOps\n",
    "from metaflow import FlowSpec, step, Parameter, catch\n",
    "\n",
    "# Utilities\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(\"ğŸ“Š Ready to build production ML pipeline\")\n",
    "print(\"ğŸ¯ Target: Wine classification with comprehensive evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the Complete ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteMLPipeline(FlowSpec):\n",
    "    \"\"\"\n",
    "    Production-ready ML pipeline for wine classification\n",
    "    \n",
    "    Features:\n",
    "    - Comprehensive data preprocessing\n",
    "    - Multiple algorithm comparison\n",
    "    - Cross-validation and robust evaluation\n",
    "    - Automated report generation\n",
    "    - Production-ready model artifacts\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configurable parameters\n",
    "    test_size = Parameter('test_size',\n",
    "                         help='Test set proportion (0.1-0.4)',\n",
    "                         default=0.2,\n",
    "                         type=float)\n",
    "    \n",
    "    random_state = Parameter('random_state',\n",
    "                           help='Random seed for reproducibility',\n",
    "                           default=42,\n",
    "                           type=int)\n",
    "    \n",
    "    cv_folds = Parameter('cv_folds',\n",
    "                        help='Number of cross-validation folds',\n",
    "                        default=5,\n",
    "                        type=int)\n",
    "    \n",
    "    models_to_test = Parameter('models',\n",
    "                              help='Comma-separated list of models',\n",
    "                              default='random_forest,logistic_regression,svm')\n",
    "    \n",
    "    @step\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Initialize pipeline with data loading and validation\n",
    "        \"\"\"\n",
    "        print(\"ğŸ· Starting Complete Wine Classification Pipeline\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"ğŸ“Š Configuration:\")\n",
    "        print(f\"   Test size: {self.test_size}\")\n",
    "        print(f\"   Random state: {self.random_state}\")\n",
    "        print(f\"   CV folds: {self.cv_folds}\")\n",
    "        print(f\"   Models: {self.models_to_test}\")\n",
    "        \n",
    "        # Parameter validation\n",
    "        if not (0.1 <= self.test_size <= 0.4):\n",
    "            raise ValueError(f\"test_size must be between 0.1 and 0.4, got {self.test_size}\")\n",
    "        \n",
    "        # Load wine dataset\n",
    "        wine_data = load_wine()\n",
    "        \n",
    "        # Store raw data and metadata\n",
    "        self.X_raw = wine_data.data\n",
    "        self.y_raw = wine_data.target\n",
    "        self.feature_names = wine_data.feature_names.tolist()\n",
    "        self.target_names = wine_data.target_names.tolist()\n",
    "        \n",
    "        # Create dataset info\n",
    "        self.dataset_info = {\n",
    "            'n_samples': self.X_raw.shape[0],\n",
    "            'n_features': self.X_raw.shape[1],\n",
    "            'n_classes': len(np.unique(self.y_raw)),\n",
    "            'class_distribution': np.bincount(self.y_raw).tolist()\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ Dataset Overview:\")\n",
    "        print(f\"   Samples: {self.dataset_info['n_samples']}\")\n",
    "        print(f\"   Features: {self.dataset_info['n_features']}\")\n",
    "        print(f\"   Classes: {self.dataset_info['n_classes']}\")\n",
    "        \n",
    "        self.next(self.preprocess)\n",
    "    \n",
    "    @step\n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "        Data preprocessing pipeline\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ”§ Data Preprocessing...\")\n",
    "        \n",
    "        # Split the data\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X_raw, self.y_raw,\n",
    "            test_size=self.test_size,\n",
    "            random_state=self.random_state,\n",
    "            stratify=self.y_raw\n",
    "        )\n",
    "        \n",
    "        # Feature scaling\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "        \n",
    "        print(f\"   ğŸ“Š Train/Test split: {len(self.X_train)}/{len(self.X_test)}\")\n",
    "        print(f\"   ğŸ“ Features scaled using StandardScaler\")\n",
    "        \n",
    "        self.next(self.train_models)\n",
    "    \n",
    "    @catch(var='training_errors')\n",
    "    @step\n",
    "    def train_models(self):\n",
    "        \"\"\"\n",
    "        Train and compare multiple ML algorithms\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ¤– Training Multiple ML Models...\")\n",
    "        \n",
    "        # Parse model list\n",
    "        model_names = [name.strip() for name in self.models_to_test.split(',')]\n",
    "        \n",
    "        # Define model configurations\n",
    "        model_configs = {\n",
    "            'random_forest': RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                random_state=self.random_state\n",
    "            ),\n",
    "            'logistic_regression': LogisticRegression(\n",
    "                random_state=self.random_state,\n",
    "                max_iter=1000\n",
    "            ),\n",
    "            'svm': SVC(\n",
    "                random_state=self.random_state,\n",
    "                probability=True\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Train models\n",
    "        self.model_results = {}\n",
    "        self.training_errors = {}\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        for model_name in model_names:\n",
    "            if model_name in model_configs:\n",
    "                try:\n",
    "                    print(f\"   ğŸ”¨ Training {model_name}...\")\n",
    "                    \n",
    "                    model = model_configs[model_name]\n",
    "                    \n",
    "                    # Cross-validation\n",
    "                    cv_scores = cross_val_score(\n",
    "                        model, self.X_train_scaled, self.y_train,\n",
    "                        cv=cv, scoring='accuracy'\n",
    "                    )\n",
    "                    \n",
    "                    # Fit and evaluate\n",
    "                    model.fit(self.X_train_scaled, self.y_train)\n",
    "                    test_accuracy = model.score(self.X_test_scaled, self.y_test)\n",
    "                    \n",
    "                    self.model_results[model_name] = {\n",
    "                        'model': model,\n",
    "                        'cv_mean': cv_scores.mean(),\n",
    "                        'cv_std': cv_scores.std(),\n",
    "                        'test_accuracy': test_accuracy\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"      CV: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}\")\n",
    "                    print(f\"      Test: {test_accuracy:.3f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"      âŒ Training failed: {str(e)}\")\n",
    "                    self.training_errors[model_name] = str(e)\n",
    "        \n",
    "        print(f\"\\n   âœ… Successfully trained {len(self.model_results)} models\")\n",
    "        \n",
    "        self.next(self.evaluate)\n",
    "    \n",
    "    @step\n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Evaluate models and select best performer\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ“Š Model Evaluation...\")\n",
    "        \n",
    "        if not self.model_results:\n",
    "            print(\"   âŒ No models to evaluate\")\n",
    "            self.best_model_name = None\n",
    "            self.next(self.end)\n",
    "            return\n",
    "        \n",
    "        # Find best model\n",
    "        best_model_name = max(self.model_results.keys(),\n",
    "                            key=lambda x: self.model_results[x]['cv_mean'])\n",
    "        \n",
    "        self.best_model_name = best_model_name\n",
    "        best_results = self.model_results[best_model_name]\n",
    "        \n",
    "        print(f\"   ğŸ† Best model: {best_model_name}\")\n",
    "        print(f\"   ğŸ“ˆ CV score: {best_results['cv_mean']:.3f} Â± {best_results['cv_std']:.3f}\")\n",
    "        print(f\"   ğŸ¯ Test accuracy: {best_results['test_accuracy']:.3f}\")\n",
    "        \n",
    "        # Generate predictions for evaluation\n",
    "        best_model = best_results['model']\n",
    "        self.y_pred = best_model.predict(self.X_test_scaled)\n",
    "        \n",
    "        # Classification report\n",
    "        self.classification_report = classification_report(\n",
    "            self.y_test, self.y_pred,\n",
    "            target_names=self.target_names,\n",
    "            output_dict=True\n",
    "        )\n",
    "        \n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        Finalize pipeline\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ‰ Complete ML Pipeline Finished!\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        if self.best_model_name:\n",
    "            best_results = self.model_results[self.best_model_name]\n",
    "            \n",
    "            print(\"ğŸ“Š Pipeline Summary:\")\n",
    "            print(f\"   ğŸ† Best Model: {self.best_model_name}\")\n",
    "            print(f\"   ğŸ¯ Accuracy: {best_results['test_accuracy']:.3f}\")\n",
    "            print(f\"   ğŸ“ˆ CV Score: {best_results['cv_mean']:.3f}\")\n",
    "            print(f\"   ğŸ¤– Models Trained: {len(self.model_results)}\")\n",
    "            \n",
    "            # Performance assessment\n",
    "            accuracy = best_results['test_accuracy']\n",
    "            if accuracy > 0.95:\n",
    "                print(\"   âœ… Excellent performance - ready for production!\")\n",
    "            elif accuracy > 0.9:\n",
    "                print(\"   âœ… Very good performance\")\n",
    "            elif accuracy > 0.8:\n",
    "                print(\"   âš ï¸ Good performance - consider improvements\")\n",
    "            else:\n",
    "                print(\"   âŒ Performance needs improvement\")\n",
    "        else:\n",
    "            print(\"âŒ Pipeline execution failed\")\n",
    "        \n",
    "        print(\"\\nâœ¨ All artifacts saved by Metaflow!\")\n",
    "\n",
    "print(\"âœ… CompleteMLPipeline class defined successfully!\")\n",
    "print(\"ğŸ’¡ To run: save as .py file and execute 'python pipeline.py run'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§ª PIPELINE DEMONSTRATION\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Quick demo with sample data\n",
    "wine_data = load_wine()\n",
    "X, y = wine_data.data, wine_data.target\n",
    "\n",
    "print(f\"ğŸ“Š Dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "\n",
    "# Split and preprocess\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"ğŸ”§ Preprocessing: {len(X_train)} train, {len(X_test)} test\")\n",
    "\n",
    "# Quick model comparison\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    accuracy = model.score(X_test_scaled, y_test)\n",
    "    print(f\"ğŸ¤– {name}: {accuracy:.3f} accuracy\")\n",
    "\n",
    "print(\"\\nâœ… Pipeline components working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“Š RESULTS VISUALIZATION\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Comprehensive model comparison\n",
    "models_to_compare = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'SVM': SVC(random_state=42, probability=True)\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "model_results = {}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models_to_compare.items():\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    test_accuracy = model.score(X_test_scaled, y_test)\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'test_accuracy': test_accuracy\n",
    "    }\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle('ML Pipeline Results Analysis', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 1. Model comparison\n",
    "model_names = list(model_results.keys())\n",
    "cv_means = [model_results[name]['cv_mean'] for name in model_names]\n",
    "test_accs = [model_results[name]['test_accuracy'] for name in model_names]\n",
    "\n",
    "x_pos = np.arange(len(model_names))\n",
    "axes[0].bar(x_pos - 0.2, cv_means, 0.4, label='CV Score', alpha=0.7)\n",
    "axes[0].bar(x_pos + 0.2, test_accs, 0.4, label='Test Score', alpha=0.7)\n",
    "axes[0].set_xlabel('Models')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Model Performance')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(model_names, rotation=45)\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Feature importance (Random Forest)\n",
    "rf_model = models_to_compare['Random Forest']\n",
    "feature_importance = rf_model.feature_importances_\n",
    "top_features_idx = np.argsort(feature_importance)[-8:]\n",
    "axes[1].barh(range(len(top_features_idx)), feature_importance[top_features_idx])\n",
    "axes[1].set_yticks(range(len(top_features_idx)))\n",
    "axes[1].set_yticklabels([wine_data.feature_names[i] for i in top_features_idx])\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].set_title('Top Features (Random Forest)')\n",
    "\n",
    "# 3. Confusion matrix (best model)\n",
    "best_model_name = max(model_results.keys(), key=lambda x: model_results[x]['cv_mean'])\n",
    "best_model = models_to_compare[best_model_name]\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[2])\n",
    "axes[2].set_xlabel('Predicted')\n",
    "axes[2].set_ylabel('Actual')\n",
    "axes[2].set_title(f'Confusion Matrix ({best_model_name})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ğŸ† Best Model: {best_model_name}\")\n",
    "print(f\"ğŸ“ˆ CV Score: {model_results[best_model_name]['cv_mean']:.3f}\")\n",
    "print(f\"ğŸ¯ Test Accuracy: {model_results[best_model_name]['test_accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Production Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸš€ PRODUCTION DEPLOYMENT\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "print(\"ğŸ“‹ Production Checklist:\")\n",
    "checklist = [\n",
    "    \"âœ… Model performance >90% accuracy\",\n",
    "    \"âœ… Cross-validation stability\",\n",
    "    \"âœ… Error handling implemented\",\n",
    "    \"âœ… Reproducible with fixed seeds\",\n",
    "    \"âš ï¸ Monitoring setup needed\",\n",
    "    \"âš ï¸ A/B testing framework\"\n",
    "]\n",
    "\n",
    "for item in checklist:\n",
    "    print(f\"   {item}\")\n",
    "\n",
    "print(\"\\nğŸ”§ Next Steps:\")\n",
    "next_steps = [\n",
    "    \"1. Set up model serving API\",\n",
    "    \"2. Implement monitoring dashboard\",\n",
    "    \"3. Create automated retraining\",\n",
    "    \"4. Establish performance alerts\",\n",
    "    \"5. Document model limitations\"\n",
    "]\n",
    "\n",
    "for step in next_steps:\n",
    "    print(f\"   {step}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Deployment Options:\")\n",
    "print(\"   ğŸ“¦ Batch Processing: Metaflow + AWS Batch\")\n",
    "print(\"   ğŸŒ Real-time API: Flask/FastAPI + Docker\")\n",
    "print(\"   ğŸ”„ Streaming: Kafka + Spark\")\n",
    "\n",
    "print(\"\\nâœ… Pipeline is production-ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Workshop Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“ WEEK 1 WORKSHOP COMPLETE!\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "print(\"ğŸ† What You've Accomplished:\")\n",
    "accomplishments = [\n",
    "    \"âœ… Built complete Metaflow ML pipeline\",\n",
    "    \"âœ… Mastered data exploration techniques\",\n",
    "    \"âœ… Implemented robust preprocessing\",\n",
    "    \"âœ… Compared multiple ML algorithms\",\n",
    "    \"âœ… Created professional visualizations\",\n",
    "    \"âœ… Assessed production readiness\"\n",
    "]\n",
    "\n",
    "for achievement in accomplishments:\n",
    "    print(f\"   {achievement}\")\n",
    "\n",
    "print(\"\\nğŸ› ï¸ Skills Developed:\")\n",
    "print(\"   ğŸ”§ Metaflow workflow development\")\n",
    "print(\"   ğŸ“Š Pandas data manipulation\")\n",
    "print(\"   ğŸ¤– Scikit-learn model training\")\n",
    "print(\"   ğŸ“ˆ Matplotlib/Seaborn visualization\")\n",
    "print(\"   âš–ï¸ Cross-validation techniques\")\n",
    "\n",
    "print(\"\\nğŸš€ Coming in Week 2:\")\n",
    "print(\"   ğŸ”— LangChain and LCEL\")\n",
    "print(\"   ğŸ§  LLM integration\")\n",
    "print(\"   ğŸ“ Text processing pipelines\")\n",
    "print(\"   ğŸŒ AI application development\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Practice Recommendations:\")\n",
    "print(\"   ğŸ”„ Run pipeline with different datasets\")\n",
    "print(\"   âš™ï¸ Experiment with parameters\")\n",
    "print(\"   ğŸ“Š Create custom visualizations\")\n",
    "print(\"   ğŸ“š Review LangChain basics\")\n",
    "\n",
    "print(\"\\nğŸ‰ Excellent work! Ready for Week 2!\")\n",
    "print(\"ğŸ† - INRIVA AI Academy Team\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Pipeline for Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ’¾ Pipeline Export Instructions\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "print(\"ğŸ“‹ To use this pipeline:\")\n",
    "print(\"\")\n",
    "print(\"1. ğŸ“„ Create 'complete_ml_pipeline.py'\")\n",
    "print(\"2. ğŸ“ Copy CompleteMLPipeline class from cell 2\")\n",
    "print(\"3. ğŸ’¾ Add imports and main block\")\n",
    "print(\"4. â–¶ï¸ Run: python complete_ml_pipeline.py run\")\n",
    "print(\"5. ğŸ“Š View: python complete_ml_pipeline.py show\")\n",
    "print(\"\")\n",
    "print(\"ğŸ”§ Example commands:\")\n",
    "print(\"   python complete_ml_pipeline.py run\")\n",
    "print(\"   python complete_ml_pipeline.py run --test_size 0.3\")\n",
    "print(\"   python complete_ml_pipeline.py run --models 'random_forest,svm'\")\n",
    "print(\"\")\n",
    "print(\"ğŸ“ˆ Access results:\")\n",
    "print(\"   from metaflow import Flow\")\n",
    "print(\"   flow = Flow('CompleteMLPipeline')\")\n",
    "print(\"   run = flow.latest_run\")\n",
    "print(\"\")\n",
    "print(\"âœ¨ Production-ready MLOps workflow!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}